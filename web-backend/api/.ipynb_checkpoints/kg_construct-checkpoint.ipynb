{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "load_dotenv()  # 加载.env文件\n",
    "\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from utils.kg_utils import *\n",
    "from objs.KG import KG_Class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f20c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_topic = \"related work, automatic generation\"\n",
    "\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "model = os.getenv(\"OPENAI_API_NAME\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7222cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--api_base\", type=str, default=api_base, help=\"the api base\")\n",
    "parser.add_argument(\"--api_key\", type=str, default=api_key,help=\"the api key\")\n",
    "parser.add_argument(\"--model\", type=str, default=model, help=\"name of the  llm\")\n",
    "args = parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25a4b44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(api_base='https://api.openai-proxy.org/v1', api_key='sk-CjN80YJ5SE9pHUdfxuN88pXsrBaIHIxIlFjOSPnzf6ahO362', model='gpt-3.5-turbo')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a10fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) , pages 1624–1633, October 25-29, 2014, Doha, Qatar. c 2014 Association for Computational Linguistics Automatic Generation of Related Work Section s in Scientific Papers: An Optimization Approach Yue Hu and Xiaojun Wan Institute of Computer Science and Technology The MOE Key Laboratory of Computational Li nguistics Peking University, Beijing, China {ayue.hu,wanxiaojun}@pku.edu.cn Abstract In this paper, we investigate a challeng- ing task of automatic related work gener- ation. Given multiple reference papers as input, the task aims to generate a related work section for a target paper. The gen- erated related work section can be used as a draft for the author to complete his or her final related work section. We propose our Automatic Related Wor k Generation system called ARWG to ad- dress this task',\n",
       " 'It first exploits a PLSA model to split the sentence set of the giv- en papers into different topic -biased parts, and then applies regression models to learn the importance of the sentences. At last it em ploys an optimization frame- work to generate the related work section. Our evaluation results on a test set of 150 target papers along with their reference papers show that our proposed ARWG system can generate related work sec- tions with better quality. A u ser study is also performed to show ARWG can achieve an improvement over generic multi -document summarization baselines. 1 Introduction The related work sec tion is an important part of a paper. An author often needs to help readers to understand the context of his or her research problem and compare his or her current work with previous works. A related work section is often used for this purpose to show the differ- ences and advantages of his or her work, com- pared with related research works ',\n",
       " 'In this study, we attempt to automatically generate a related work section for a target academic paper with its reference papers. This kind of related work sec- tions can be used as a basis to reduce the author’s time and effort when he or she wants to complete his or her final related work section. Automatic related work section generation is a very challenging task. It can be considered a top- ic-biased, multiple -document summarization problem. The input is a targe t academic paper, which has no related work se ction, along with its reference papers. The goal is to create a related work section that describes the related works and addresses the relationship between the target pa- per and the reference papers. Here we as sume that the set of reference papers has been given as part of the inp ut. Existing works in the NLP and recommendation systems communities have al- ready focused on the task of finding reference papers',\n",
       " 'For example, citation prediction (Nal- lapati et al., 20 08) aims at finding individual pa- per citation patterns . Generally speaking, automatic related work section generation is a strikingly different prob- lem and it is much more difficult in comparison with general multi -document summarization tasks. For example, multi -document summariza- tion of news articles aims at synthesizing con- tents of similar news and removing the redundant information contained by the different news arti- cles. However, each scientific paper has much specific content to state its own work and contri- bution. Even for the papers that investigate the same research topic, their contribution s and con- tents can be total ly different. The related work section g eneration task needs to find the specific contributions of individual papers and arran ge them into one or several paragraphs ',\n",
       " 'In this study, we focus on the problem of au- tomatic related work section generation and pro- pose a novel system called A RWG to address the 1624problem. For the target paper, we assume that the abstract and introduction se ctions have already been written by the author and they can be used to help generate the related work section. For the reference papers, we only consider and extract the abstract, introduction, related work and con- clusion sections, because other s ections like the method and evaluation sections always describe the extreme details of the specific work and they are not suitable for this task. Then we generate the related work secti on using both sentence sets which are extracted from the target paper and refer ence papers, respectively. Firstly, we use a PLSA model to group both sentence sets of the target p aper and its reference papers into different topic -biased clusters',\n",
       " 'Sec- ondly, the importance of each sentence in the target paper and the reference papers is learned by using two different Support Vector Regres- sion (SVR) models. At last, a global optimization framework is proposed to generate the related work section by selecting sentences from both the target paper and the reference papers. Mean- while, the fra mework selects sentences from dif- ferent topic -biased clusters globally. Experimental results on a test set of 150 target papers show our method can generate related work sections with better quality than those of several baseline methods. With the ROUGE toolkit, the results indicate the related work sec- tions generated by our system can get higher ROUGE scores. Moreover, our related work sec- tions can get higher rating scores based on a user study. Therefore, our related work sections can be much more suitabl e for the authors to prepare their final related work sections. 2 Related Work There are few studies to directly address auto- matic related work generation',\n",
       " 'Hoang and Kan (2010) proposed a relate d work summarization system given the set of keywords arranged i n a hierarchical fashion that describes the paper’s topic. They used two different rule -based strate- gies to extract sentences for general topics as well as detailed ones. A few studies focus on multi -document scien- tific article summarization. Agarwal et al ., (2011) introduced a n unsupervised approach to the prob- lem of multi -document summarization. The input is a list of papers cited together within the same source article. The key point of this approach is a topic based clustering of fragments extracted from each co -cited article. They rank all the clus-ters using a query generated from the context surrounding the co -cited list of papers. Yeloglu et al',\n",
       " ', (2011) compared four different approaches for multi -document scientific articles summariza- tion: MEAD, M EAD with corpus specific vo- cabulary, LexRank and W3SS. Other studies investigate mainly on the single - document scientific article summarization. Early works including (Luhn 1958; Baxendale 1958; Edumundson 1969) tried to use various features specific to sc ientific text (e.g., sentence position, or rhetorical clues features). They have proved that these features are effective for the scientific article summarization. Citation information has been already shown effective in summarize the scientific articles. Works including (Mei and Zhai 2008; Qazvinian and Radev 2008; Schwartz and Hearst 2006; Mohammad et al. , 2009) em- ployed citation information for the single scien- tific article summarization. Earlier work (Nakov et al',\n",
       " ', 2004) indicated that citation sentence s may contain important concepts that can give useful descriptions of a paper. Various methods have been proposed for news document summarization, including rule -based methods (Barzilay and Elhadad 1997; Marcu and Daniel 1997), graph -based methods (Mani an d Bloedorn 2000; Erkan and Radev 2004; Michal- cea and Tarau 2005), learning -based methods (Conroy et al. , 2001; Shen et al. , 2007; Ouyang et al. , 2007; Galanis et al. , 2008), optimization - based methods (McDonald 2007; Gillick et al. , 2009; Xie et al. , 2009; Berg -Kirkpatrick et al. , 2011; Lei Huang et al. , 2011; Woodsend et al',\n",
       " ', 2012; Galanis 2012), etc. The most relevant work is (Hoang and Kan, 2010) as mentioned above. They also assumed the set of reference papers was given as part of the input. They also adopt the hierarchical topic tree that describes the topic structure in the target paper as an essential input for their system. However, it is non -trivial to build the hierar- chical topic tree. Moreover, they do not consider the content of the target paper to construct the related work section , which is actually crucial in the related work section. To the best of our knowledge, no previous works have used super- vised learning and optimization framework to deal with the multi ple scientific article summari- zation tasks . 3 Problem Analysis and Corpus 3.1 Problem Analysis 1625We firstly analyze the structure of related work sections briefly. By using examples for illustra- tion, we can gain insight on how to generate re- lated work sections',\n",
       " 'A specific related work ex- ample is shown in Figure 1. This related work section introduces previous related works for a paper on Automatic Taxono- my Induction. From Fig ure 1, we can have a glance at the structure of related work sections. Related work sections usually discuss several different topics, such as “pattern -based” and “cluster -based” approaches shown in the Figure 1. Besides the knowledge of previous works, th e author often compares his own work with the previous works. The differences and advantages are generally mentioned. The example in Figure 1 also indicates this phenomenon. Therefore, we design our system to generate related work sections according to the related work section structure mentioned above. Our system takes the target paper for which a related work section needs to be drafted besides its ref- erence papers as input. The goal of our system is to generate a related work section with the above struc ture. The generated related work section should have several topic -biased parts',\n",
       " \"The au- thor's own wo rk is also needed to be described and its difference with other works is needed to be emphasized on. 3.2 Corpus and Preprocessing We build a corpus that contains academic papers and their corresponding reference papers. The academic papers are selected from the ACL An- thology1. The ACL Anthology currently hosts 1 http://aclweb.org/anthology/ over 24,500 pa pers from major conferences such as ACL, EMNLP, COLING in the fields of com- putational linguistics and natural language pro- cessing. We remove the papers that contain relat- ed work sections with very short length, and ran- domly select 1050 target papers to construct our whole corpus. The papers are all in PDF format. We extract their texts by using PDFlib2 and detect their physical structures of paragraphs, subsection s and sections by using ParsCit3. For the target papers, the related work sections are directly ex- tracted as the gold summaries\",\n",
       " 'The references are also extracted. For th e references that can be found in the ACL Anthology, we download them from the ACL Anthology. The other reference papers are searched and downloaded by using Google Scholar. References to books and PhD theses are discarded, for their verbosity may change t he problem drastically (Mihalcea and Ceylan, 2007). The input of our system includes the abstract and introduction sections of the target paper, and the abstract, introduction, related work and con- clusion sections of the reference papers. As men- tioned abov e, the method and evaluation sections in the reference papers are not used as input be- cause these sections usually describe extreme details of the methods and evaluation results and they are not suitable for related work generation',\n",
       " 'Note that it is reasona ble to make use of the ab- stract and introduction sections of the target pa- per to help generate the related work section, because an author usually has already written the abstract and introduction sections before he or she wants to write the related work s ection for the target paper. Otherwise, we cannot get any information about the author’s own work. All other sections in the target paper are not used. 4 Our Proposed System 4.1 Overview In this paper, we propose a system called ARWG to automatically generate a related work section for a given target paper. The architecture of our system is shown in Figure 2. We take both the target paper and its reference papers as input and they are represented by several sections men- tioned in Secti on 3.2 ',\n",
       " 'After preprocessing, we extract the feature vectors for sentences in the target paper and the reference papers, respective- 2 http://www.pdflib.com/ 3 http://aye.comp.nus.edu.sg/parsCit/ Figure 1: A sample related work section (Yang and Callan 2009 ) There has been a substantial amount of research on automatic taxonomy induction. As we mentioned earlier, two main approaches are pattern -based and clustering -based . Pattern -based approaches are the main trend for automatic taxonomy induction . … Pattern -based approaches started from and still pay a great deal of attention to the most common is -a relations . … Clustering -based approaches usually represent word contexts as vectors and cluster words based on similarities of the vectors (Brown et al., 1992; Lin, 1998 ). … Many clustering -based approaches face the challenge of appropriately labeling non -leaf clusters . … In this paper, we take an incremental clustering approach,..',\n",
       " 'The advantage of the incremental approach is that it eliminates the trouble of inventing cluster labels and concentrates on placing terms in the correct positions in a taxonomy hierarchy . The work by Snow et al. (2006) is the most similar to ours … Moreover, our approach employs heterogeneous features from a wide range; while their approach only used syntactic dependency.Two different topics Comparison with the author’s work1626ly. The importance scores for sentences in the target paper and the reference papers are as- signed by using two SVR based sente nce scoring model s. The two SVR models are trained for sentences in the target paper and the reference papers, respectively. Meanwhile, a topic model is applied to the whole set of sentence s in both the target paper and reference pap ers. The sentences are grouped into several different topic -biased clusters. The sentences with importance scores and topic cluster information are taken as the input for the global optimization framework',\n",
       " 'The optimization framework extracts sentences to describe both the author ’s own work and back- ground knowledge. More details of each part will be discussed in the following sections. 4.2 Topic Model Learning As mentioned in the previous section, the related work section usually addresses several different topics. The topics may be d ifferent research themes or different aspects of a broad research theme. The related work section should describe the specific details for each topic, respectively. Therefore, we aim to discover the hid den top- ics of the input papers, and we use the Probabi l- istic latent semantic analysis (PLSA) (Hofmann, 1999) to solve this problem. The PLSA approach models each word in a document as a sample from a mixture model. The mixture components are multinomial ran- dom variables that can be viewed as representa- tions of “topics ”. Different words in a document may be generated from different topics',\n",
       " 'Each document is represented a list of mixing propor- tions for t hese mixture components and can be reduced to a probability distribution on a fixed set of topics. Considering that the sentences in one paper may relate to different topics, we treat each sen- tence as a “document” d. We treat the noun phases in the sentences as the “words” w. In or- der to extract the noun phrases, chunking imple- mented by the OpenNLP toolkit 4 is ap plied to the sentences. Noun phrases that contain words such as “paper” and “data” are discarded. Then the sentences with their corresponding noun phrases are taken as input into the PLSA model. Here both the sentences in the target pa- per and the sentences in the reference papers are treated the same in the model. Finally, we can get the sentence set with topic information and use it in the subsequent steps. Each sentence has a topic weight t in each topic',\n",
       " '4.3 Sentence Important Assessment In our proposed system, sentence importance assessment aims to a ssign an importance score to each sentence in the target paper and reference papers. The score of each sentence will be used in the subsequent optimization framework. We propose to use the support vector regr ession model to achieve this goal . In the above topic model learning process, we do not di stinguish the sentences in the target paper and reference pa- pers. In contrast, we train two different support vector regression models separately for the sen- tences in the target paper and the sentences in the reference papers. In the related work section, the sentences that describe the author’s own work usually address the differences from the related works, while the sentences that describe the re- lated works often focus on the specific details . We think the two kinds of sentences should be treated differe ntly',\n",
       " 'Scoring Method To construct training data based on the papers collected, we apply a similarity scoring method to assign the importance scores to the sentences in the papers. The main hypothesis is that the sentences in the gold related work sections should summarize the target paper and reference papers as well. Thus the sentences in the papers which are more similar to the sentences in the gold related work sections should be considered more important and suitable to be selected. Our scoring method should assign h igher scores to them ',\n",
       " '4 http://opennlp.apache.org/ Figure 2: System Architecture Target paper Reference papers Preprocessing Topic ModelSentence Score Assessment(target )Sentence Score Assessment(reference ) Optimization Framework PostprocessingRelated Work Section1627We define the importance score of a sentence in the papers as below: 𝑠𝑐𝑜𝑟𝑒 (𝑠)= 𝑚𝑎𝑥 𝑠𝑖∗∈𝑆∗(𝑠𝑖𝑚(𝑠,𝑠𝑖∗)) (1) where s is a sentence in the papers, 𝑆∗ is the set of the sentences in the corresponding gold relat- ed work section. The standard cosine measure is employed as the similarity function',\n",
       " 'Consider ing the difference between the sen- tences that describe the author’s work and the sentences that describe the related work s, we split the set of sentences in the gold related work section into two parts: one discusses the author ’s own work and the other introduces the related works. We observe that sentences related to the author ’s own work often feature specific words or phrases ( such as “we”, “our work ”, “in this paper ” etc.) in the related work section. So we check the sentences about whether they contain clue words or phrases (i.e., “in this paper ”, “our work ” and 18 other phrases). If the clue phra se check fails, the sentence belongs to the related work part. If not, it belongs the own work part',\n",
       " 'Thus for the sentences in the target paper, 𝑆∗ is the set of sentences in the own work part of the gold related work section, while for the sentences in the reference papers , 𝑆∗ is the set of sentences in the related work part of the gold related work section. Then we can use the scoring method to compute the target score s of the sentences in the training set . It is noteworthy that two SVR mod- els can be trained on the two parts o f the training data, respectively. Feature Each sentence is represented by a set of features. The common features used for the sentences of the target paper and reference papers are shown in Table 1. The additional features applied to the sentences of the target paper are introduced in Table 2. Here, s is a sentence that needs to extract fea- tures. th is paper title, section headings and sub- section headings set of the reference papers or target paper for the two SVR models, respective- ly',\n",
       " 'Each feature with “*” represent a feature set that contain s similar features. All the features are scaled into [0, 1]. Thus we can learn SVR models based on the features and importance scores of the sentences, and then use the models to predict an importance score for each s entence in the test set. The SVR models are trained and applied for the target paper and reference papers, respectively. Table 1: Common features employed in the SVR models Feature Description 𝑆𝑖𝑚 (𝑠,𝑡ℎ)∗ The similarity between s and each title in th; Stop words are removed and stemming is employed. WS(s,th) Number of words shared by s and th',\n",
       " '𝑆𝑃(𝑠)∗ The position of s in its section or subsection 𝑃𝑇𝐼(𝑠)∗ The parse tree information of s, including the number of noun phrase and verb phrases, the depth of the parse tree, etc. 𝐼𝑠𝐻𝑒𝑎𝑑 (𝑠)∗ Indicates whether s is the first sen- tence of the section or subsection 𝐼𝑠𝐸𝑛𝑑 (𝑠)∗ Indicates whether s is the last sen- tence of the section or subsection SWP(s) The percentage of the stop words Length(s) The length of sentence s Length_rw(s) The length of s after removing stop words SI(s) The section index of s that indi- cates which section s is from',\n",
       " '𝐶𝑙𝑢𝑒𝑃 ℎ𝑟𝑎𝑠𝑒 (𝑠)∗ Indicates whether a clue phrase appears in s. the clue phrases in- clude “our work ”, “propose ” and other 20 words. Each clue phrase corresponds to one feature. Table 2: Additional features for sentences in the target paper Feature Description HasCitation(s) Indicates whether s contains a citation 𝑃h𝑟𝑎𝑠𝑒𝐹𝑜𝑟𝐶𝑚𝑝 (𝑠)∗ Indicates whether s contains words or phrases used for com- parison such as “in contrast ”, “instead ” and other 26 words. Each word or phrase corre- sponds to one feature',\n",
       " '4.4 A Global Optimization Framework In the above steps, we can get the predicted im- portance score and topic information for each sentence in the target paper and reference papers. Here, we introduce a global optimization frame- work to generate the related work section. According to the structure of the related work section mentioned above, the related work sec- tion usually discusses several topics. In each top- ic, the related works and their details are intro- duced. Besides, the author often compares his own work with these previous works. Therefore, we propose to formu late the genera- tion as an optimization problem. Basically, we will be searching for a set of sentence s to opti- mize the objective function',\n",
       " '1628Table 3: Notations used in this section Symbol Description 𝑠𝑟𝑖/𝑠𝑡𝑖 the sentence in the reference/target paper 𝑙𝑟𝑖/𝑙𝑡𝑖 the length of sentence 𝑠𝑟𝑖/ 𝑠𝑡𝑖 𝑤𝑟𝑖/𝑤𝑡𝑖 the importance score of 𝑠𝑟𝑖/𝑠𝑡𝑖 𝑥𝑟𝑖𝑗/𝑥𝑡𝑖𝑗 indicates whether 𝑠𝑟𝑖/𝑠𝑡𝑖 is selected into the part of topic j in the generated related work section nr/nt the number of sentences in the refer- ence/target papers',\n",
       " 'm the topic count 𝑡𝑖𝑗 the topic weight of 𝑠𝑟𝑖/𝑠𝑡𝑖 in topic j from the PLSA model B the set of unique bigrams 𝑦𝑖 indicates whether bigram 𝑏𝑖 is included in the result 𝑐𝑏𝑖 the count of the occurrences of bigram 𝑏𝑖 in the both target paper and reference papers 𝐿𝑚𝑎𝑥 the maximum word count of the related work section 𝐿𝑗 the maximum word count of the part of topic j which depends on the percentage of sentences belong t o topic j 𝐵∗ the total set of bigrams in the whole pa- per set 𝐵𝑖 the set of bigrams that sentence',\n",
       " '𝑠𝑟𝑖/𝑠𝑡𝑖 contains 𝑆𝑟𝑚/𝑆𝑡𝑚 the set of sentences that include bigram 𝑏𝑚 in the reference/target papers 𝜆1, 𝜆2,𝜆3 parameters for tuning To design the objective function, three aspects should be considered: 1) First, the related work section we generate should introduce the previous works well',\n",
       " 'In our assumption, sentences with higher im- portance scores are better to be selected. In addition, very short sentences should be pe- nalized. So we introduce the first part of our objective function below: ∑ (𝑙𝑟𝑖𝑤𝑟𝑖∑ 𝑡𝑖𝑗𝑥𝑟𝑖𝑗)𝑚 𝑗=1𝑛𝑟 𝑖=1 (2) We add the sentence length as a multipli- cation factor in order to penalize the very short sentences, or the objective function tends to select more and shorter sentences. At the same time, the objective function does not tend to select the very long sentences. The total length of the sentences selected is fixed. So if the objective functi on tends to select the longer sentences, the fewer sen- tences can be selected',\n",
       " 'A tradeoff needs to be made between the number and the average length of the sentences selected . The constraints introduced below ensure that the sentence can only be selected into one topic and the topic weight is used to measure the degree that the sentence is rele- vant to the specific topic. 2) Second, similar to the first part, we should consider the own work part of the related work section. Thus the second part of our ob- jective function is shown as follows: ∑ (𝑙𝑡𝑖𝑤𝑡𝑖∑ 𝑡𝑖𝑗𝑥𝑡𝑖𝑗)𝑚 𝑗=1𝑛𝑡 𝑖=1 (3) 3) At last, redundancy reduction should be con- sidered in the objective function',\n",
       " 'The last part of the objective function is shown below: ∑ 𝑐𝑏𝑖𝑦𝑖|𝐵| 𝑖=1 (4) The intuition is that the more unique bi- grams the related work section contains, the less redundancy the related work section has. We add 𝑐𝑏𝑖 as the weight of the bigram in or- der to include more important bigrams',\n",
       " 'By combing all the parts defined above, we have the following full object ive function: max 𝑥𝑟,𝑥𝑡𝜆1∑ (𝑙𝑟𝑖 𝛼𝐿𝑚𝑎𝑥𝑤𝑟𝑖∑ 𝑡𝑖𝑗𝑥𝑟𝑖𝑗)𝑚 𝑗=1 +𝑛𝑟 𝑖=1 𝜆2∑ (𝑙𝑡𝑖 (1−𝛼)𝐿𝑚𝑎𝑥𝑤𝑡𝑖∑ 𝑡𝑖𝑗𝑥𝑡𝑖𝑗)𝑚 𝑗=1𝑛𝑡',\n",
       " '𝑖=1 + 𝜆3∑𝑐𝑏𝑖𝑦𝑖 |𝐵∗||𝐵| 𝑖=1 (5) Subject to: ∑ 𝑙𝑟𝑖𝑥𝑟𝑖𝑗𝑛𝑟 𝑖=1 +∑ 𝑙𝑡𝑖𝑥𝑡𝑖𝑗𝑛𝑡 𝑖=1 < 𝐿𝑗,𝑓𝑜𝑟 𝑗=1,…, 𝑚 (6) ∑ ∑ 𝑙𝑟𝑖𝑥𝑟𝑖𝑗𝑚 𝑗=1𝑛𝑟 𝑖=1 <',\n",
       " '𝛼𝐿𝑚𝑎𝑥 (7) ∑ ∑ 𝑙𝑡𝑖𝑥𝑡𝑖𝑗𝑚 𝑗=1𝑛𝑡 𝑖=1 < (1−𝛼)𝐿𝑚𝑎𝑥 (8) ∑ 𝑥𝑟𝑖𝑗𝑚 𝑗=1 ≤1,𝑓𝑜𝑟 𝑖=1,…,𝑛𝑟 (9) ∑ 𝑥𝑡𝑖𝑗𝑚 𝑗=1 ≤1,𝑓𝑜𝑟 𝑖=1,…,𝑛𝑡 (10) ∑ 𝑦𝑘',\n",
       " '𝑏𝑘∈𝐵𝑖 ≥|𝐵𝑖|∑ 𝑥𝑟𝑖𝑗𝑚 𝑗=1 ,𝑓𝑜𝑟 𝑖=1,…,𝑛𝑟 (11) ∑ 𝑦𝑘 𝑏𝑘∈𝐵𝑖 ≥|𝐵𝑖|∑ 𝑥𝑡𝑖𝑗𝑚 𝑗=1 ,𝑓𝑜𝑟 𝑖=1,…,𝑛𝑡 (12) ∑ ∑ 𝑥𝑟𝑖𝑗𝑚 𝑗=1 +∑ ∑ 𝑥𝑡𝑖𝑗𝑚 𝑗=1',\n",
       " '𝑠𝑡𝑖∈𝑆𝑡𝑘 𝑠𝑟𝑖∈𝑆𝑟𝑘≥𝑦𝑘, 𝑘=1,…|𝐵| (13) 𝑥𝑟𝑖𝑗,𝑥𝑡𝑖𝑗,𝑦𝑖∈{0,1} (14) All the three parts in the objec tive function are normalized to [0, 1] by using the maximum length 𝐿𝑚𝑎𝑥 and the total number of bigrams | 𝐵∗|',\n",
       " '𝜆1, 𝜆2 and 𝜆3 are parameters for tuning the three parts and we set 𝜆1+𝜆2+𝜆3=1. We explain the constraints as follows: Constraint (6): It ensures that the total word count of the part of topic j does not exceed 𝐿𝑗. Constraints (7), (8): The two constraints try to balance the lengths of the previous works part and the own work part, respectively. 𝛼 is set to 2/3. Constraints (9), (10) : These two constraints guarantee that the sentence can only be included into one topic. 1629Constraints (11), (12): When these two con- straints hold, all bigrams that 𝑠𝑖 has are selected if 𝑠𝑖 is selected',\n",
       " 'Constraint (13): This constraint makes sure that at least one sentence in 𝑆𝑟𝑚 or 𝑆𝑡𝑚 is select- ed if bigram 𝑏𝑚 is selected. Therefore, we transform our optimization problem into a linear programing problem. We solve this linear programming problem by using the IBM CPLEX optimizer5. It generally ta kes tens of seconds to solve the problem and it is very efficient . Finally, ARWG post -processes sentences to improve readability, including replacing agentive forms with a citation to the specific article (e.g., “our work ” → “(Hoang and Kan, 2010) ”) for the sentences extracted from reference papers. The sentences belonging to different topics are placed separately',\n",
       " '5 Evaluation 5.1 Evaluation Setup To set up our experiments, we divide our dataset which contains 1050 target papers and their ref- erence papers into two parts: 700 target papers for training, 150 papers for test and the other 200 papers for validation. The PLSA topic model is applied to the whole dataset. We train two SVR regression models based on the own work part and the previous work pa rt of the training data and apply the models to the test data. The global optimization framework is used to generate the related work sections. We set the maximum word count of the generated related work section to be equal to that of the gold related work section. The parameter values of 𝜆1, 𝜆2 and 𝜆3 are set to 0.3, 0.1 and 0.6, respectively. The parameter val- ues are tuned on the validation data',\n",
       " 'We compare our system with five baseline sys- tems: MEAD -WT, LexRank -WT, ARWG -WT, MEAD and LexRank. MEAD6 (Radev et al. , 2004) is an open -source extractive multi - document summarizer. LexRank7 (Eran and Radev, 2004) is a multi -document summarization system which is based on a random walk on the similarity graph of sentences',\n",
       " 'We also implement the MEAD, LexRank b aselines and our method 5 www -01.ibm.com/software/integration/optimization/cplex - optimizer/ 6 http://www.summarization.com/mead/ 7 In our experiments, LexRank performs much better than the more complex variant - C-LexRank ( Qazvinian and Radev , 2008), and thus we choose LexRank , rather than C - LexRank, to represent graph -based summarization methods for comparison in this paper. with only the reference papers (i.e. the target pa- per’s content is not considered ). Those methods are signed by “-WT”. To evaluate the eff ectiveness of the SVR mod- els we employ, we implement a baseline system RWGOF that uses the random walk scores as the important scores of the sentences and take the scores as inputs for the same global optimization framework as our system to generate the related work section',\n",
       " 'The random walk scores are com- puted for the sentences in the reference papers and the target paper, respectively. We use the ROUGE toolkit to evaluate the content quality of the generated related work sec- tions. ROUGE (L in, 2004) is a widely used au- tomatic summarization evaluation method based on n -gram comparison. Here, we use the F - Measure score s of ROUGE -1, ROUGE -2 and ROUGE -SU4. The model texts are set as the gold related work sections extracted from the target papers , and word stemming is utilized. ROUGE -N is an n -gram based measure between a candida te text and a reference text',\n",
       " 'The recall oriented score, the precision oriented score and the F -measure score for ROUGE -N are comput- ed as follows: 𝑅𝑂𝑈𝐺𝐸 −𝑁𝑅𝑒𝑐𝑎𝑙𝑙 = ∑ ∑ 𝐶𝑜𝑢𝑛𝑡 𝑚𝑎𝑡𝑐 ℎ(𝑔𝑟𝑎𝑚 𝑛) 𝑔𝑟𝑎𝑚 𝑛 𝑆∈{𝑅𝑒𝑓𝑒𝑟𝑒𝑛𝑐𝑒 𝑇𝑒𝑥𝑡 } / ∑ ∑ 𝐶𝑜𝑢𝑛𝑡',\n",
       " '(𝑔𝑟𝑎𝑚 𝑛) 𝑔𝑟𝑎𝑚 𝑛 𝑆∈{𝑅𝑒𝑓𝑒𝑟𝑒𝑛𝑐𝑒 𝑇𝑒𝑥𝑡 } (15) 𝑅𝑂𝑈𝐺𝐸 −𝑁𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 = ∑ ∑ 𝐶𝑜𝑢𝑛𝑡 𝑚𝑎𝑡𝑐 ℎ(𝑔𝑟𝑎𝑚 𝑛) 𝑔𝑟𝑎𝑚 𝑛',\n",
       " '𝑆∈{𝑅𝑒𝑓𝑒𝑟𝑒𝑛𝑐𝑒 𝑇𝑒𝑥𝑡 } / ∑ ∑ 𝐶𝑜𝑢𝑛𝑡 (𝑔𝑟𝑎𝑚 𝑛) 𝑔𝑟𝑎𝑚 𝑛 𝑆∈{𝐶𝑎𝑛𝑑𝑖𝑑𝑎𝑡𝑒 𝑇𝑒𝑥𝑡 } (16) 𝑅𝑂𝑈𝐺𝐸 −𝑁𝐹−𝑚𝑒𝑎𝑠𝑢𝑟𝑒 =',\n",
       " '2∗𝑅𝑂𝑈𝐺𝐸 −𝑁𝑅𝑒𝑐𝑎𝑙𝑙 ∗𝑅𝑂𝑈𝐺𝐸 −𝑁𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 / 𝑅𝑂𝑈𝐺𝐸 −𝑁𝑅𝑒𝑐𝑎𝑙𝑙 +𝑅𝑂𝑈𝐺𝐸 −𝑁𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 (17) where n stands for the length of the n -gram 𝑔𝑟𝑎𝑚 𝑛 , and',\n",
       " '𝐶𝑜𝑢𝑛𝑡 𝑚𝑎𝑡𝑐 ℎ(𝑔𝑟𝑎𝑚 𝑛) is the maxi- mum number of n -grams co -occurring in a can- didate text and a reference text',\n",
       " 'In addition, we conduct ed a user study to sub- jectively evaluate the related work sections to get more evidences. We select ed the related work sections generate d by different methods for 15 random target papers in the test set. We ask ed three human judges to follow an evaluation guideline we design and evaluate these related work sections. The human judges are graduate students in the comput er science field and they did not know the identities of the evaluated relat- ed work section s',\n",
       " 'They were asked to give a rat- ing on a scale of 1 (very poor) to 5 (very good) for the correctness, readability and usefulness of the related work sections , respectively : 16301) Correctness: Is the related work section ac- tually related to the target paper? 2) Readability: Is the related work section easy for the readers to read and grasp the key content? 3) Usefulness: I s the related work section useful for the author to prepare their final related work section? Paired T -Tests are applied to both the ROUGE scores and rating scor es for comparing ARWG and baselines and comparing the systems with WT and without WT',\n",
       " '5.2 Results and Discussion Table 4: ROUGE F -measure comparison results Method ROUGE -1 ROUGE -2 ROUGE - SU4 Mead - WT 0.39720 0.08785 0.14694 LexRank - WT 0.43267 0.09228 0.16312 ARWG - WT 0.45077∗{1,2} 0.09987∗{1,2} 0.16731∗{1}#{2} Mead 0.41012∗{1} 0.09642∗{1} 0.15441∗{1} LexRank 0.44235∗{2} 0.10090∗{2} 0.17067∗{2} ARWG 𝟎.𝟒𝟕𝟗 𝟒𝟎∗{𝟏−𝟓}',\n",
       " '𝟎.𝟏𝟐𝟏 𝟕𝟔∗{𝟏−𝟓} 𝟎.𝟏𝟖𝟔 𝟏𝟖∗{𝟏−𝟓} (* represents pairwise t -test value p < 0.01; # rep- resents p < 0.05; the numbers in th e brackets rep- resent the indices of the methods compared, e.g',\n",
       " '1 for MEAD -WT, 2 for LexRank -WT, etc.) Table 5 : Average rating scores of judges Method Correctness Readability Usefulness Mead 2.971 2.664 2.716 LexRank 2.958 2.847 2.784 ARWG 3.433∗# 3.420∗# 3.382∗# (*# represents pairwise t -test value p < 0.01, compared with Mead and LexRank , respectively .) Table 6 : ROUGE F -measure comparison of dif- ferent sentence importance scores Method ROUGE -1 ROUGE -2 ROUGE -SU4 RWGOF 0.46932 0.11791 0.18426 ARWG 0.47940 0.12176 0.18618 The evaluation results over ROUGE metrics are presented in Table 4',\n",
       " 'It shows that our proposed system can get higher ROUGE scores, i.e., better content quality. In our system, we split the sen- tence set in to different topic -biased parts, and the importance score s of sentence s in the target pa- per and re ference papers are learned differently. So the obtained importance scores of the sen- tences are more reliable. The global optimizatio n framework considers the extraction of both the previous work part and the own work part. We can see the importance of the own work part by comparing the results of the methods with or without considering the own work part. MEAD, LexRank and our method al l get a significant improvement after considering the own work part by extracting sentences from the target paper. The results also prove our as- sumption about the related work section structure. Figure 3 pre sents the fluctuation of ROUGE scores when tuning the parameters λ1, λ2 and λ3',\n",
       " 'We can see our method gene rally performs better than the baselines. All the three parts in the ob- jective function are useful to generate r elated work sections with good quality. The aver age scores rated by human judge s for each meth od are showed in Table 5 . We can see that the related work sections generated by our system are more related to the target papers. Moreover, because of the good structure of our generated related work sections, our generated related work sections are considered more reada- ble and more useful for the author to prepare the final related work sections. T-test results show that the performance im- provements of our method over baselines are statistically significant on both automatic and manual evaluation s. Most of p -values for t -test are far smaller than 0.01',\n",
       " 'Overall, the results indicate that our method can generate much better related wor k sections 00.600.20.40.6 00.3 0.6 0.9 𝜆1ROUGE -1 𝜆2ROUGE -1 0.4- 0.6 0.2- 0.4 00.600.050.10.15 00.3 0.6 0.9 𝜆1ROUGE -2 𝜆2ROUGE -2 0.1- 0.15 0.05- 0.1 00.600.050.10.150.2 00.3 0.6 0.9 𝜆1ROUGE -SU4 𝜆2ROUGE -SU4 0.15 -0.2 0.1- 0.15 Figure 3: Parameter influences (horizontal, vertical axis are 𝜆1, 𝜆2 , respectively,',\n",
       " '𝜆3=1−𝜆1− 𝜆2 ) 1631than the baselines on both automatic and human evaluations',\n",
       " 'Table 6 shows the comparison results between ARWG and RWGOF. We can see ARWG per- forms better than RWGOF. It proves that the SVR models can better estimate the importance scores of the sentences. For the SVR models are trained from the large dataset, the sentence scores predicted by the SVR models can be more reliable to be used in the global optimization framework. 6 Conclusion and Future Work This paper proposes a novel system called ARWG to generate related work sections for ac- ademic papers. It first exploits a PLSA model to split the sentence set of the given papers into dif- ferent topic -biased parts, and then applies regres- sion models to learn the importance scores of the sentences. At last an optimization framework is proposed to generate the related work section . Evaluation results show that our system can gen- erate much better related work sections than the baseline methods. In future work, we will make use of citation sentence s to improve our sys tem',\n",
       " 'Citation sen- tences are the sentence s that contain s an explicit reference to another paper and they usually high- light the most impor tant aspects of the cited pa- pers. So citation sentences are likely to contain important and rich information for generating related work sections. Acknowledgments The work was supported by National Natural Science Foundation of China (61170166, 61331011), Beijing Nova Program (2008B03) and National Hi -Tech Research and Develop- ment Program (863 Program) of China (2012AA011101). We also thank the anonymous reviewers for very help ful comments. The corre- sponding author of this paper, according to the mean ing given to this role by Peking University , is Xiaojun Wan . Reference Nitin Agarwal , Kiran Gvr, Ravi Shankar Red dy, and Carolyn Penstein Rosé . 2011. Towards multi - document summarization of scientific articles: making intere sting comparisons with SciSumm',\n",
       " \"In Proceedings of the Workshop on Automatic Summarization for Different Genres, Media, and Languages , pp. 8 -15. Association for Computa- tional Linguistics . Phyllis B . Baxendale . 1958. Machine -made index for techn ical literature: an experiment. IBM Journal of Research and Development 2, no. 4 : 354 -361. Taylor Berg -Kirkpatrick , Dan Gillick, and Dan Klein. 2011. Jointly learning to extract and compress. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies -Volume 1 , pp. 481 -490. Association for Computational Linguistics . Chih -Chung Chang , and Chih -Jen Lin. 2011. LIBSVM: a library for support vector ma- chines. ACM Transact ions on Intelligent Systems and Technology (TIST) 2, no. 3 : 27. John M. Conroy , and Dianne P. O'leary. 2001\",\n",
       " 'Text summarization via hidden markov models. In Proceedings of the 24th annual international ACM SIGIR conference on Research and develop- ment in information retrieval , pp. 406 -407. ACM . Harold P. Edmundson . 1969. New methods in auto- matic extracting. Journal of the ACM (JACM) 16, no. 2: 264 -285. Gü nes Erkan , and Dragomir R. Radev. 2004. LexPag- eRank: Prestige in Multi -Document Text Summa- rization. In EMNLP , vol. 4, pp. 365 -371. Gü nes Erkan , and Dragomir R. Radev. 2004. LexRank: Graph -based lexical centrality as sali- ence in text summarization. J. Artif. Intell. Res.(JAIR) 22, no. 1 : 457 -479. Dimitrios Galanis , Gerasimos Lampo uras, and Ion Androutsopoulos. 2012',\n",
       " 'Extractive Multi - Document Summarization with Integer Linear Pro- gramming and Support Vector Regression. In COLING , pp. 911 -926. Dimitrios Galanis , and Prodromos Malakasiotis. 2008. Aueb at tac 2008. InProceedings of the TAC 2008 Workshop . Dan Gillick , and Benoit Favre. 2009. A scalable glob- al model for summarization. InProceedings of the Workshop on Integer Linear Programming for Natural Langauge Processing , pp. 10 -18. Associa- tion for Computational Linguistics . Cong Duy Vu Hoang , and Min -Yen Kan. 2010. To- wards automated related work summarization. In Proceedings of the 23rd International Confer- ence on Computational Linguistics: Posters , pp. 427-435. Association for Computational Linguis- tics. Lei Huang , Yanxiang He, Furu Wei, and Wenjie Li. 2010. Modeling document summarization as multi - objective optimization',\n",
       " 'In Intelligent Information Technology and Security Informatics (IITSI), 2010 Third International Symposium on , pp. 382 -386. IEEE . 1632Thomas Hofmann . 1999. Probabilistic latent semantic indexing. In Proceedings of the 22nd annual inter- national ACM SIGIR conference on Research and development in information retrieval , pp. 50 -57. ACM . Chin -Yew Lin. 2004. Rouge: A package for automatic evaluation of summarie s. InText Summarization Branches Out: Proceedings of the ACL -04 Work- shop , pp. 74 -81. Hans Peter Luhn . 1958. The automatic creation of literature abstracts. IBM Journal of research and development 2, no. 2 : 159 -165. Inderjeet Mani , and Eric Bloedorn. 1999. Summariz- ing similarities and differences among related doc- uments. Information Retrieval 1, no. 1 -2: 35-67. Ryan McDonald . 2007',\n",
       " 'A study of global inference algorithms in multi -document summarization . Springer Berlin Heidelberg . Qiaozhu Mei, and ChengXiang Zhai. 2008. Generat- ing Impact -Based Summaries for Scientific Litera- ture. In ACL, vol. 8, pp. 816 -824. Rada Mihalcea , and Paul Tarau. 2005. A language independent algorithm for single and multiple doc- ument summarization . Rada Mihalc ea, and Hakan Ceylan. 2007. Explora- tions in Automatic Book Summarization. In EMNLP -CoNLL , pp. 380 -389. Saif Mohammad , Bonnie Dorr, Melissa Egan, Ahmed Hassan, Pradeep Muthukrishan, Vahed Qazvinian, Dragomir Radev, and David Zajic. 2009. Using ci- tations to generate surveys of scientific paradigms',\n",
       " \"In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North Ameri- can Chapter of the Association for Computational Linguistics , pp. 584 -592. Association fo r Computa- tional Linguistics . Preslav Nakov , Ariel Schwartz, and M. Hearst. 2004. Citation sentences for semantic analysis of biosci- ence text. In Proceedings of the SIGIR'04 work- shop on Search and Discovery in Bioinformatics . Ramesh M. Nallapati , Amr Ahmed, Eric P. Xing, and William W. Cohen. 2008. Joint latent topic models for text and citations. In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining , pp. 542 - 550. ACM. Vahed Qazvini an, and Dragomir R. Radev. 2008. Sci- entific paper summarization using citation sum- mary networks\",\n",
       " 'In Proceedings of the 22nd Inter- national Conference on Computational Linguistics - Volume 1 , pp. 689 -696. Association for Computa- tional Linguistics . You Ouyang , Sujian Li, and Wenjie Li. 2007. Devel- oping learn ing strategies for topic -based summari-zation. In Proceedings of the sixteenth ACM con- ference on Conference on information and knowledge management , pp. 79 -86. ACM . Dragomir Radev , Timothy Allison, Sasha Blair - Goldensohn, John Blitzer, Arda Celebi, S tanko Dimitrov, Elliott Drabek et al. 2004. MEAD -a plat- form for multidocument multilingual text summa- rization. Proceedings of the 4th International Con- ference on Language Resources and Evaluation (LREC 2004) . Ariel S. Schwartz , and Marti Hearst. 2006. Summariz- ing key concepts using citation sentences',\n",
       " 'In Proceedings of the Workshop on Linking Natu- ral Language Processing and Biology: Towards Deeper Biological Literature Analysis , pp. 134 -135. Association for Comp utational Linguistics . Dou Shen , Jian-Tao Sun, Hua Li, Qiang Yang, and Zheng Chen. 2007. Document Summarization Us- ing Conditional Random Fields. In IJCAI , vol. 7, pp. 2862 -2867 . Andreas Stolcke , Klaus Ries, Noah Coccaro, Eliza- beth Shriberg, Rebecca Bates, Daniel Jurafsky, Paul Taylor, Rachel Martin, Carol Van Ess - Dykema, and Marie Meteer. 2000. Dialogue act modeling for automatic tagging and recognition of conversational speech. Computational linguis- tics 26, no. 3 : 339 -373. Kristian Woodsen d, and Mirella Lapata. 2012. Multi- ple aspect summ arization using integer linear pro- gramming',\n",
       " 'In Proceedings of the 2012 Joint Con- ference on Empirical Methods in Natural Lan- guage Processing and Computational Natural Language Learning , pp. 233 -243. Association for Computational Linguistics . Shasha Xie, Benoit Favre, Dilek Hakkani -Tü r, and Yang Liu. 2009. Leveraging sentence weights in a concept -based optimization framework for extrac- tive meeting summarization. In INTERSPEECH , pp. 1503 -1506 . Hui Yang , and Jamie Callan. 2009. A metric -based framework for automatic taxonomy induction. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th Interna- tional Joint Conference on Natural Language Pro- cessing of the AFNLP: Volume 1 -Volume 1 , pp. 271-279. Association for Computation al Linguis- tics. Ozge Yeloglu , Evangelos Milios, and Nur Zincir - Heywood',\n",
       " '2011. Multi -document summarization of scientific corpora. In Proceedings of the 2011 ACM Symposium on Applied Computing , pp. 252 -258. ACM . 1633',\n",
       " 'Vol.:(0123456789)Scientometrics (2020) 125:3159–3185 https://doi.org/10.1007/s11192-020-03630-2 1 3 Automatic related work section generation: experiments in scientific document abstracting Ahmed AbuRa’ed1 · Horacio Saggion1 · Alexander Shvets1 · Àlex Bravo1 Received: 9 November 2019 / Published online: 24 July 2020 © Akadémiai Kiadó, Budapest, Hungary 2020 Abstract Related work sections or literature reviews are an essential part of every scientific article being crucial for paper reviewing and assessment. However, writing a good related work section is an activity which requires considerable expertise to identify, condense/summa-rize, and combine relevant information from different sources. In this work we compare different automatic methods to produce “descriptive” related work sections given as input the set of papers which need to be described',\n",
       " 'The main contribution of our work is a neural sequence learning process which produces citation sentences to be included in a related work section of an article. We train the neural architecture using an available scientific data set of citation sentences and we test over a data set of related work sections; we also compare the performance to a set of baseline extractive summarizers, an abstractive sum- marizer and a state of the art CNNs approach. Our results indicate that our approach out-performs the simple as well as the informed baselines',\n",
       " 'Keywords Scientific summarization · Document abstracting · Sequence learning · Information extraction from scientific literatureMathematics Subject Classification 68T50 · 97R40 CR Subject Classification I.2.7 * Ahmed AbuRa’ed ahmed.aburaed@upf.edu Horacio Saggion horacio.saggion@upf.edu Alexander Shvets alexander.shvets@upf.edu Àlex Bravo alex.bravo@upf.edu 1 Universitat Pompeu Fabra, Barcelona, Spain3160 Scientometrics (2020) 125:3159–3185 1 3 Introduction Every scientific paper should include a related work section providing, in a well organ- ized and condensed form, the key information from a carefully selected list of publications which contextualize and ground the research being presented by Rowley and Slack (2004)',\n",
       " 'Moreover, their relevance is critical for quality assessment since journals pay particular attention to related work sections where evaluation of manuscripts is of concern (Maggio et al. 2016). The reason why a scientific paper should include a related work section is motivated by the fact that scientific research is a collective activity. The work of research-ers depends on knowledge accumulated by scientists and scholars over years of research. Therefore, an author often needs to describe related previous works for the readers to help them understand the context of his or her contributions in an area of research, also facilitat- ing any form of comparison between the current and previous works. Good related work sections are difficult to produce since they require the author to select, contrast, and organ-ize key information from several sources. It is generally agreed that related work sections or literature reviews can either be descriptive or integrative (Khoo et al. 2011; Jaidka et al. 2013)',\n",
       " 'While a descriptive report will summarize individual papers providing infor - mation such as methods and results in citation sentences, integrative reports will focus on key ideas and topics, providing in the citation sentences critical views on the presented approaches. In a context where scientific information is growing at an unprecedented pace, related work sections or literature reviews offer already digested information ready to be used by researchers interested in getting a gist of the state of the art. Automatically gener - ating this type of text, that is selecting and combining key information from a set of arti- cles, could greatly help researchers in coping with the problem of scientific information overload. In this paper we are concerned with the automatic production of descriptive related work sections from a set of selected papers. We do not attempt to generate integrative reviews since they will require knowledge difficult to encode in an automatic process. Moreover, recommending a pre-selection set of scientific papers to be included in the report is outside the scope of this paper',\n",
       " 'To further investigate possible ways of compiling a list of scientific papers to cite, see McNee et al. (2002). Past research has shown that descriptive related work sections usually bring and com- bine information from titles, abstracts, and introductions of the cited articles making use of cut-and-paste summarization strategies (Jaidka et al. 2013) which are typical of abstracting a document (insertion, deletion, substitution, etc.) (Endres-Niggemeyer et al. 1995; Sag- gion 2011). These observations motivate our generative approach to the automatic produc- tion of related work sections. Taking advantage of an available data set for scientific summarization composed of research articles, citation sentences, and human summaries we train a sequence-to- sequence model to simulate the generation of citation sentences',\n",
       " 'We concatenate cita- tion sentences automatically generated from each cited paper to produce a novel related work section which we evaluate by comparing the generated texts to the gold related work section using content-based evaluation metrics. The comparison is carried out with our abstractive approach, several baselines, unsupervised summarizers, and an extractive state of the art neural networks approach. To model our generative approach, we make use of pointer–generator neural networks (Vinyals et al. 2015a) which are sequence-to-sequence models that produce an output sequence consisting of elements from the input sequence. We use the pointer–generator 3161 Scientometrics (2020) 125:3159–3185 1 3 networks with two Neural Networks (NN) architectures which have recently achieved good performance in complicated tasks; Transformer (Vaswani et al',\n",
       " '2017), that uses stacked self-attention and point-wise fully connected layers for both the encoder and decoder, and Bi-Directional RNNs, more specifically, in Kalchbrenner and Blunsom (2013), Sutskever et al. (2014), Cho et al. (2014) it is introduced as a variation of RNNs called sequence-to- sequence (seq2seq) learning which uses recurrent neural networks to map variable-length input sequences to variable-length output sequences. While relatively new, the sequence- to-sequence approach has achieved state-of-the-art results in not only its original appli- cation—machine translation—(Luong and Manning 2015; Jean et al. 2014; Luong et al. 2015; Jean et al. 2015; Luong et al. 2014), but also image caption generation (Vinyals et al. 2015b), and text summarization (Nallapati et al. 2016)',\n",
       " 'Sequence-to-sequence learning aims to indirectly model the conditional probability p(y|x) of mapping an input sequence, x=x1,…,xn , into an output sequence, y=y1,…,ym accomplishing such goal through the encoder–decoder framework proposed by Sutskever et al. (2014), Cho et al. (2014). We use sequence-to-sequence architecture to generate each citation sentence to be included in the related work section from an input sequence which is composed of a title and an abstract of a scientific paper that is being cited. To directly tackle the problem of producing a related work section, we use a gold-stand- ard data set of related work sections and their cited papers to test our approach. We feed our model with a set of sentences from the cited papers and accumulate the generated cita- tion sentences to produce a related work section',\n",
       " 'The contributions of our work are the following: • The design and evaluation of an abstractive related work section generation system; • A new data set of over 15K pairs of articles and citation sentences to train sequence-to-sequence models; • A comparison with state-of-the-art methods showing the potential of the approach. Software and data are being made available to guarantee reproducible research.1 The rest of the paper is organized as follows: In the next section we give an overview of related work in the broader area of scientific text summarization and in the more focused problem of related work section generation. Then in “Data” section we describe the data sets created and/or used in our experiments while in “Methodology” section we describe the method used for our sequence-to-sequence system. “Experiments” section describes the experi- ments carried out, “Results” section presents the obtained results while in Sect. “Limita- tions” section of the study are highlighted',\n",
       " 'Finally, we close the paper in “Conclusion” section with conclusions and avenues for further research. Related work Related work for our research refers to the broad topic of scientific text summarization as well as to the more targeted generation of related work reports. Summarization of scientific and technical articles has been studied for a long time (Saggion and Poibeau 2013). Early approaches to single document summarization of scientific input has been addressed with 1 https ://githu b.com/Ahmed AbuRa ed/SPSeq 2Seq.3162 Scientometrics (2020) 125:3159–3185 1 3 sentence classification (Teufel and Moens 2002), domain specific pattern-based matching and extraction (Oakes and Paice 1999), or generic information extraction and text genera- tion techniques (Saggion and Lapalme 2002). More recently, multi-document summariza- tion of scientific texts took center stage',\n",
       " 'Agarwal et al. (2011) tackled the multi-document summarization of scientific articles using an unsupervised method which discovers com- parable attributes in co-cited articles using Frequent Term Based Clustering (Beil et al. 2002). Discovered clusters are used to rank and extract sentences for the summary. Qazvin- ian et al. (2013) proposed C-LexRank, a graph-based summarization method which relies on implicit as well as explicit citation sentences to summarize a given cited paper. They cluster the citation sentences extracting the most relevant from each cluster using differ - ent procedures. Jha et al. (2013) implemented a simliar system but to generate a survey of a given topic. Their approach identifies different aspects of the scientific paper extracting representative sentences for each aspect. Mohammad et al',\n",
       " '(2009) performed experiments to show the helpfulness of citation text to automatically generate technical surveys while (Ronzano and Saggion 2016) using data from the BioSumm 2014 Challenge studied per - formance gains when using citation sentences to summarize a scientific article. Recent approaches to abstractive summarization include the following. Bražinskas et al. (2019) has addressed opinions summarization in which they analyze multiple reviews from users over different products and businesses and then created text summaries that reflect subjective information expressed in these reviews. To overcome any rely on large quanti-ties of document-summary pairs as used in supervised abstractive summarization which are expensive to acquire, they used an unsupervised approach which uses a hierarchical variational auto-encoder (VAE) model and utilizes two sets of latent variables. A continu-ous variable that captures latent semantics of a group of reviews and a second continuous variable to encode latent semantics of each individual review in the group',\n",
       " 'The final sum- maries are produced by the decoder that uses the information stored at the second contin- ues variable. Chu and Liu (2018) also utilized an unsupervised abstractive summarization model that uses an auto-encoder where the mean of the representations of the input reviews (i.e. mean over the hidden and cell states of all the input reviews) decodes to a reasonable summary-review while not relying on any review-specific features. They implemented vari- ants of the proposed architecture and analyzed the different variants. Finally, Baziotis et al. (2019) also uses an unsupervised abstractive model to develop a sequence-to-sequence-to- sequence autoencoder ( SEQ3 ), where the first sequence is the input, the second sequence is the compressed sentence and the last sequence consists of reconstructed sentences. SEQ3 consists of two chained encoder-decoder pairs, with words used as a sequence of discrete latent variables',\n",
       " 'In contrast with generic summarization, related work section generation - summariza- tion has not been so extensively explored. Hoang and Kan (2010), Vu (2010) presented an automatic related work summarization system which creates a topic-biased related work section for a target paper given multiple scientific articles. The extractive approach requires the user to provide a topic hierarchy tree as an input and a set of papers to summarize. The method, which improves over generic multi-document summarization approaches, com-putes the likelihood of each sentence in the input documents to belong to the topics as a method for selection. Hu and Wan (2014) investigated the task of producing a related work section for a target paper given as input a set of reference papers along with a target academic paper but ignor - ing its related work section',\n",
       " 'Their system exploits Probabilistic Latent Semantic Analysis (PLSA) (Hofmann 1999) to divide the set of sentences of the given papers into different topic-biased parts applying regression models to learn the ranking of the sentences. Finally, 3163 Scientometrics (2020) 125:3159–3185 1 3 an optimization framework is used to produce the related work section. In order to reduce the amount of text to consider, they make use of the abstract, introduction, related work and conclusion sections from the reference papers, since according to them other sections corresponding to method, evaluation or any other sections always describe in too much details any specific work and they are not suitable for this task. Jaidka et al. (2013) estab- lished a literature review framework by deconstructing human-written literature review sections of information science research papers',\n",
       " 'They studied scientific papers to be able to compare them, to identify new problems, to place a work inside the current literature and to elaborate new research propositions. Their study offers the results of a multi-level discourse analysis to examine their discourse and content features. A framework for litera- ture reviews created focusing on macro-level document structure, sentence-level templates, and information summarization strategies. Zhang et al. (2018) proposed a latent variable extractive model that views labels of sentences in a document as binary latent variables. The latent model maximizes the likelihood of human summaries given selected sentences where loss comes directly from gold summaries. They modeled instances of sequence labe- ling in which a document is viewed as a sequence of sentences and the model is expected to predict a true or false label for each sentence, where true indicates that the sentence should be included in the summary',\n",
       " 'Their system has three parts: a sentence encoder to convert each sentence into a vector, a document encoder to learn sentence representations given surrounding sentences as context, and a document decoder to predict sentence labels based on representations learned by the document encoder. Finally, they use CNN/Dailymail data set (Hermann et al. 2015) for their experiments and they compare their system with other extractive and abstractive systems. Lastly, an hybrid method for summarization of multiple related work sections of scientific articles has recently been proposed (Altmami and Menai 2018). In this work a semantic graph-based approach is used to handle the redundancy of citation sentences by reducing the sentence graph while preserving its properties. Using cross-document structure theory (CST) to analyze multi-documents i.e. related work sec- tion, they discover semantic relations to further reduce redundancy in the set of citation sentences. Most reviewed approaches to related work section generation are based on an extractive paradigm',\n",
       " 'Extractive approaches, while offering the advantages of producing readable sen-tences, are clearly limited to address the challenges of producing citation sentences which are generally non-literal versions of information found in the input document. Moreover, citations sentences sometimes combine fragments from different sentences which can not be dealt with extractive approaches. These limitations could be addressed by applying non- extractive techniques as the ones we present in the rest of this article, which although still preliminary can pave the way for further research in this area. Data We make use of two different types of data: a data set of scientific papers and their citation sentences that we use to train our citation sentence generation model, and a gold-standard data set of related work sections and their cited papers to test the whole process. The test- ing data set has been used in previous work (Hoang and Kan 2010; Vu 2010), and has been considerably expanded by AbuRa’ed et al',\n",
       " '(2020) who processed the data set and manually mapped the sentences of the cited papers with the sentences in related work sections citing 3164 Scientometrics (2020) 125:3159–3185 1 3 them.2 Additionally, we study the effect of a filter over the data sets in order to select sen- tences which explicitly indicate the author’s work. Training datasets We make use of the data available in the ScisummNet Corpus (Yasunaga et al. 2019). This corpus is being released by Yale LILY lab and expanded from the CL-Scisumm project (Mayr et al. 2019; Jaidka et al. 2014). This dataset provides over 1000 papers of the Asso- ciation for Computational Linguistics (ACL) anthology network (Bird et al. 2008) with their citation networks (e.g. citation sentences, citation counts) and their author abstracts',\n",
       " 'Additionally, we collect data similar to ScisummNet but from Open Academic Graph (OAG) and Microsoft Academic Graph (MAG) (Sinha et al. 2015; Tang et al. 2008). MAG is a diverse graph containing scientific publication records, citation relationships between those publications, as well as authors, institutions, journals, conferences, and fields of study. OAG is a large knowledge graph unifying two billion records from two academic graphs: Microsoft Academic Graph (MAG) and AMiner (Tang 2016). We used the avail- able OAG dumps to gain access to the list of all paper IDs at MAG. Afterward, we used Microsoft Cognitive Services Academic Knowledge API to access MAG nodes. The obtained papers were kept if and only if: (i) MAG contained an abstract for the paper and (ii) MAG contained at least one of the papers being cited',\n",
       " 'The references of the stored papers were extracted to iteratively obtain more data, storing papers only if conditions (i) and (ii) were satisfied. All the collected data, which will be released with this paper, 3 has been indexed for efficient processing. The collected data amounts to: 940 pairs from Sci- summNet Corpus and 15,574 pairs from our new dataset. In summary, our data from these two sources consists of pairs of input and output sequences as follows: Where the i-th input sequence is a concatenation ( ⊕ ) of a scientific paper’s title Ti and abstract Ai , as for the output sequence we use the citation sentence Ci used by the citing scientific paper. For further analysis we also applied a filter on the same data which selects sentences from the abstract that are directly related to the scientific paper author or presentation. The filter is based on Teufel’s (Teufel et al. 2000) first pronoun (e.g',\n",
       " 'we, our and my) and pres- entation nouns (e.g. this paper, study and article) gazetteers. The filter is only applied to the abstract sentences (the title is never removed). The resulting sentences from the filter process are the title and abstracts’ sentences that contain any of the first pronoun and pres- entation nouns',\n",
       " 'This process will exclude any sentences that do not explicitly mention the authors nor the presented work directly.(1) <Ti⊕Ai,Ci> 3 The dataset can be accessed though this link: https ://githu b.com/Ahmed AbuRa ed/SPSeq 2Seq.2 http://taln.upf.edu/scien cecor pus.3165 Scientometrics (2020) 125:3159–3185 1 3 Table 1 Example of a scientific article (title ⊕ (non-filtered) abstract) and a citation sentence Similar phrases have been highlightedTitle An Unsupervised Method For Detecting Grammatical Errors Abstract We present an unsupervised method for detecting grammatical errors by inferring negative evidence from edited textual corpora. The system was developed and tested using essay-length responses ...The error-recognition system, ALEK, performs with about 80% precision and 20% recall Cit. sent',\n",
       " 'Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evi- dence from edited textual corpora achieving high precision but low recall Table 2 Example of a filtered scientific article (title ⊕ filtered abstract) and a citation sentence Similar phrases have been highlightedTitle An Unsupervised Method For Detecting Grammatical Errors Abstract We present an unsupervised method for detecting grammatical errors by inferring negative evidence from edited textual corpora Cit. sent. Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evi- dence from edited textual corpora achieving high precision but low recall 4 Cited paper: Martin Chodorow and Claudia Leacock. 2000. An unsupervised method for detecting grammatical errors. In Proceedings of the 1st North American chapter of the Association for Computa-tional Linguistics conference (NAACL 2000)',\n",
       " 'Association for Computational Linguistics, Stroudsburg, PA, USA, 140–147. Citing paper: Chung-Chi Huang, Mei-Hua Chen, Shih-Ting Huang, Jason S. Chang. EdIt: A Broad-Coverage Grammar Checker Using Pattern Grammar. Proceedings of the ACL-HLT 2011 System Demonstrations.An example of the data used for training the citation sentence generator is shown in Table 1. In the example,4 the citation sentence contains some literal (e.g. “negative evi- dence from edited textual corpora”) and non-literal (e.g. “high precision” instead of “80% precision” or “checkers” instead of “detecting grammatical errors”) elements extracted from title and abstract of the cited work. From the set of citation sentences available for each paper we use the one that is most similar (closest) to title and abstract in terms of the BLEU score measure (Papineni et al',\n",
       " '2002) used to compare a target and source translations. A similar example showing the filtered version of the previous example can be seen in Table 2. We can notice that after applying the filter process most of the shared phrases are still present. Testing data set In order to test our approach, we make use of a data set previously used for related work generation (Hoang and Kan 2010; Vu 2010), the RWSData corpus, which contains a col- lection of 20 article sets (i.e. Clusters). Each set contains a scientific paper with a related 3166 Scientometrics (2020) 125:3159–3185 1 3 work section, the text of the related work section and the set of reference papers mentioned in the related work section, See Fig',\n",
       " '1 which represents a segment of a related work section for a scientific paper in the corpus5 that is citing three different scientific papers.6,7,8 Since the papers provided in RWSData are all in PDF and in order to extract the nec- essary information from them, AbuRa’ed et al. (2020) used three state-of-the-art PDF to XML converters: PDF Digest (Ferrés et al. 2018), PDFX (Constantin et al. 2013) and Fig. 1 Example from the RWSData corpus of a scientific paper citing three other scientific papers 5 Kong, Fang, Hwee Tou Ng, and Guodong Zhou. ”A constituent-based approach to argument labeling with joint inference in discourse parsing.” In Proceedings of the 2014 Conference on Empirical Methods in Nat- ural Language Processing (EMNLP), pp. 68–77, 2014. 6 Ben Wellner and James Pustejovsky (2007)',\n",
       " 'Automatically identifying the arguments of discourse con- nectives. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Process-ing and Computational Natural Language Learning, pp. 92–101. 7 Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Rashmi Prasad, Aravind Joshi, and Bonnie Webber (2005) Attribution and the (non-)alignment of syntactic and discourse arguments of connectives. In Proceedings of the Workshop on Frontiers in Corpus Annotation II: Pie in the Sky, pp. 29–36 8 Sucheta Ghosh, Richard Johansson, Giuseppe Riccardi, and Sara Tonelli (2011) Shallow discourse pars- ing with conditional random fields. In Proceedings of the 5th International Joint Conference on Natural Language Processing, pp',\n",
       " '1071–1079.3167 Scientometrics (2020) 125:3159–3185 1 3 Grobid (GRO 2008–2019). Whenever one of the converters failed to convert the PDF doc- ument we moved to next one as a fail safe, using this procedure allowed us to convert all the documents in the dataset and extract the necessary information for testing our system. The three converters provide basic information about each scientific paper including: title, abstract and content. Then, using the GATE system (Maynard et al. 2002) we automatically annotated (and manually checked) each citation sentence in the related work section of the target scientific paper linking it with its cited paper. Finally, the same filtering process applied on the training data set was applied for the testing data set. Methodology Our approach is based on pointer–generator neural networks with copy-attention technique and coverage mechanism (See et al. 2017; Wu et al. 2016)',\n",
       " 'Copy-based generation can copy words from the source text via pointing, which aids accurate reproduction of infor - mation while retaining the ability to produce novel words through the generator. As for coverage (Wu et al. 2016), it is a mechanism to keep track of what has been summarized discouraging repetition by forcing penalties on repeated text therefore controlling redun- dancy of the generated output. We utilize pointer–generator neural networks with two different architectures; Bidi- rectional Recurrent Neural Networks (BRNN) (Schuster and Paliwal 1997) which maps a source sequence to a target sequence, and Transformers (Vaswani et al. 2017); where the closest model to the one we use is so-called CopyTransformer proposed in Gehrmann et al. (2018). See Fig. 2 which shows the pointer–generator neural network used with the BRNN architecture',\n",
       " 'For each decoder time-step a generation probability Pgen∈[0, 1] is calculated, which weights the probability of generating words from the vocabulary, versus copying words from the source text. The vocabulary distribution and the attention distribution are weighted and summed to obtain the final distribution, from which we make our prediction. Fig. 2 The pointer–generator architecture3168 Scientometrics (2020) 125:3159–3185 1 3 The figure presents an example of a scientific paper at the input text9 being cited by another scientific paper10 and the network is trying to generate the next token for the citation con- text (summary) in which the next token to be generated by the decoder is “speech” which has the highest attention in the attention distribution. Sequence-to-sequence models are particularly good at translation, where the sequence of words from one language is transformed into a sequence of different words in another language',\n",
       " 'However, summarization can, in certain cases, be casted as sequence-to- sequence modeling to summarize a long source into a shorter one in the same language to form the final output summary. We use BRNN (Schuster and Paliwal 1997) as can be noticed at Fig. 2 which is a nat- ural generalization of feed-forward neural networks where the source sequence tokens are fed one-by-one into a single-layer of a bidirectional LSTM (encoder), producing a sequence of encoder hidden states hi . On each step t, a single-layer of a unidirectional LSTM receives the word embedding of the previous word (while training, this is the pre- vious word of the reference summary; at test time it is the previous word emitted by the decoder), and has decoder state st . We also applied the transformer (Vaswani et al. 2017)— encoder–decoder–based architecture—for ”translating” one sequence into another one as a basis',\n",
       " 'This architecture uses stacked self-attention and point-wise fully connected layers for both the encoder and decoder. See the model architecture at Fig. 3 which we use with the pointer–generator neural network separately replacing the BRNN architecture. The encoder is composed of a stack of N identical layers. Each layer has two sub-layers. The first is a multi-head, self-attention mechanism, and the second is a simple, position wise fully connected feed-forward network. The decoder is also composed of a stack of N identical layers. In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack',\n",
       " 'The transformer uses a self-attention layer by adding a mechanism called ”multi-headed” atten- tion expanding the model’s ability to focus on different positions of the input, giving the attention layer multiple ”representation subspaces” for the weight matrices, and allowing selection of important parts of the sequence at each step to adjust the distribution over the vocabulary which is essential while summarizing. We rely on the Neural Machine Translation (NMT) tool OpenNMT-py (Klein et al. 2017) to implement our abstractive models. OpenNMT is an open source initiative for NMT and neural sequence modeling. It is a general-purpose attention-based sequence- to-sequence system that also implements the latest state-of-the-art sequence-to-sequence techniques. 9 Cited paper: Brill, Eric. ”A simple rule-based part of speech tagger.” In Proceedings of the third con- ference on Applied natural language processing, pp. 152–155',\n",
       " 'Association for Computational Linguistics, 1992 10 Citing Paper: Modi, Deepa, and Neeta Nain. ”Part-of-Speech Tagging of Hindi Corpus Using Rule- Based Method.” In Proceedings of the International Conference on Recent Cognizance in Wireless Com-munication and Image Processing, pp. 241–247. Springer, New Delhi, 2016.3169 Scientometrics (2020) 125:3159–3185 1 3 Experiments In order to compare our approach, we implemented several baselines over the RWSData. Alongside, we ran several experiments to generate abstractive summaries for each cluster i.e. a related work section for a target paper. Fig. 3 The transformer model architecture: encoder to the left and decoder to the right3170 Scientometrics (2020) 125:3159–3185 1 3 Baselines For our experiments we implemented several extractive summarization baselines',\n",
       " 'A set of simple baselines is based on the observations arising from the analysis of citation sentences and scientific abstracts on the use of titles and abstracts (Jaidka et al. 2013; Saggion 1999). The title baseline is to use the title of each cited article as citation sentences. The abstract first baseline uses as citation sentences the first sentence of the abstract of the cited articles while the abstract last baseline uses the last sentence. The second set of baselines is composed of available systems that use well-established extractive techniques. All summarizers are given as input the title and abstract of a cited documents from which a single summary sentence is obtained. They are as follows: • MEAD (Radev et al. 2004) is a well-known extractive document summarizer which generates summaries using centroids alongside other features such as the position of the sentence and the length. We configured MEAD to select one sentence from each cited paper in order to generate the related work section',\n",
       " '• TextRank (Mihalcea and Tarau 2004) and LexRank (Erkan and Radev 2004) are both extractive and unsupervised graph-based text summarization systems which create sen- tence graphs in order to compute centrality values for each sentence. Both algorithms have similar underlying methods to compute centrality which are based on the PageR - ank ranking algorithm. They differ in how links are weighted in the document graph. • SUMMA (Saggion 2008) is a Java implementation of several sentence scoring func-tions. We use the implementation of the centroid scoring functionality to select the most central sentence in a document. • SEQ3 Baziotis et al. (2019) the unsupervised abstractive model named SEQ3 which used a sequence-to-sequence-to-sequence autoencoder was used as a recently proposed non-extractive technique',\n",
       " 'Extracting sentences with a convolutional neural network This system, which is based on a neural network architecture which achieved state of the art performance in the Sci-Summ 2018 Challenge (AbuRa’ed et al. 2018; Mayr et al. 2019), takes advantage of the potential of convolutions to abstract higher level features from sentences in order to learn its relevance in a specific document (AbuRa’ed et al. 2017, 2018). This relevance is based on the relationship between a set of features extracted and computed for each sentence and the scoring function. The system assigns a score between 0 (not relevant) and 1 (highly relevant). Extraction of sentence features The set of sentence features is organized into two inputs to feed the system. First, we transformed each word from a sentence into a vector by looking up word embeddings',\n",
       " 'In this scenario, we used two pre-trained word embeddings, which were concatenated: the Google News embeddings 11 (three million words in 300 dimensional vectors trained using word2vec (Mikolov et al. 2013a) over a news text corpus of 100 billion 11 https ://code.googl e.com/archi ve/p/word2 vec/.3171 Scientometrics (2020) 125:3159–3185 1 3 words) and the Association for Computational Linguistics (ACL) Anthology Reference Corpus embeddings (Liu 2017) (300 dimensional vector trained over a corpus of ACL papers Bird et al. 2008). This embedding matrix representing the words contained in a sentence is introduced in the system as input. In addition to word embeddings, for each sentence we extracted, using SUMMA (Saggion 2008; AbuRa’ed et al',\n",
       " '2018), features in order to provide information about its context in the document: • Sentence Document Similarity the cosine similarity of a sentence vector to the arti-cle centroid. • Title Sentence Similarity: the cosine similarity of a sentence vector to the vector of the first sentence, that is, the title of the RP. • TextRank Normalized a sentence vector is computed to obtain a normalized score using the TextRank algorithm (Mihalcea and Tarau 2004). • Position a score representing the position of the sentence in the article. • Normalized Cue-phrase the total number of cue-words in the sentence divided by the total number of cue-words in the article based on Teufel and Moens (2002) for - mulaic expressions. • Term Frequency we sum up the tf*idf values of all words in the sentence. Then, the obtained value is normalized using the set of scores from the whole document',\n",
       " '• Rhetorical Class Probability the probability that the sentence belongs to each of five rhetorical categories—background, outcome, approach, challenge, and future work (five features, one per each rhetorical category) according to the scientific document analyser Dr Inventor (Ronzano and Saggion 2015). To calculate the similarities and TextRank Normalized features, we computed three different vectors based on the sentence representations. A vector similarity is the result of comparing two vectors of the same type using the cosine distance function. From the previous input, we also used the Google and ACL pre-trained word embeddings to generate two sentence vectors by calculating the centroid (or average) of the words vectors contained in a sentence. The third vector is based on a SUMMA word vector (Saggion 2008), which is computed from the tf*idf of each word',\n",
       " 'Finally, the context features are also introduced in the system (as a second input) within a sequential window including the context features of the 3 previous and 3 fol-lowing sentences. Scoring functions The aim of the system is to learn a scoring function in order to select the most relevant sentences from a document (title + abstract). In other words, the system learns the relation between both set of features (word embeddings and context features) and a score, learning a regression task. In this work three scoring functions are defined related to the three sentence vectors (SUMMA, Google and ACL), which are basically based on the similarity between sen-tences in the document (title + abstract) and the gold citation sentence.3172 Scientometrics (2020) 125:3159–3185 1 3 Convolutional model The network independently decodes each input (word embeddings and context features) by convolutions to abstract higher level features',\n",
       " 'Each convolution applies a filter to produce a new feature, which is included in the resulting feature map. The convolution can be replicated with different windows with multiple filters giving multiple feature maps. Next, a max-pooling layer selects the most relevant feature from each feature map. Rel- evant features are concatenated together in a single feature vector. In order to prevent over- fitting, after max-pooling layer we applied dropout regularization over the single feature vector (Hinton et al. 2012). At this point, both single feature vectors generated by each input are also concatenated and the resulting vector is passed to two subsequent fully-connected layers. The fully-con- nected layers scale a large amount of features from the previous vector to a single output value, in order to learn the regression task. We also rescale the weights whose l2-norms exceed a hyperparameter as in Kim (2014) and Nguyen and Grishman (2015)',\n",
       " 'Sequence‑to‑sequence approach We feed our training sequences (see “Data” section) to the model and use the validation data to tune the hyper parameters and keep the learning rate in check during training. We have used 15,000 pairs for training, 1514 pairs for development and 219 pairs for testing. The final model is fed with the set of reference papers (titles and abstracts) in the testing dataset generating a citation context for each reference paper (see Fig. 4). Finally, we group the generated set of citations context together to form the final related work section. We ran all our experiments on both the Title and Abstract as described at “Data” section and the filtered version of the data. Training For our abstractive sequence-to-sequence approach we generated several models while training the data. We ran two separate encoder–decoder architectures i.e',\n",
       " 'Transformer and BRNN as mentioned at “Methodology” section with four recurrent layers for the trans- former architecture and one layer of Bi-Directional RNN. We set the hidden size of the Fig. 4 Generation of related work sections from a set of papers ( P1,…,Pn ) and evalu- ation. Model represents any of the sentence extraction/genera-tion systems tested in this work. Output citation sentences ( Ci ) are concatenated and compared to a gold standard related work section 3173 Scientometrics (2020) 125:3159–3185 1 3 recurrent unit to 512 and used ADAM (Kingma and Ba 2014) and AdaGrad (Duchi et al. 2011) optimizers respectively. We set the system to share the same weight vectors for shared vocabulary between the encoder and decoder and we add a sinusoidal position encoding to each vocabulary. This option drastically decreases the number of parameters a model has to learn',\n",
       " 'To further represent the sentences we not only rely on the internal representation of words by the OpenNMT-py (Klein et al. 2017) tool, but we also use word-based and character-based word2vec pre-trained models. These models will provide some insight of how changing the representation of the input could affect the results, for that reason we use GoogleNews (Mikolov et al. 2013a) (word-based) and FastText (Mikolov et al. 2018) (character-based) pre-trained models to run additional experiments for both the filtered and unfiltered data. Regarding batches and normalization, there are two types of batches; sentence based and token based. Sentence based batching sets the batch size based on the number of instances (sentences), while token based batching is also known as dynamic batching due Fig. 5 The neural network accuracy over training and validation data over time Fig',\n",
       " '6 Perplexity of generated strings at different training points3174 Scientometrics (2020) 125:3159–3185 1 3 Table 3 Example of a scientific article (title ⊕ abstract) and a grammatically correct generated citation sen- tence with considerable “matching” content Title Measuring Semantic Similarity by Latent Relational Analysis Abstract This paper introduces latent relational analysis (lra), a method for measuring semantic similarity. this paper describes ...classifying semantic relations in noun modifier expres- sions. this paper has introduced a new method for calculating relational similarity, latent relational analysis. just as attributional similarity measures have proven to have many practical uses, ... Gen. cit',\n",
       " '<CITE> describes a method (latent relational analysis) that extracts subsequence pat- terns for noun pairs from a large corpus, using query expansion to increase the recall of the search and feature selection and dimensionality reduction to reduce the complexity of the features Table 4 Example of a scientific article (title ⊕ abstract) and an incoherent generated citation sentence Title Extracting structural Paraphrases From Aligned Monolingual Corpora Abstract We present an approach for automatically learning paraphrases from aligned monolin- gual corpora. we present an approach for automatically learning paraphrases ...our algorithm works by generalizing the syntactic paths between corresponding anchors in aligned sentence pairs...we also describe a novel information retrieval system under development that is designed to take advantage of structural paraphrases Gen. cit',\n",
       " '<CITE> proposed a information based approach to select monolingual paraphrases of a paraphrases in the sentence paths of a sentence paths to reduce the monolingual rules of paraphrases and penn variations to be identified to the fact that a batch is created based on a specific number of tokens. The motivation behind dynamic batching is to avoid any memory problems for sentences that are consid- ered long, it is usually used with greedy algorithms such as the Transformer’s multi-head attention technique. For our experiments we batch and normalize based on dynamic batch-ing of size 4096 tokens for the Transformer architecture. As for the BRNN we batch and normalize based on sentence batching of size 16. We set the network to compute gradients and update the parameters after each set of batches. Moreover, we initialized with Xavier uniform (Glorot and Bengio 2010) and used 0.2 dropout (Srivastava et al. 2014) mecha- nism to prevent over-fitting',\n",
       " 'We set the network to save models over time, every K steps a model is saved and tested against the validation data generating a total of ten models. See Fig. 5 which highlights the accuracy of the network at each check point (Trans is a short for Transformer). The figure shows the accuracy over the training and validation steps for the BRNN and Transformer models over the filtered (denoted as F) and unfiltered data. The BRNN models tend to have a slower and more consistent training accuracy improvements over the transformer models, the slowest learning process were recorded over the filtered data. As for validation accu- racy the transformer models are more consistent and stable over the validation data. Finally the validation accuracy of both models have a higher accuracy over the filtered data.3175 Scientometrics (2020) 125:3159–3185 1 3 Finally, we used a learning rate decay managed under the ”noam” scheme (Goyal et al',\n",
       " '2017) (linear warm-up for a given number of steps followed by exponential decay of the learning rate). Testing We ran the testing sequences over the models generated at each check point. The network reported the perplexity scores (Jelinek et al. 1977) at each check point (See Fig. 6) which shows that the Transformer models has less perplexity measures than the BRNN. The generated sentences from our system varied between readable sentences and sen- tences that were not acceptable, but shared common words with the title and abstract of the cited scientific paper. An example of a good generated citation for a paper in the test set12 is shown in Table 3. An example of a bad generated citation for a testing paper13 in shown in Table 4',\n",
       " 'Even though the generated citation is not very readable due to the inclusion of several “main“ verbs without proper syntactic structure, some relevant keywords have been selected.Table 5 Extractive baseline systems VS abstractive sequence- to-sequence system ROUGE-1 and ROUGE-2 Metrics Bold values indicate the highest number in each column System ROUGE-1 ROUGE-2 R P F R P F Titles 0.074 0.375 0.119 0.013 0.072 0.022 AbsFS 0.126 0.272 0.155 0.019 0.041 0.023 AbsLS 0.114 0.263 0.150 0.013 0.035 0.018 SUMMA 0.130 0.236 0.158 0.019 0.026 0.020 MEAD 0.247 0.215 0.219 0.067 0.042 0.048 LexRank 0.162 0.306 0.194 0.029',\n",
       " '0.044 0.032 TexRank 0.211 0.232 0.207 0.043 0.038 0.038 SEQ3 0.045 0.140 0.066 0.0004 0.002 0.0007 CNNSUMMA 0.163 0.262 0.187 0.030 0.047 0.034 CNNGoogle 0.191 0.261 0.207 0.034 0.0413 0.034 CNNACL 0.176 0.246 0.195 0.035 0.041 0.035 TransformerCB 0.216 0.237 0.215 0.072 0.063 0.063 BRNNCB 0.189 0.293 0.219 0.054 0.070 0.058 TransformerWB 0.221 0.248 0.222 0.070 0.062 0.062 BRNNWB 0.179 0.266 0.204 0.044 0.055 0.046 Transformer 0.192',\n",
       " '0.255 0.219 0.066 0.071 0.069 BRNN 0.223 0.238 0.230 0.069 0.072 0.070 12 Cited paper: Turney, Peter D',\n",
       " '”Measuring semantic similarity by latent relational analysis.” arXiv pre- print cs/0508053 (2005). 13 Cited paper: Ibrahim, Ali, Boris Katz, and Jimmy Lin. ”Extracting structural paraphrases from aligned monolingual corpora.” Proceedings of the second international workshop on Paraphrasing-Volume 16. Association for Computational Linguistics, 2003.3176 Scientometrics (2020) 125:3159–3185 1 3 Figure 7 shows the entire pipeline of our experiments. We experimented on title and abstract of scientific papers and we also applied a filter based on Teufel’s (Teufel et al. 2000) gazetteers producing a title + filtered abstract. As for the representation of the sentences, we used the internal representation by OpenNMT-py, word-based Word2Vec pre-trained model (i.e. GoogleNews) and character-based word2vec pre-trained model (i.e. FastText)',\n",
       " 'The input source is fed to the pointer generator architecture (BRNN or Transformer) which generates a summary (i.e. citation context) based on the presenta- tion of sentences.Table 6 Extractive Baseline Systems VS Abstractive Sequence-to-Sequence System Over the Filtered Data',\n",
       " 'ROUGE-1 and ROUGE-2 metrics Bold values indicate the highest number in each column System ROUGE-1 ROUGE-2 R P F R P F Titles 0.074 0.375 0.119 0.013 0.072 0.022 AbsFS 0.118 0.271 0.150 0.019 0.043 0.024 AbsLS 0.115 0.265 0.146 0.014 0.036 0.019 SUMMA 0.142 0.288 0.180 0.022 0.040 0.027 MEAD 0.216 0.239 0.203 0.038 0.037 0.034 LexRank 0.138 0.292 0.172 0.024 0.038 0.028 TexRank 0.222 0.236 0.210 0.041 0.036 0.035 SEQ3 0.068 0.158 0.091 0.003 0.006 0.004 CNNSUMMA',\n",
       " '0.118 0.250 0.146 0.018 0.038 0.023 CNNGoogle 0.182 0.234 0.187 0.035 0.038 0.033 CNNACL 0.187 0.239 0.193 0.037 0.042 0.037 TransformerCB 0.276 0.267 0.271 0.120 0.092 0.104 BRNNCB 0.286 0.314 0.299 0.122 0.108 0.115 TransformerWB 0.274 0.276 0.275 0.118 0.092 0.103 BRNNWB 0.284 0.317 0.300 0.120 0.107 0.113 Transformer 0.261 0.251 0.256 0.116 0.088 0.100 BRNN 0.281 0.298 0.289 0.117 0.100 0.108 Fig',\n",
       " '7 An outline of the performed experiments showing the different scenarios we used over our approach3177 Scientometrics (2020) 125:3159–3185 1 3 Results In this section we compare our abstractive sequence-to-sequence approaches with the baselines. We used several ROUGE metrics (Lin 2004) to automatically evaluate all the systems. The metrics used from ROUGE are: ROUGE-L: which uses the Longest Table 7 Comparison of filtered versus non-filtered ROUGE-1 results with two-tailed t-test(20) Mean, standard deviation (SD), and p-values (sig.) are reported † in the significance column indicates if a difference was found System Filtered Non-filtered Sig',\n",
       " 'Mean SD Mean SD BRNN 0.28 0.002 0.23 0.0008 1×10−4† BRNNCB 0.29 0.002 0.21 0.0009 9.86×10−7† BRNNWB 0.30 0.002 0.20 0.001 2×10−8† Transf 0.25 0.003 0.21 0.0005 0.01† TransfCB 0.27 0.001 0.21 0.001 2.39×10−6† TransfWB 0.27 0.001 0.22 0.001 2×10−6† CNNSUMMA 0.14 0.001 0.18 0.003 8×10−4† CNNGoogle 0.18 0.001 0.20 0.003 0.14 CNNACL 0.19 0.001 0.19 0.002 0.86 SUMMA 0.18 0.001',\n",
       " '0.15 0.001 0.01† MEAD 0.20 0.004 0.21 0.003 0.2 LexRank 0.17 0.001 0.19 0.003 0.09 TextRank 0.21 0.002 0.20 0.002 0.78 Table 8 Comparison of filtered versus non-filtered ROUGE-2 results with two-tailed t-test(20) Mean, standard deviation (SD), and p-values (sig.) are reported † in the significance column indicates if a difference was found System Filtered Non-filtered Sig',\n",
       " 'Mean SD Mean SD BRNN 0.10 0.002 0.07 0.0003 8×10−2† BRNNCB 0.11 0.002 0.058 0.0003 1.6×10−4† BRNNWB 0.11 0.002 0.047 0.002 2.45×10−6† Transf 0.10 0.002 0.069 0.0002 1.6×10−2† TransfCB 0.10 0.0018 0.063 0.0002 1×10−3† TransfWB 0.10 0.002 0.62 0.0001 7×10−4† CNNSUMMA 0.023 0.0001 0.034 0.0005 0.02† CNNGoogle 0.035 0.0003 0.034 0.0005 0.83 CNNACL 0.037 0.0005 0.035 0.0007',\n",
       " '0.77 SUMMA 0.027 0.00027 0.019 0.0001 0.09 MEAD 0.034 0.00098 0.049 0.00076 2×10−3† LexRank 0.028 0.0002 0.032 0.0002 0.39 TextRank 0.035 0.0004 0.038 0.00035 0.473178 Scientometrics (2020) 125:3159–3185 1 3 Common Subsequence (LCS) evaluating the structural similarity between two summa- ries therefore paying attention to syntax; ROUGE-1: which checks the overlap of each word between the automated summary and the gold standard paying attention to word content; ROUGE-2: similar to ROUGE-1 but at the level of bi-gram overlap; and finally ROUGE-SU4: which considers Skip-bigram plus unigram-based co-occurrence statis- tics',\n",
       " 'therefore considering long sequences as the basis for evaluation',\n",
       " 'ROUGE measures combine precision and recall in a harmonic F-measure which is generally used to assess the systems’ performance. The results of ROUGE-1 and ROUGE-2 metrics before filtering the data can be found at Table 5 and over the filtered data at Table 6. ROUGE-L and ROUGE-SU4 results are computed for the sake of completeness and provided in the Appendix in Tables 10 and 11 for unfiltered and filtered data respectively. As can be appreciated from the numbers in Tables 5, 6, 10 and 11 the non-informed extractive baselines which do not perform any analysis of the input (e.g. use of titles or sentences from abstracts) tend to have a high precision but low recall, specially pre- cise is the title',\n",
       " 'For all ROUGE measures, and disregarding of the status of the input data (filtered/non-filtered), the sequence-to-sequence models obtain the higher scores in terms of F-score (ROUGE-F). For precision and recall variants of ROUGE in the case of non-filtered data, we can observe that MEAD is better at Recall and LexRank at pre- cision, however not achieving the best F-score. This trend is not observed in the filtered Table 9 Comparison of ROUGE scores in BRNN and transformer systems under different embedding con- ditions using two-tailed t-test(20) Mean, standard deviation (SD), and p-values (sig.) are reported † in the significance column indicates if a difference was foundEmbedding BRNN Transf Sig',\n",
       " 'Mean SD Mean SD ROUGE-1 filtered None 0.28 0.002 0.25 0.003 1.09×10−6† Word 0.30 0.002 0.27 0.001 0.003† Character 0.29 0.002 0.27 0.001 0.0002† ROUGE-1 non-filtered None 0.23 0.0008 0.21 0.0005 0.015† Word 0.22 0.001 0.20 0.001 0.008† Character 0.21 0.0009 0.21 0.0009 0.58 ROUGE-2 filteredNone 0.108 0.002 0.100 0.002 0.001† Word 0.11 0.002 0.10 0.001 8.5×10−5† Character 0.11 0.002 0.10 0.001 0.0029† ROUGE-2 non-filteredNone 0.07',\n",
       " '0.0003 0.069 0.0001 0.50 Word 0.06 0.0001 0.046 0.0002 0.0001† Character 0.06 0.0002 0.058 0.0003 0.113179 Scientometrics (2020) 125:3159–3185 1 3 Table 10 Extractive baseline systems VS abstractive sequence- to-sequence system ROUGE-L and ROUGE-SU4 Metrics Bold values indicate the highest number in each columnSystem ROUGE-L ROUGE-SU4 R P F R P F Titles 0.087 0.363 0.134 0.029 0.147 0.046 AbsFS 0.149 0.260 0.174 0.051 0.082 0.056 AbsLS 0.127 0.221 0.151 0.045 0.079 0.054 SUMMA 0.129 0.186 0.146 0.052 0.059 0.052 MEAD',\n",
       " '0.209 0.178 0.179 0.130 0.067 0.082 LexRank 0.161 0.259 0.183 0.067 0.092 0.070 TexRank 0.186 0.194 0.178 0.092 0.067 0.073 SEQ3 0.043 0.281 0.074 0.016 0.038 0.021 CNNSUMMA 0.170 0.227 0.181 0.070 0.081 0.070 CNNGoogle 0.201 0.225 0.199 0.081 0.077 0.073 CNNACL 0.191 0.206 0.189 0.077 0.075 0.071 TransformerCB 0.190 0.189 0.179 0.103 0.077 0.084 BRNNCB 0.070 0.365 0.103 0.090 0.096 0.088 TransformerWB 0.198 0.198 0.189 0.105 0.078',\n",
       " '0.085 BRNNWB 0.077 0.358 0.118 0.080 0.083 0.077 Transformer 0.166 0.228 0.192 0.098 0.089 0.093 BRNN 0.192 0.213 0.202 0.110 0.091 0.099 Table 11 Extractive baseline systems VS abstractive sequence- to-sequence system over the filtered data ROUGE-L and ROUGE-SU4 metrics Bold values indicate the highest number in each column System ROUGE-L ROUGE-SU4 R P F R P F Titles 0.087 0.363 0.134 0.029 0.147 0.046 AbsFS 0.143 0.261 0.171 0.048 0.082 0.055 AbsLS 0.131 0.236 0.157 0.045 0.078 0.052 SUMMA 0.154 0.243 0.178 0.058 0.085 0.066 MEAD',\n",
       " '0.179 0.190 0.166 0.093 0.070 0.072 LexRank 0.157 0.264 0.179 0.056 0.092 0.062 TexRank 0.204 0.196 0.187 0.093 0.068 0.073 SEQ3 0.078 0.205 0.109 0.024 0.042 0.029 CNNSUMMA 0.141 0.230 0.162 0.047 0.075 0.052 CNNGoogle 0.189 0.197 0.179 0.077 0.069 0.066 CNNACL 0.191 0.203 0.185 0.082 0.072 0.071 TransformerCB 0.231 0.231 0.231 0.155 0.097 0.119 BRNNCB 0.117 0.437 0.184 0.163 0.117 0.136 TransformerWB 0.238 0.235 0.237 0.153 0.099',\n",
       " '0.120 BRNNWB 0.137 0.415 0.206 0.165 0.119 0.138 Transformer 0.225 0.215 0.220 0.145 0.092 0.112 BRNN 0.124 0.444 0.193 0.165 0.113 0.1343180 Scientometrics (2020) 125:3159–3185 1 3 data where the sequence-to-sequence models obtain higher results for precision, recall, and F-score (for all ROUGE measures)',\n",
       " 'In order to eliminate our bias and get a better insight of how reliable our methods are over the filtered and unfiltered data in comparison with the baselines, we have analysed the ROUGE results by running a t-test 14 (using the R software and selecting 95% confi- dence level). We report our analysis on Tables 7 and 8 for the differences when the same approach is trained with different data types (filtered vs. non-filtered). Moreover, for each sequence-to-sequence model we analyze the effect of the embedding condition used (none, word embedding, character embedding), see Table 9. More specifically, Table 7 compares ROUGE-1 means of the different systems under the filtered and non-filtered conditions. We can observe that differences are statistically significant for all sequence-to-sequence mod- els ( † in the sig. column indicates if a difference was found). Table 8 compares ROUGE-2 results showing similar findings, the filtered condition offers clear advantages',\n",
       " 'Table 9 compares ROUGE (1 and 2) means for the BRNN and Transformer approaches (under dif- ferent embedding conditions). Differences are statistically significant for 9 out of 12 con-ditions ( † in the sig. column indicates if a difference was found) indicating that BRNN is superior in most conditions. Besides, statistical tests (not shown in the tables) comparing BRNN with different embedding conditions indicate that only in two cases of non-filtered data: (i) none/word embedding ( p<0.06 ) and (i) character/word embedding ( p<0, 007 ), differences exist. When comparing the embedding condition for Transformer (not shown in tables), only one difference is detected: the none/character embedding with filtered data ( p<0.06). Limitations Certain limitations apply to abstractive summarization methods in which the generated text could be repetitive for certain phrases that appears often in the training data (e.g',\n",
       " 'stop words), such repetition could affect the comprehensibility of the text. Using a huge dataset as training could reduce the repetition also some post-processing steps could be applied. We have utilized OpenNMT-py to prevent the model from repeating trigrams in the same sentence (i.e. block_ngram_repeat argument), which could help addressing this problem. Example of an incoherent sentence in Table 4 shows that the syntactic structure of the outcome text should be improved. Denoising is one of the promising techniques to tackle this issue (Artetxe et al. 2018). It consists in reordering the input sequence and reconstruct-ing the original word order that makes the model learn how to compose words to result in correct syntactic transformation. It is relevant to our task since there are cases when the change of positions of words in a citation sentence and a corresponding change in the syn-tactic structure are required to compose a meaningful summary (cf., the upper-right text in Fig. 1)',\n",
       " 'We are going to try this technique in the future taking into account that according to the recent works in denoising (Surya et al. 2019) for complex syntactic operations such as sentence splitting, rephrasing, and paraphrasing, some explicit mechanisms should be employed in addition. Although our work is related to a number of scientific summarization approaches, the work most similar to ours is Hu and Wan (2014) who made available the dataset of related 14 Normality of the data was verified with a Kolmogorov–Smirnov test of normality.3181 Scientometrics (2020) 125:3159–3185 1 3 work sections used in our evaluation',\n",
       " 'Their approach however can not be compared directly with ours due to several facts but most importantly: (i) their software is not available to run and (ii) their paper does not indicate which part of the corpus was used for evaluation, leav - ing reproducible research of their approach difficult to achieve.15 In spite of this limitation, we argue that the complete comparison of approaches we have carried out here provides a solid picture into the use of sequence-to-sequence approaches for this specific summariza- tion task. Conclusion Being an essential part of every scientific article, related work sections or literature reviews pose important challenges for natural language processing in the context of the scientific text. Here we have been concerned with the generation of “descriptive“ related work sec- tion given a set of scientific papers to summarize',\n",
       " 'Based on previous research, which indi-cate that related work sections usually include elements from titles and abstracts of the cited papers, we have reduced the complexity of the task considering as input to our gen- eration process only those parts of the scientific articles. Since it has also been shown that related work sections exhibit cut-and-paste summarization strategies we have investigated a sequence-to-sequence approach in order to automatically generate citation sentences for each paper to cite. Our sequence-to-sequence approach makes use of a novel dataset which we make available to the research community for further research. We additionally have presented a comparison between our abstractive approach against a set of extractive meth-ods and evaluated them based on a gold standard dataset using content-based metrics. Our results indicate that our approach outperforms the simple as well as the informed base- lines and competitive neural network approaches',\n",
       " 'There are many avenues for continuing this research such as considering a broader approach to the generation of citations which will jointly take advantage of existing citations as well as paper content to generate more informed citations. Our approach for now just uses titles and abstracts of scientific papers as a source and the citation context as the target because it is cost effective to access them, MAG API facilitates having such information by indexing it directly. However, we will investigate the cost of adding more sentences from the scientific papers directly and the value of extending the context of the source and the target. Another important direction of research is to investigate how to generate sentences which combine in a given sentence information from multiple papers. Future work should also examine the role of discourse and how to connect different citation sentences to produce a cohesive and coherent piece of text. In this sense, a subject which would be interesting to address is that of generat- ing integrative reviews which compare, contrast, and provide judgments on papers, putting them in context',\n",
       " 'However, we see this as a very challenging task in that it would require specific knowledge besides linguistic one to understand which aspects should be compared and in which way, a topic which would be difficult to address with the techniques we have presented here. Acknowledgements This work is (partly) supported by the Spanish Ministry of Economy and Competitive- ness under the Maria de Maeztu Units of Excellence Programme (MDM-2015-0502) Special thanks to ALI TAQI for designing the pointer generator architecture figure. 15 We have attempted to contact in several occasions the authors without receiving any answers.3182 Scientometrics (2020) 125:3159–3185 1 3 Appendix A: ROUGE‑L and ROUGE‑SU4 metrics results We present here the results of our experiments over the filtered and unfiltered data (Tables 10 and 11)',\n",
       " 'References AbuRa’ed, A., Bravo, A., Chiruzzo, L., & Saggion, H. (2018). Lastus/taln+ inco@ cl-scisumm 2018-using regression and convolutions for cross-document semantic linking and summarization of scholarly lit- erature. In Proceedings of the 3nd joint workshop on bibliometric-enhanced information retrieval and natural language processing for digital libraries (BIRNDL2018). Ann Arbor, Michigan (July 2018). AbuRa’ed, A., Chiruzzo, L., Saggion, H., Accuosto, P., & Bravo Serrano, À. (2017). Lastus/taln@ clsci- summ-17: Cross-document sentence matching and scientific text summarization systems. In Proceed-ings of the 2nd joint workshop on bibliometric-enhanced information retrieval and natural language processing for digital libraries (BIRNDL2017)',\n",
       " 'Tokyo, Japan (August 2017). AbuRa’ed, A., Saggion, H., & Chiruzzo, L. (2020). A multi-level annotated corpus of scientific papers for scientific document summarization and cross-document relation discovery. In Proceedings of the 12th international conference on language resources and evaluation (LREC 2020). Agarwal, N., Gvr, K., Reddy, R, S., & Rosé, C. P. (2011). Towards multi-document summarization of sci- entific articles: Making interesting comparisons with scisumm. In Proceedings of the workshop on automatic summarization for different genres, media, and languages (pp. 8–15). Association for Com-putational Linguistics. Altmami, N. I., & Menai, M. E. B. (2018). Semantic graph based automatic summarization of multiple related work sections of scientific articles',\n",
       " 'In International conference on artificial intelligence: Meth-odology, systems, and applications (pp. 255–259). Springer. Artetxe, M., Labaka, G., Agirre, E., & Cho, K. (2018). Unsupervised neural machine translation. In 6th international conference on learning representations, ICLR 2018. Baziotis, C., Androutsopoulos, I., Konstas, I., & Potamianos, A. (2019). Seq 3: Differentiable sequence- to-sequence-to-sequence autoencoder for unsupervised abstractive sentence compression. arXiv :1904.03651 . Beil, F., Ester, M., & Xu, X. (2002). Frequent term-based text clustering. In Proceedings of the eighth ACM SIGKDD international conference on knowledge discovery and data mining (pp. 436–442). ACM. Bird, S., Dale, R., Dorr, B',\n",
       " 'J., Gibson, B. R., Joseph, M. T., Kan, M.-Y., Lee, D., Powley, B., Radev, D. R. & Tan, Y. F. (2008). The ACL anthology reference corpus: A reference dataset for bibliographic research in computational linguistics. LREC. Bražinskas, A., Lapata, M., & Titov, I. (2019). Unsupervised multi-document opinion summarization as copycat-review generation. arXiv :1911.02247 . Cho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., & Bengio, Y. (2014). Learning phrase representations using RNN encoder–decoder for statistical machine transla-tion. arXiv :1406.1078. Chu, E., & Liu, P. J. (2018)',\n",
       " 'Meansum: A neural model for unsupervised multi-document abstractive sum- marization. arXiv :1810.05739 . Constantin, A., Pettifer, S., & Voronkov, A. (2013). PDFX: Fully-automated PDF-to-XML conversion of scientific literature. In Proceedings of the 2013 ACM symposium on Document engineering (pp. 177–180). ACM. Duchi, J., Hazan, E., & Singer, Y. (2011). Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12(Jul), 2121–2159. Endres-Niggemeyer, B., Maier, E. E., & Sigel, A. A. (1995). How to implement a naturalistic model of abstracting: Four core working steps of an expert abstractor. Information Processing and Management, 31(5), 631–674',\n",
       " 'Erkan, G., & Radev, D. R. (2004). Lexrank: Graph-based lexical centrality as salience in text summariza- tion. Journal of Artificial Intelligence Research, 22, 457–479. Ferrés, D., Saggion, H., Ronzano, F., & Bravo, À. (2018). PDFdigest: an adaptable layout-aware PDF-to- XML textual content extractor for scientific articles. In Proceedings of the eleventh international con-ference on language resources and evaluation (LREC-2018). Gehrmann, S., Deng, Y., & Rush, A. M. (2018). Bottom-up abstractive summarization. arXiv :1808.10792 .3183 Scientometrics (2020) 125:3159–3185 1 3 Glorot, X., & Bengio, Y. (2010). Understanding the difficulty of training deep feedforward neural networks',\n",
       " 'In Proceedings of the thirteenth international conference on artificial intelligence and statistics (pp. 249–256). Goyal, P., Dollár, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., Tulloch, A., Jia, Y., & He, K. (2017). Accurate, large minibatch sgd: Training imagenet in 1 hour. arXiv :1706.02677 . Grobid. (2008–2019). https ://githu b.com/kermi tt2/grobi d. Hermann, K. M., Kocisky, T., Grefenstette, E., Espeholt, L., Kay, W., Suleyman, M., & Blunsom, P. (2015). Teaching machines to read and comprehend. In Advances in neural information processing systems (pp. 1693–1701). Hinton, G',\n",
       " 'E, Srivastava, N., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. R. (2012). Improving neural networks by preventing co-adaptation of feature detectors. arXiv :1207.0580. Hoang, C. D. V., & Kan, M.-Y. (2010). Towards automated related work summarization. In Proceedings of the 23rd international conference on computational linguistics: Posters (pp. 427–435). Association for Computational Linguistics. Hofmann, T. (1999). Probabilistic latent semantic indexing. In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval (pp. 50–57). ACM. Hu, Y., & Wan, X. (2014). Automatic generation of related work sections in scientific papers: An optimiza- tion approach. In EMNLP (pp. 1624–1633)',\n",
       " 'Jaidka, K., Chandrasekaran, M. K., Jha, R., Jones, C., Kan, M.-Y., Khanna, A., Mollá-Aliod, D., Radev, D. R., Ronzano, F., Saggion, H., & Wee, W. K. (2014). The computational linguistics summarization pilot task. In Proceedings of TAC 2014. Jaidka, K., Khoo, C., & Na, J.-C. (2013). Deconstructing human literature reviews—A framework for multi- document summarization. In Proceedings of the 14th European workshop on natural language genera-tion (pp. 125–135). Jean, S., Cho, K., Memisevic, R., & Bengio, Y. (2014). On using very large target vocabulary for neural machine translation. arXiv :1412.2007',\n",
       " 'Jean, S., Firat, O., Cho, K., Memisevic, R., & Bengio, Y. (2015). Montreal neural machine translation systems for WMT’15. In Proceedings of the tenth workshop on statistical machine translation (pp. 134–140). Jelinek, F., Mercer, R. L., Bahl, L. R., & Baker, J. K. (1977). Perplexity—A measure of the difficulty of speech recognition tasks. The Journal of the Acoustical Society of America, 62(S1), S63–S63. Jha, R., Abu-Jbara, A., & Radev, D. R. (2013). A system for summarizing scientific topics starting from keywords. ACL , 2, 572–577. Kalchbrenner, N., & Blunsom, P. (2013). Recurrent continuous translation models. In Proceedings of the 2013 conference on empirical methods in natural language processing (pp',\n",
       " '1700–1709). Khoo, C. S. G., Na, J.-C., Jaidka, K. (2011). Analysis of the macro-level discourse structure of literature reviews. Online Information Review, 35. Kim, Y. (2014). Convolutional neural networks for sentence classification. arXiv :1408.5882. Kingma, D. P., & Ba, J. (2014). Adam: A method for stochastic optimization. arXiv :1412.6980. Klein, G., Kim, Y., Deng, Y., Senellart, J., & Rush, A. M. (2017). Opennmt: Open-source toolkit for neural machine translation. arXiv :1701.02810 . Lin, C.-Y. (2004). Rouge: A package for automatic evaluation of summaries. In Text summarization branches out: Proceedings of the ACL-04 workshop (Vol. 8). Barcelona, Spain. Liu, H. (2017)',\n",
       " 'Sentiment analysis of citations using word2vec. CoRRarXiv :1704.00177 . Luong, M.-T., & Manning, C. D. (2015). Stanford neural machine translation systems for spoken language domains. In Proceedings of the international workshop on spoken language translation (pp. 76–79). Luong, M.-T., Pham, H., & Manning, C. D. (2015). Effective approaches to attention-based neural machine translation. arXiv :1508.04025 . Luong, M.-T., Sutskever, I., Le, Q. V., Vinyals, O., & Zaremba, W. (2014). Addressing the rare word prob- lem in neural machine translation. arXiv :1410.8206. Maggio, L., Sewell, J., & Artino, A. (2016). The literature review: A foundation for high-quality medical education research',\n",
       " 'Journal of Graduate Medical Education, 8, 297–303. Maynard, D., Tablan, V., Cunningham, H., Ursu, C., Saggion, H., Bontcheva, K., et al. (2002). Architectural elements of language engineering robustness. Natural Language Engineering, 8(2–3), 257–274. Mayr, P., Chandrasekaran, M. K., & Jaidka, K. (2019). Report on the 3rd joint workshop on bibliometric- enhanced information retrieval and natural language processing for digital libraries (birndl 2018). In ACM SIGIR Forum (Vol. 52, pp. 105–110). ACM. McNee, S. M., Albert, I., Cosley, D., Gopalkrishnan, P., Lam, S. K., Rashid, A. M., Konstan, J. A., & Riedl, J. (2002)',\n",
       " 'On the recommending of citations for research papers. In Proceedings of the 2002 ACM con-ference on computer supported cooperative work (pp. 116–125). ACM.3184 Scientometrics (2020) 125:3159–3185 1 3 Mihalcea, R., & Tarau, P. (2004). Textrank: Bringing order into text. In Proceedings of the 2004 conference on empirical methods in natural language processing. Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013a). Efficient estimation of word representations in vec- tor space. In ICLR workshop. Mikolov, T., Grave, E., Bojanowski, P., Puhrsch, C., & Joulin, A. (2018). Advances in pre-training distrib- uted word representations. In Proceedings of the international conference on language resources and evaluation (LREC 2018)',\n",
       " 'Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013b). Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems (pp. 3111–3119). Mohammad, S., Dorr, B., Egan, M., Hassan, A., Muthukrishan, P., Qazvinian, V., Radev, D., & Zajic, D. (2009). Using citations to generate surveys of scientific paradigms. In Proceedings of human language technologies: The 2009 annual conference of the North American chapter of the association for com- putational linguistics (pp. 584–592). Association for Computational Linguistics. Nallapati, R., Zhou, B., Gulcehre, C., & Xiang, B., et al. (2016)',\n",
       " 'Abstractive text summarization using sequence-to-sequence RNNs and beyond. arXiv :1602.06023 . Nguyen, T. H., & Grishman, R. (2015). Relation extraction: Perspective from convolutional neural net- works. In Proceedings of the 1st workshop on vector space modeling for natural language processing (pp. 39–48). Oakes, M. P., & Paice, C. D. (1999). The automatic generation of templates for automatic abstracting. In Proceedings of the 21st annual BCS-IRSG conference on information retrieval research, IRSG’99 (pp. 11–11). Swindon: BCS Learning and Development Ltd. Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). Bleu: A method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational lin-guistics (pp. 311–318)',\n",
       " 'Association for Computational Linguistics. Qazvinian, V., Radev, D. R., Mohammad, S., Dorr, B. J., Zajic, D. M., Whidby, M., et al. (2013). Generating extractive summaries of scientific paradigms. Journal of Artificial Intelligence Research (JAIR), 46, 165–201. Radev, D. R., Allison, T., Blair-Goldensohn, S., Blitzer, J., Celebi, A., Dimitrov, S., Drabek, E., Hakim, A., Lam, W., Liu, D., et al. (2004). Mead-a platform for multidocument multilingual text summarization. In LREC. Ronzano, F., & Saggion, H. (2015). Dr. Inventor framework: Extracting structured information from scien- tific publications. In International conference on discovery science (pp. 209–220). Springer',\n",
       " 'Ronzano, F., & Saggion, H. (2016). An empirical assessment of citation information in scientific summa- rization. In Natural language processing and information systems—21st international conference on applications of natural language to information systems, NLDB 2016, Salford, UK, June 22–24, 2016, Proceedings (pp. 318–325). Rowley, J., & Slack, F. (2004). Conducting a literature review. Management Research News, 27.Saggion, H. (1999). Using linguistic knowledge in automatic abstracting. In 27th annual meeting of the association for computational linguistics, University of Maryland, College Park, Maryland, USA, 20–26 June 1999. Saggion, H. (2011). Learning predicate insertion rules for document abstracting',\n",
       " 'In Computational linguis- tics and intelligent text processing—12th international conference, CICLing 2011, Tokyo, Japan, Feb-ruary 20–26, 2011. Proceedings, Part II (pp. 301–312). Saggion, H., & Poibeau, T. (2013). Automatic text summarization: Past, present and future. In Multi-source, multilingual information extraction and summarization (pp. 3–21). Saggion, H. (2008). SUMMA: A robust and adaptable summarization tool. Traitement Automatique des Langues, 49(2), 103–125. Saggion, H., & Lapalme, G. (2002). Generating indicative-informative summaries with sumum. Computa- tional Linguistics, 28(4), 497–526. Schuster, M., & Paliwal, K. K. (1997). Bidirectional recurrent neural networks',\n",
       " 'IEEE Transactions on Sig- nal Processing, 45(11), 2673–2681. See, A., Liu, P. J., & Manning, C. D. (2017). Get to the point: Summarization with pointer-generator net- works. arXiv :1704.04368 . Sinha, A., Shen, Z., Song, Y., Ma, H., Eide, D., Hsu, B.-J. P., & Wang, K. (2015). An overview of micro- soft academic service (MAS) and applications. In Proceedings of the 24th international conference on world wide web (pp. 243–246). ACM. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: A simple way to prevent neural networks from overfitting',\n",
       " 'The Journal of Machine Learning Research, 15(1), 1929–1958.3185 Scientometrics (2020) 125:3159–3185 1 3 Surya, S., Mishra, A., Laha, A., Jain, P., & Sankaranarayanan, K. (2019). Unsupervised neural text simplifi- cation. In Proceedings of the 57th annual meeting of the association for computational linguistics (pp. 2058–2068). Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. In Advances in neural information processing systems (pp. 3104–3112). Tang, J. (2016). Aminer: Toward understanding big scholar data. In WSDM.Tang, J., Zhang, J., Yao, L., Li, J., Zhang, L., & Su, Z. (2008)',\n",
       " 'Arnetminer: Extraction and mining of aca- demic social networks. In Proceedings of the 14th ACM SIGKDD international conference on Knowl-edge discovery and data mining (pp. 990–998). ACM. Teufel, S., et al. (2000). Argumentative zoning: Information extraction from scientific text. Ph.D. Thesis, Citeseer. Teufel, S., & Moens, M. (2002). Summarizing scientific articles: Experiments with relevance and rhetorical status. Computational Linguistics, 28(4), 409–445. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017). Attention is all you need. In Advances in neural information processing systems (pp. 5998–6008)',\n",
       " 'Vinyals, O., Fortunato, M., & Jaitly, N. (2015a). Pointer networks. In Advances in neural information pro- cessing systems (pp. 2692–2700). Vinyals, O., Toshev, A., Bengio, S., & Erhan, D. (2015b). Show and tell: A neural image caption generator. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3156–3164). Vu, H. C. D. (2010). Towards automated related work summarization. Ph.D. Thesis.Wu, Y., Schuster, M., Chen, Z., Le, Q. V., Norouzi, M., Macherey, W., Krikun, M., Cao, Y., Gao, Q., & Macherey, K., et al. (2016). Google’s neural machine translation system: Bridging the gap between human and machine translation',\n",
       " 'arXiv :1609.08144 . Yasunaga, M., Kasai, J., Zhang, R., Fabbri, A. R., Li, I., Friedman, D., & Radev, D. R. (2019). ScisummNet: A large annotated corpus and content-impact models for scientific paper summarization with citation networks. AAAI (2019) Zhang, X., Lapata, M., Wei, F., & Zhou, M. (2018). Neural latent extractive document summarization. arXiv :1808.07187 .',\n",
       " 'ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary Yutong Li1, Lu Chen2,3, Aiwei Liu1, Kai Yu2,3,Lijie Wen1 1Tsinghua University, Beijing, China 2X-LANCE Lab, Department of Computer Science and Engineering MoE Key Lab of Artificial Intelligence, SJTU AI Institute Shanghai Jiao Tong University, Shanghai, China 3Suzhou Laboratory, Suzhou, China li-yt21@mails.tsinghua.edu.cn ,chenlusz@sjtu.edu.cn ,wenlj@tsinghua.edu.cn Abstract The literature review is an indispensable step in the research process. It provides the ben- efit of comprehending the research problem and understanding the current research situa- tion while conducting a comparative analysis of prior works. However, literature summary is challenging and time consuming',\n",
       " 'The previous LLM-based studies on literature review mainly focused on the complete process, including lit- erature retrieval, screening, and summarization. However, for the summarization step, simple CoT method often lacks the ability to provide extensive comparative summary. In this work, we firstly focus on the independent literature summarization step and introduce ChatCite1, an LLM agent with human workflow guidance for comparative literature summary. This agent, by mimicking the human workflow, first ex- tracts key elements from relevant literature and then generates summaries using a Reflective In- cremental Mechanism. In order to better eval- uate the quality of the generated summaries, we devised a LLM-based automatic evaluation metric, G-Score, in refer to the human evalua- tion criteria. The ChatCite agent outperformed other models in various dimensions in the ex- periments. The literature summaries generated byChatCite can also be directly used for draft- ing literature reviews',\n",
       " '1 Introduction As the rapid advancement of academic research, scholars must delve into existing literature to under- stand past studies, recognize future research trends, and find innovative approaches in their fields. Craft- ing a literature review entails searching for relevant literature and conducting detailed comparative sum- marization. It typically involves two main steps: literature collection followed by literature summary generation based on the collected sources. How- ever, organizing a high-quality literature review 1Our code will be released after the review process. Reference papers set Proposed work description Generated - literature summaryFigure 1: Literature Summary Task Description necessitates scholars to engage in thorough analy- sis, organization, comparison, and integration of an extensive of related works, which is often a chal- lenging and time-consuming task. Therefore, Hoang and Kan (2010) have proposed the automatic generation of literature summary. However, machine-generated literature summaries often encounter challenges like information omis- sion, lack of linguistic fluency, and insufficient comparative analysis',\n",
       " 'In traditional models, sum- maries generated through extraction and abstrac- tion approach may miss key information due to the limitations of the model, leading to the lack of cru- cial points or findings of the generated summaries. Some automated systems may lack the ability for in-depth comparative analysis, potentially resulting in literature summaries that lack a comprehensive understanding of the relevant research in the field. In recent years, with the rapid development of large language models (LLMs) (Radford et al., 2019; Brown et al., 2020), their powerful capa- bilities in natural language generation tasks have been demonstrated across various tasks, that pro- vides possibilities for handling longer texts and generating comprehensive summaries. Researchers have started exploring how to leverage LLMs to generate automatic literature summaries. Wei et al. (2023) propose a Chain-of-Thought (CoT) prompt- ing method to enhance the ability of large language models to perform complex reasoning',\n",
       " 'CoT al- lows LLMs to devise their own plan, resulting inarXiv:2403.02574v1 [cs.IR] 5 Mar 2024generated text that aligns more closely with hu- man preferences.Recent study by (Huang and Tan, 2023) and Agarwal et al. (2024) on literature re- view has focused more on how to retrieve relevant papers more accurately and neglected research on literature summarization. They use only simple CoT guidance to generate literature summaries, re- sulting in a lack of comparative and organizational analysis. Large language models, despite their flu- ent language generation, struggle to consistently produce comparative literature summaries due to their unpredictable an stochastic nature. The length limitations of these models require a two-step sum- marization approach, increasing the risk of infor- mation omission during abstract generation',\n",
       " 'In this work, we focus on the independent lit- erature summarization task, aiming to generate a comprehensive comparative literature summary through a certain collection of literature and a de- scription of the proposed work, as illustrated in Figure 1. To address these challenges mentioned above, our work proposes ChatCite , a LLM-based agent guided by human workflow. Different from simple CoT prompting approach, the agent is de- signed with the human workflow guidance, rather than formulating the generation process in a black- box manner, ensuring a more stable generation of higher-quality generic summaries. Furthermore, quality assessment for generative tasks has always been a challenge. Prior studies on literature summarization have primarily relied on text summarization metrics, such as ROUGE (Lin (2004a)). However, traditional text summary evaluation metrics, like ROUGE, are not sufficient to assess the quality of literature summaries',\n",
       " 'More comprehensive evaluation criteria covering mul- tiple dimensions are required to ensure that the generated literature summaries truly meet the re- quirements. Therefore, we combine human studies on literature reviews (Justitia and Wang, 2022) to formulate the evaluation criteria for literature sum- maries from multiple dimensions2, and propose an LLM-based automatic evaluation metric, G-Score. Experimental results demonstrate its consistency with human evaluations. In this paper, we summarize our main contribu- tions of our framework as follows: •we focus on the independent literature sum- marization step of literature review, and in- 2Six evaluation dimensions are: Consistency, Coherence, Comparative, Integrity, Fluency, Cite Accuracy.troduce ChatCite , an LLM agent with human workflow guidance for comparative literature summary. •Based on research on literature summaries, we have developed a multidimensional quality assessment criterion for literature summaries',\n",
       " 'Additionally, we propose an LLM-based auto- matic evaluation metric, G-Score, demonstrat- ing results consistent with human preferences. •The experimental results indicate that ChatCite outperforms other LLM-based literature summarization methods in all quality dimensions. The literature summaries produced by ChatCite can be directly utilized for drafting literature reviews. •We demonstrate that LLMs with human work- flow guidance, have the ability to effectively perform comprehensive comparative summa- rization of multiple documents. Therefore, we infer that Large Language Models (LLMs) have the potential to handle more complex inferential summarization tasks. 2 Related Work3 In recent years, there is abundant research on gen- erated literature summaries with the initial pro- posal made by Hoang and Kan (2010), to automate related work summarization created by a topic- related work summary based on an extractive ap- proach. To generate citation sentence, Xing et al',\n",
       " '(2020) adopted a multi-source pointer-generator network with cross-attention mechanism, while AbuRa’ed et al. (2020) utilized the ARWG sys- tem, employing a neural sequence learning process and Ge et al. (2021) proposed a BACO framework based on background knowledge and content. Fur- thermore, Chen et al. (2021) employed the Relation- aware Related Work Generator (RRG) to generate citation paragraphs while Chen et al. (2022) ap- plied contrastive learning to generate target-aware related work segments. Yet traditional generation methods cannot generate the conprehensive coher- ent literature review due to the size of their model and the lack of the coherent and procedural lan- guage continuity. 3Our related work utilizes summaries generated by ChatCite with GPT-4 as a draft, with minimal refinement. The information is comprehensive with minimal errors. The gen- erated results organize the literature and include comparative analysis',\n",
       " 'The generated results are presented in the appendix (Table 4).Large Language Models (LLMs), such as GPT (Radford et al. (2019), Brown et al. (2020)), have demonstrated their powerful capabilities in natural language generation tasks. The study by Huang and Tan (2023) on the use of AI tools like Chat- GPT in writing scientific review articles reveals the potential benefits and drawbacks of artificial intel- ligence in academic writing. Building on these in- sights, Agarwal et al. (2024) introduces the LitLLM toolkit, which overcomes challenges such as gener- ating hallucinated content and overlooking recent research by adopting Retrieval Augmented Gen- eration (RAG) principles, specialized prompting, and instructive techniques. However, these stud- ies only applied a simple Chain of Thought (CoT) to the search and filtering process in literature re- views, resulting in poor readability',\n",
       " 'By comparison, ChatCite focuses on the independent task of text summarization, aiming to generate higher-quality summaries. Furthermore, this paper introduced a multi- dimensional G-Score evaluation metric inspired by the previous attempt to use Large Language Models (LLMs) through chain-of-thought methods to evaluate the quality of natural language genera- tion (NLG) systems (Liu et al. (2023), Goyal et al. (2023)) which is more consistent with human evalu- ation compared to traditional ROUGE metrics (Lin (2004b)). 3 ChatCite The literature review task can be decomposed into two sub tasks: relevant papers retrieval and litera- ture summaries generation. This work focuses on the independent task of literature summary genera- tion. Our task is to generate the literature summary based on the proposed work description Dand a certain reference papers set R={r1, r2, ..., r n}',\n",
       " 'Given DandR, our agent generates a literature summary Y=f(D,R). Diverging from other types of summaries, such as news summaries, the literature summary gener- ated directly by large language models using simple Chain-of-Thought (CoT) guidance in existing work mainly faces the following issues: Key Elements missing: Because of the window limitations of LLMs, generating the complete lit- erature review directly is challenging. Typically, a two-step approach is used involving summariza- tion and literature review generation. However, this process can lead to the loss of key elements duringsummarization. Even if the entire literature sum- mary can be directly generated, using the entire text may result in mistakes in understanding key elements and the loss of such elements',\n",
       " 'Lack of Comparative Analysis: Comparative analysis is crucial in literature summary, requir- ing an analysis on the limitations and advantages of existing research methods, and focusing on dif- ferences and similarities in methods, experimental design, dataset usage, and more. Directly using CoT-generated results often lacks comparative anal- ysis. Lack of Organizational Structure: The litera- ture summary generated solely by CoT tends to be discrete for each paper, lacking classification for similar works and an organized structure for the literature review. To address these challenges, we have proposed an LLM agent for comparative literature summary with human workflow guidance, ChatCite , consist- ing two modules: the Key Element Extractor and the Reflective Incremental Generator, as illustrated in Figure 2. In this process, we utilize large lan- guage models as both generation and evaluation components, eliminating the need for additional model training and improving the quality of gener- ated text to some extent',\n",
       " 'The generation process guided by human work- flow is as follows: 1.The proposed work description and reference papers in the reference papers set are initially processed using the Key Element Extractor separately. 2.Iteratively generate literature summaries us- ing reference papers set. In each iteration, use the comparative summarizer to generate a comparative analysis summary. Then, use the reflective evaluator to vote on the generated candidate results, ranking the vote score and retaining the top ncresults. Iterate continu- ously until all reference papers are processed. The final output is selected based on the highest voting score among the generated related work sum- maries',\n",
       " 'In this section, we first elaborate on the specifics of the Key Element Extractor (§3.1) and the Reflec- tive Iterative Generator module (§3.2) in detail.Please extract the following key elements from the content: •Research questions: What research questions does the paper attempt to address? •Methodology: What method does the paper employ to address this issue? •Results: What were the obtained experimental results in the paper •Conclusions: What conclusions were drawn from the experiments? •Contributions: What contributions does this paper make? •Innovations: What are the innovations introduced in the paper? •Limitations: What limitations are identified in the paper? Content : {content} Key Element Extractor Guidelines for Writing Literature Reviews； Previous summary: {text} Proposed work:{text} i-th Reference Paper summary:{text} ## Examples Comparative summarizer Reflective Evaluator Given the target',\n",
       " 'paper summary and references, Analyze each choice in detail, then conclude in the last line \"The best choice is {s}\", where s the integer id of the choice',\n",
       " 'Choices 1,...;Choice2,...;Choice3,...;...;The best choice is 3. Reflective Mechanism Rank & Select Choice 3 Choice 4 Choice 1 Choice 6 Choice 2 Choice 5 Proposed work discripition Reference Papers SetChoice 1 Choice 2 Choice 3 Choice 4 Choice 5 Choice 6 ... ... ...Turn One Turn Two Turn Three Trun ThreeReflective Incremental Generator 푟�\\x002푟�\\x001 푟�\\x002 푟�\\x003 푟�\\x003 푟�\\x003 푟�\\x003 푟�\\x004 푟�\\x004 푟�\\x004 푟�\\x004푟�\\x004푟�\\x004Figure 2: The ChatCite consists of two modules, the Key Element Extractor and the Reflective Incremental Generator',\n",
       " 'The agent mimicking human workflow generates literature summary utilizing the Key Element Extractor to process the proposed work description and reference paper in Reference Papers Set. It then iteratively generates literature summaries using each paper in the Reference Papers Set, proposed work key elements and previous summary generated with the Reflective Incremental Generator. This process is iteratively repeated until a complete related work summary is generated, and the optimal one is selected as the final result. 3.1 Key Element Extractor In order to retain sufficient key element for litera- ture summary, we create seven simple guiding ques- tions based on analysis (Justitia and Wang, 2022) on literature review. We concatenate theses ques- tions and the content required extraction as prompt to instruct LLMs extract the key elements',\n",
       " 'For each element, a simple question (shown in Figure 2) is set to guide the model in extraction, and these ques- tions are Qe= [q1, q2, ..., q 7].These questions Qeand paper content Care concatenated to form the key element extraction prompt Pe= [Qe, C] . Using LLM as extraction decoder to extract key elements and storing them in memory. 3.2 Reflective incremental Generator To overcome the challenges of lacking comparative analysis and organizational structure in literature reviews generated by LLMs, we designed the reflec- tive incremental generator. The generator uses the Comparative Summarizer to continue writing com- parative summaries, combining the results from the previous turn and the key elements of the pro- posed work and reference papers. It then utilizes the reflective evaluator to filter the generated re-sults. This process is interatively applied to each reference paper in the reference papers set until all reference papers are processed',\n",
       " 'The best result is ultimately retained as the model’s generated output. 3.2.1 Comparative Summarizer For turn i, based on the proposed work key element pro, the key element of the i-th reference paper refiand comparative summarization guidance se- quentially generated summary for each summary s∈Si−1, and generating nssamples each time',\n",
       " 'Si={G(Dg, pro, ref i, s, n s),∀s∈Si−1}Here, to enhance the comparability and organization of the generated summaries, comparative summariza- tion guidance are provided: \"Considering the rela- tionship between the reference paper and the target paper, as well as existing references in the previ- ously completed related work, while retaining the content of all referenced papers mentioned in the previously completed related work.\" 3.2.2 Reflective Mechanism Due to significant uncertainty in text generation tasks, we employ reflective generation to enhance the quality and stability of generated paragraphs. Here, we use LLMs as Reflective Evaluator to votenvtimes on the generated results in each turn and then perform a statistical analysis on the voting results to obtain voting scores Ei=E(De, S′ i)',\n",
       " 'Then we sort the scores, and retain the top nccandidates Si={St, t∈Sort(Ei)(1, nc)}. These selected candidates will be used for the next round of incremental generation. This approach helps identify the most promising results, ensures the quality of the generated text, and enhances gen- eration stability. 3.2.3 Reflective Incremental Generator Algorithm In implementing reflective incremental generation, we drew inspiration from the breadth-first search algorithm for trees (Algorithm 1). Algorithm 1 Reflective Incremental Generator Require: Proposed work key element pro, ref- erence paper summaries list refs _list = [ref 1, ref 2, ...ref n], Comparative Summarizer G(), Reflective Evaluator E(), LM decoder for summarization Ds, LM decoder for evaluation De, n_samples for each generation ns, and the number of candidates retained for each turn is nc',\n",
       " 'S0← {} steps←len(refs _list) fori= 1tosteps do S′ t← {G(Dg, pro, ref i, s, n s), s∈Si−1} Ei←E(De, S′ i) Si← {St, t∈Sort(Ei)(1, nc)} end for return Sargmax iEn(i) notes: G()corresponds to the Comparative Sum- marizer function described in §3.2.1, and E()cor- responds to the Reflective Envaluation function described in §3.2.2. At each step, a collection containing ncmost promising generated results is maintained, where the depth of the tree equals the number of documents in the relevant literature collection, S′ tcontains nc*nsresults, while Si−1 andSieach contain ncresults',\n",
       " '4 G-Score: LLM-based automatic Evaluation Metrics The evaluation of generative tasks has always been challenging. Previous research on literature sum- marization predominantly depended on text sum- marization metrics, like ROUGE (Lin (2004a)).However, conventional text summary evaluation metrics such as ROUGE fall short in gauging the quality of literature summaries. It is crucial to adopt more comprehensive evaluation criteria across various dimensions to guarantee that the generated literature summaries align with the nec- essary standards. Here, inspired by G-Eval (Liu et al., 2023), we attempted to assess it using LLMs. We established six-dimensional metrics for auto- matic evaluation based on research on literature summaries (Justitia and Wang, 2022). Evaluation Steps. We used Large Language Models (LLMs) to score the six dimensions of generic quality and voted for the best summary from a series of model-generated summaries',\n",
       " 'Spe- cially, to ensure fairness and consistency in evalu- ation, we simultaneously scored and voted for the generated results of multiple models in a single conversation. Evaluation Criterion: Consistency (1-5) :Content consistency between the generated summary and the gold summary. The generated summary must not contain content that conflicts with the gold summary. Coherence(1-5) :The quality of language coher- ence in generated summaries, which should not just be a heap of related information. Comparative (1-5) :Assess the extent to whether the generated summary conducts a compara- tive analysis on references and proposed work. Whether it provides an integrated summary of simi- lar related works. Integrity (1-5) :Assess if the summary covers es- sential elements: research context, reference paper summaries, past research evaluation, contributions, and innovations',\n",
       " 'Fluency (1-5) :Assess the quality of the summary in terms of grammar, spelling, punctuation, word choice, and sentence structure. Cite Accuracy(1-5) :Assess whether the summary correctly cites reference paper in the format ‘[Ref- erence i]’ when mention the reference paper. 5 Experiment We validate the capabilities of our proposed ChatCite agent by verifying the following ques- tions: 1) Is the literature summary generated by ChatCite better than that generated directly by LLMs with CoT and other LLM-based literature review approach? 2) Do all the modules in the ChatCite contribute to its effectiveness? 3) Whatspecific impact do the modules in the ChatCite framework have on the quality of generated sum- mary? In this section, we conducted a series of experi- ments to address these questions. Firstly, we intro- duced our experimental setup (§5.1)',\n",
       " 'We compared the performance of existing large language models (LLMs) in directly generating related work under zero-shot and few-shot settings, as well as the best- performing LLM-based literature review approach (§5.2). Additionally, we performed ablation analy- sis on each module in our agent to verify their re- spective capabilities (§5.3). Finally, we conducted a human study for a detailed quality assessment of the generated related work summaries (§5.4). 5.1 Experimental Setup Dataset. We conducted experiments to validate on a paper dataset NudtRwG-Citation dataset (Wang et al., 2020) designed for related work summariza- tion task. This test set includes 50 academic re- search papers in the field of Computer Science, each data containing the following components: 1) A target paper requiring related work generation without the related work section. 2) A ground truth related work section',\n",
       " '3) Reference papers of the target paper (annotated with authors and years). Each paper is well-received in conferences of computational linguistics and natural language pro- cessing, with an average citation number reach- ing 63.59, which indicates these target papers are widely recognized by the academic community. Models. For the LLMs baseline, we employed the GPT-3.5 model (Ouyang et al. (2022)) with a 16k context window (version gpt-3.5-turbo-1106) and the GPT-4.0 model (Achiam et al. (2023)) with a 128K context window (gpt-4-turbo-preview). We evaluated their performance under zero-shot and few-shot settings. For the previously best- performing LLM-based literature review approach, we use the recently proposed approach LitLLM (Agarwal et al., 2024) as the baseline',\n",
       " 'We repro- duce their ability to generate literature summaries according to the CoT prompt mentioned in their paper. To showcase its best performance, we use GPT-4.0 as the decoder for the LitLLM baseline. For our model, due to the high cost of GPT-4.0, we conducted experiment based on GPT-3.5 (version gpt-3.5-turbo-1106) as the decoder for the experi- ment. For evaluation, we use GPT-4.0 (gpt-4-turbo- preview) as decoder.Implementation. In zero-shot setting, for GPT- 3.5 model, due to the limitation of the context window, a two-step approach is used for gener- ation: 1) summarizing and then generating with the prompt [ps] =\"Summarize the current article, preserving as much information as possible. Con- tent:{content}\" for summarization',\n",
       " 'For generating the related work section, we use the prompt [pg] = \"Generate the related work section based on the given target paper summary and its references sum- mary. Read the Target Paper Content: {Target}. References content: {References}\" . For GPT-4.0 and LitLLM with GPT-4.0, [pg]is directly used for summarization. In the few-shot setting, we add the instruction \"Follow the writing style of the example but without including any content from the example. {Exam- ples}\" to the zero-shot prompt. Evaluation metrics. We utilize both automatic metrics and human evaluations to assess the generic result. We employed traditional automatic metrics for summarization evaluation - the vocabulary over- lap measures ROUGE-1/2/L (F1) (Lin (2004b)), our proposed LLM-based evaluation metrics G- Eval, and human evaluation under the same evalua- tion criterion',\n",
       " '5.2 Main Results We compared the performance of different base- line models on the paper test set (see Table 1). In traditional summary evaluation metrics, such as ROUGE, GPT-4.0 achieved the best results under zero-shot settings. Although ROUGE scores of ChatCite may be slightly lower than GPT-4.0 with zero-shot, its performance in quality metrics gen- erated by LLMs and the preference of LLMs is far superior to results obtained directly from other LLM baselines. Surprisingly, GPT-4.0 performed poorly in few- shot settings.It is found that influenced by exam- ples in the few-shot, resulting in irrelevant and erroneous summaries after case study. Notably, LitLLM with GPT-4.0 produced outcomes similar to GPT-4.0 in zero-shot but significantly lower than ChatCite ',\n",
       " 'Therefore, we conclude that \"ChatCite performs best among LLM-based literature summarization methods, and the approach following the human workflow guidance is superior to the results ob- tained by the Chain of Thought (CoT) method.\"ModelROUGE Metrics G-Score G-Prf',\n",
       " 'ROUGE -1 ROUGE -2 ROUGE -L (1-5) (%) GPT-3.5 w/zero shot 26.01 6.11 24.02 3.4102 2.21 GPT-3.5 w/few shot 25.84 6.01 23.55 3.5968 10.80 GPT-4 w/zero shot 30.02 8.03 27.97 3.5076 26.40 GPT-4 w/few shot 15.52 1.78 14.20 1.6621 0.21 LitLLM w/GPT-4 27.08 6.07 24.94 3.5448 24.51 ChatCite 25.30 6.36 23.13 4.0642 35.86 Table 1: Main Results : The results are automatically evaluated using ROUGE-1/2/L (F1) and the GPT-4.0 evaluator',\n",
       " 'G-Score represents the total score assessed by the GPT-4.0 evaluator, while G-Prf. indicates the model preferences among the five models. 5.3 Ablation Analysis Our proposed framework can be decomposed into two components: the Key Element Extractor and the Reflective Incremental Generator. The Re- flective Incremental Generator comprises two key points: the Comparative Incremental Generation and the Reflective Mechanism. Therefore, we will analyze the three part separately. Key Element Extractor. To validate the effec- tiveness of the Key Element Extractor, we chose ChatCite without the Key Element Extractor as a comparison. The ChatCite without Key Element Extractor used the baseline summary prompt [ps]to directly summarize the article and then use Reflec- tive Incremental Generator generate the literature summary',\n",
       " 'In Table 2, comparing the results of ChatCite without Key Element Extractor and ChatCite, we can observe that ChatCite performs better in all dimensions of ROUGE metrics and the metrics generated by the LLM based evaluator. Therefore, it indicates that the Topic Extractor module plays an effective role in literature summarization. Comparative Incremental Mechanism. To val- idate the effectiveness of the Comparative Incre- mental Mechanism, we choose ChatCite without Comparative Incremental Mechanism as compar- ison, following the few-shot baseline prompt [ps] and few-shot examples as prompts to directly gener- ate literature summaries from the text after standard summarization. Considering controlling variables for the incremental mechanism, we also incorpo- rated CoT writing instructions into the method to ensure that the experimental results are not influ- enced by the writing instructions',\n",
       " 'In Table 2, when comparing ChatCite with and without the Comparative Incremental Mechanism, the results indicate that ChatCite achieves higherROUGE metrics and LLM-based evaluation met- rics compared to ChatCite without the Compara- tive Incremental Mechanism. This suggests that the Comparative Incremental Mechanism signifi- cantly contributes to the effectiveness of literature summarization in the ChatCite framework. 12345 Consistency CoherenceComparative Integrity FluencyCite_Accuracy Overall Evaluation Dimensions12345 Consistency CoherenceComparative Integrity FluencyCite_Accuracy OverallScoresChatCiteChatCite -w/o Reflective Figure 3: Ablation Study on the Reflective Mechanism. The upper and lower whiskers represent the overall range of the data, while the box displays the distribution of the middle 50% of the dataset, with a line inside the box representing the median of the data',\n",
       " 'Data points outside the boxplot are considered outliers, indicating data points that significantly deviate from the box and whiskers. It can be observed that ChatCite performs more stable across all dimensions. Reflective Mechanism. In conclusion, we ana- lyzed the reflective mechanism’s impact. G-Scores for various dimensions were assessed based on mul- tiple results from ChatCite , both with and without the Reflective Mechanism. The boxplot results in Figure 3 show similarities between the outcomeModelROUGE Metrics G-Score G-Prf. ROUGE -1 ROUGE -2 ROUGE -L (1-5) (%) GPT-3.5 w/few shot 25.84 6.01 23.55 3.2426 2.84 -w/o Elem. 24.38 5.81 22.36 4.0016 22.11 ChatCite -w/o Incre',\n",
       " '24.72 5.93 22.40 3.8195 35.34 ChatCite 25.30 6.36 23.13 4.1064 39.71 Table 2: Ablation Results : This table presents the ablation results on the model’s Key Element Extractor and Comparative Incremental Generator, with the results of GPT-3.5 w/few-shot used as the baseline for GPT-3.5. ofChatCite with and without the Reflective Mech- anism. However, the overall results of ChatCite are slightly higher, with minimal distribution out- liers, suggesting a more stable generation of results. This affirms that the Reflective Mechanism effec- tively improves the quality and stability of the text generated in ChatCite ',\n",
       " 'Overall, through ablation experiments on three components, we have demonstrated that \"each part ofChatCite framework contributes to the improve- ment of the quality and stability of the generated results in literature summaries\" . 5.4 Human Study To conduct a fine-grained analysis on the quality of summary generated by ChatCite and to understand the specific impact of individual modules on sum- marization, we conducted a human study. Several researchers in the field of computer science, with experience in academic writing, were enlisted to evaluate 10 selected samples using the same set of criteria and choose the better summary. GPT-3.5 w/few shot ChatCite -w/o Topiv ChatCite -w/o Incre',\n",
       " 'ChatCite 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 253.03 3.02 2.26 3.03 3.03 3.03 3.59 3.93 3.63 3.78 3.98 4.17 3.28 3.06 2.5 3.23 3.35 3.33 3.88 4.18 3.96 3.91 4.2 3.95 GPT-3.5 w/few shot ChatCite -w/o Topiv ChatCite -w/o Incre',\n",
       " 'ChatCite 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 Consistency Coherency Comparative Integrity Fluency Cite_Accuracy3.36 3.78 3.13 3.66 4.30 1.70 3.93 4.06 3.79 4.20 4.45 3.60 4.06 4.20 3.58 4.26 4.48 2.44 4.14 4.42 3.75 4.45 4.36 3.71G-ScoresHuman Evaluation Figure 4: Human Evaluation vs.G-Score on six di- mensions of the generic summary quality',\n",
       " 'The scoring results of the G-Score model is aligned with the distri- bution of human evaluations. Figure 4 demonstrates the results of G-score met- ric align with human preferences. Specifically, the method incorporating Key Element Extractor ex- hibits higher content consistency. Summaries gen- erated with the Comparative Incremental gener- Human Preference 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% ChatCite ChatCite -w/o Incre. ChatCite -w/o Topic GPT-3.5 w/few shot51% 13% 26% 1%Figure 5: Human Preference: Average annotator vote distribution for better generated summaries. ation Mechanism demonstrate better characteris- tics of literature review, excelling in organizational structure, comparative analysis, and citation accu- racy',\n",
       " 'The fluency of results generated by LLMs is consistently high, with relatively low variation among different models. In terms of human evalu- ation, summaries generated without the Compara- tive Incremental Mechanism exhibit overly discrete descriptions for each paper, lacking coherence. Un- expectedly, this feature was not captured in the assessment by the large models. Additionally, Figure 5 shows the extinct human preference of the ChatCite model over the others. 6 Conclusion LLMs are powerful tools in generating literature summaries, however, it poses the challenges of information omission, lack of comparative sum- maries and organizational deficiencies. In ChatCite, the Key Element Extractor contributes to improv- ing content consistency, and the Comparative In- cremental Generator effectively enhances the or- ganizational structure, comparative analysis, and citation accuracy of the generated summary. Ad- ditionally, the literature summaries generated by ChatCite can be directly used for drafting litera- ture reviews',\n",
       " 'Our study also demonstrated that the approach following the human workflow guidance is superior to the results obtained by the Chain of Thought (CoT) method. In the future, we hope that our work will further inspire research on complex inferential writing, enabling the full potential of LLMs in open-ended writing tasks.Limitations In this work, we focused mainly on the summariza- tion of specific topics based on the selected litera- tures instead of the collection and the filtering of the literatures themselves. The datasets primarily consist of research articles in the area of computer science and lack research articles from other fields of study to validate our model. Our experimenta- tion used Chat GPT 3.5 as the tool for validating the quality of the generated content and the func- tionalities of the various components of the agent. We did not explore any additional spec that can influence the result of the GPT3.5 model nor the possibility of using other models as the validation tool',\n",
       " 'The evaluation of the generated content poses a great challenge. We evaluated the generated re- sults from multiple dimensions using G-Score as the performance metric, but there is still room for improvements over the accuracy of the automatic evaluation process. The generated results exhibit randomness and instability. While our proposed ap- proach demonstrates the effectiveness of the agent, the results have shown further research potential on improving the stability and quality of the output. Ethics Statement The dataset we used consists of research articles sourced only from publicly available papers, elimi- nating concerns about data origin. We employ large language models as generators used and only used for summarizing people’s ideas and literature and never on the innovative writing processes of the academic papers. However, if generated literature summaries are to be incorporated into academic paper writing, a review and editing of the gener- ated results should be conducted. This ensures that academic writing content is free from harmful information and plagiarism issues. We will make our code publicly available to en- sure experiment reproducibility',\n",
       " 'References Ahmed AbuRa’ed, Horacio Saggion, Alexander Shvets, and Àlex Bravo. 2020. Automatic related work sec- tion generation: experiments in scientific document abstracting. 125(3). Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 .Shubham Agarwal, Issam H. Laradji, Laurent Charlin, and Christopher Pal. 2024. Litllm: A toolkit for scientific literature review. Tom B',\n",
       " 'Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. Xiuying Chen, Hind Alamro, Mingzhe Li, Shen Gao, Xi- angliang Zhang, Dongyan Zhao, and Rui Yan. 2021',\n",
       " 'Capturing relations between scientific papers: An abstractive model for related work section generation. InProceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Lan- guage Processing (Volume 1: Long Papers) , pages 6068–6077, Online. Association for Computational Linguistics. Xiuying Chen, Hind Alamro, Li Mingzhe, Shen Gao, Rui Yan, Xin Gao, and Xiangliang Zhang. 2022. Target-aware abstractive related work generation with contrastive learning. Proceedings of the 45th Inter- national ACM SIGIR Conference on Research and Development in Information Retrieval . Yubin Ge, Ly Dinh, Xiaofeng Liu, Jinsong Su, Ziyao Lu, Ante Wang, and Jana Diesner. 2021. BACO: A background knowledge- and content-based frame- work for citing sentence generation',\n",
       " 'In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) , pages 1466–1478, Online. Association for Computational Linguistics. Tanya Goyal, Junyi Jessy Li, and Greg Durrett. 2023. News summarization and evaluation in the era of gpt-3. Cong Duy Vu Hoang and Min-Yen Kan. 2010. Towards automated related work summarization20. In Col- ing 2010: Posters , pages 427–435, Beijing, China. Coling 2010 Organizing Committee. Jingshan Huang and Ming Tan. 2023. The role of chat- gpt in scientific communication: writing better sci- entific review articles. American Journal of Cancer Research , 13(4):1148. Army Justitia and Hei-Chia Wang. 2022. Automatic related work section in scientific article: Research trends and future directions',\n",
       " 'In 2022 International Seminar on Intelligent Technology and Its Applica- tions (ISITIA) , pages 108–114. IEEE.Chin-Yew Lin. 2004a. Rouge: A package for automatic evaluation of summaries. In Annual Meeting of the Association for Computational Linguistics . Chin-Yew Lin. 2004b. ROUGE: A package for auto- matic evaluation of summaries. In Text Summariza- tion Branches Out , pages 74–81, Barcelona, Spain. Association for Computational Linguistics. Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu. 2023. G-eval: Nlg evaluation using gpt-4 with better human align- ment. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022',\n",
       " 'Training language models to follow instruc- tions with human feedback. Advances in Neural Information Processing Systems , 35:27730–27744. Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. Pancheng Wang, Shasha Li, Haifang Zhou, Jintao Tang, and Ting Wang. 2020. Toc-rwg: Explore the com- bination of topic model and citation information for automatic related work generation. IEEE Access , 8:13043–13055. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023. Chain-of-thought prompting elic- its reasoning in large language models. Xinyu Xing, Xiaosheng Fan, and Xiaojun Wan. 2020',\n",
       " 'Automatic generation of citation texts in scholarly papers: A pilot study. In Annual Meeting of the Association for Computational Linguistics .A Appendix A.1 An Example of generated results of all the models mentioned Table 3: An Example of literature summary results generated for Paper: BEL: Bagging for Entity Linking Gold literature Summary Statistical machine translation systems often rely on large-scale parallel and monolingual training corpora to generate translations of high quality. Unfortunately, statistical machine translation system often suffers from data sparsity problem due to the fact that phrase tables are extracted from the limited bilingual corpus. Much work has been done to address the data sparsity problem such as the pivot language approach (Wu and Wang,2007; Cohn and Lapata, 2007) and deep learning techniques (Devlin et al., 2014; Gao et al., 2014; Sundermeyer et al., 2014; Liu et al., 2014)',\n",
       " 'On the problem of how to translate one source language to many target languages within one model, few work has been done in statistical machine translation. A related work in SMT is the pivot language approach for statistical machine translation which uses a commonly used language as a ”bridge” to generate source-target translation for language pair with few training corpus. Pivot based statistical machine translation is crucial in machine translation for resource-poor language pairs, such as Spanish to Chinese. Considering the problem of translating one source language to many target languages, pivot based SMT approaches does work well given a large-scale source language to pivot language bilingual corpus and large-scale pivot language to target languages corpus. However, in reality, language pairs between English and many other target languages may not be large enough, and pivot-based SMT sometimes fails to handle this problem. Our approach handles one to many target language translation in a different way that we directly learn an end to multi-end translation system that does not need a pivot language based on the idea of neural machine translation',\n",
       " 'Neural Machine translation is a emerging new field in machine translation, proposed by several work recently (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2014), aiming at end-to-end machine translation without phrase table extraction and language model training. Different from traditional statistical machine translation, neural machine translation encodes a variable-length source sentence with a recurrent neural network into a fixed-length vector representation and decodes it with another recurrent neural network from a fixed-length vector into variable-length target sentence. A typical model is the RNN encoder-decoder approach proposed by Bahdanau et al. (2014), which utilizes a bidirectional recurrent neural network to compress the source sentence information and fits the conditional probability of words in target languages with a recurrent manner. Moreover, soft alignment parameters are considered in this model',\n",
       " 'As a specific example model in this paper, we adopt a RNN encoder-decoder neural machine translation model for multi-task learning, though all neural network based model can be adapted in our framework. In the natural language processing field, a1724 notable work related with multi-task learning was proposed by Collobert et al. (2011) which shared common representation for input words and solve different traditional NLP tasks such as part-of-Speech tagging, name entity recognition and semantic role labeling within one framework, where the convolutional neural network model was used. Hatori et al. (2012) proposed to jointly train word segmentation, POS tagging and dependency parsing, which can also be seen as a multi-task learning approach. Similar idea has also been proposed by Li et al. (2014) in Chinese dependency parsing. Most of multi-task learning or joint training frameworks can be summarized as parameter sharing approaches proposed by Ando and Zhang (2005) where they jointly trained models and shared center parameters in NLP tasks',\n",
       " 'Researchers have also explored similar approaches (Sennrich et al., 2013; Cui et al., 2013) in statistical machine translation which are often refered as domain adaption. Our work explores the possibility of machine translation under the multitask framework by using the recurrent neural networks. To the best of our knowledge, this is thefirst trial of end to end machine translation under multi-task learning framework.ChatCite with GPT-3.5 Related Work The field of machine translation has witnessed remarkable progress in addressing data scarcity and enhancing translation quality. Early approaches such as the pivot language approach proposed by Wu and Wang (2007) [Reference 1], and the triangulation method introduced by Cohn and Lapata (2007) [Reference 2], focused on improving phrase-based statistical machine translation, particularly for language pairs with scarce resources. Additionally, Devlin et al',\n",
       " '(2014) [Reference 3] contributed by introducing a neural network joint model (NNJM) for machine translation, offering valuable insights into the formulation of a novel neural network joint model and techniques for enhancing machine translation performance. Moreover, Gao et al. (2014) [Reference 4] enriched the understanding of addressing data scarcity and improving translation quality by introducing a Continuous-space Phrase Translation Model (CPTM) to project source and target phrases into continuous-valued vector representations, complementing the approaches of previous researchers. Furthermore, Sundermeyer et al. (2014) [Reference 5] expanded the scope of machine translation by investigating the effectiveness of recurrent neural networks in translation modeling, contributing to the broader landscape of machine translation research. In the context of the target paper, which proposed a multi-task learning framework for machine translation, the works by Zhenghua Li et al',\n",
       " '(2011) [Reference 6] and Nal Kalchbrenner and Phil Blunsom (2013) [Reference 7] proved highly relevant. Zhenghua Li et al. (2011) proposed joint optimization for Chinese POS tagging and dependency parsing, offering valuable insights into joint optimization techniques. Similarly, Nal Kalchbrenner and Phil Blunsom (2013) [Reference 7] introduced recurrent continuous translation models (RCTMs), providing a new perspective in the domain of machine translation and contributing to the advancement of purely continuous sentence-level translation models. The work by Ilya Sutskever, Oriol Vinyals, and Quoc V . Le (2014) [Reference 8] on sequence to sequence learning with neural networks is also highly relevant to the target paper’s objectives',\n",
       " 'The paper addresses the challenge of mapping sequences to sequences using Deep Neural Networks (DNNs) and proposes a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure, aligning with the multi-task learning framework proposed in the target paper. Additionally, the 9th reference paper by Ronan Collobert et al. (2011) [Reference 9] addresses the effectiveness of leveraging large unlabeled datasets and multitask supervised training to improve performance, aligning with the multi-task learning framework proposed in the target paper. The recently explored Incremental Joint Approach to Word Segmentation, POS Tagging, and Dependency Parsing in Chinese by Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and Jun (2012) [Reference 10] presents a joint model for word segmentation, POS tagging, and dependency parsing for Chinese, demonstrating significant improvements in accuracies of the three tasks over baseline models',\n",
       " 'The study’s positive results in Chinese segmentation accuracies and the effectiveness of the proposed joint model are highly relevant to the advancements in multi-task learning frameworks for machine translation, providing further insights into joint model approaches and their potential for improving translation quality. The 11th reference paper by Rie Kubota Ando and Tong Zhang (2005) focuses on learning predictive structures from multiple tasks and unlabeled data. It attempts to improve the performance of supervised learning algorithms by including unlabeled data and investigates a closely related problem that leads to a novel approach to semi-supervised learning. The paper introduces a general framework for structural learning and proposes algorithms for structural learning, demonstrating the effectiveness of the proposed algorithms in semi-supervised learning. In a similar vein, the proposed multi-task learning framework in the target paper aims to improve the translation quality and address data scarcity by leveraging multiple tasks and large-scale parallel training corpora',\n",
       " 'By integrating insights from Rie Kubota Ando and Tong Zhang (2005) [Reference 11] with existing literature, the target paper aligns with the broader trend of leveraging multiple tasks and unlabeled data to enhance machine learning models. The contributions of both the target paper and the referenced works collectively enrich the understanding of addressing data scarcity, enhancing translation quality, and advancing the capabilities of machine translation models, laying the foundation for the multi-task learning framework proposed in the target paper. These contributions provide valuable insights into the advancements in machine translation, emphasizing contributions to the research field and predicting potential future directions.ChatCite without Key Elements Extractor Related Work The field of machine translation has witnessed significant advancements in overcoming challenges related to limited training resources and enhancing translation quality across various language pairs. Notably, approaches such as the pivot language method, multi-parallel corpora, and the triangulation method have been explored to address scenarios with limited training data [Radford et al. (2019)[Reference 5]]',\n",
       " 'Additionally, the development of neural network joint models (NNJM) [Sutskever, Vinyals, and Le (2014)[Reference 8]] and the integration of bidirectional recurrent neural networks have shown promise in improving translation quality, particularly for language pairs with limited resources. In alignment with these developments, the target paper focuses on the translation of sentences from a source language to multiple target languages using a multi-task learning framework inspired by neural machine translation. This approach not only demonstrates substantial progress in machine translation, especially for languages with limited training resources but also introduces a neural network joint model (NNJM) for statistical machine translation, aligning with the innovative approaches presented in the referenced studies and offering promise for enhancing translation quality for language pairs with limited resources',\n",
       " 'Moreover, Ïncremental joint approach to word segmentation, POS tagging, and dependency parsing in Chinese ¨[Reference 10] proposes a joint model for word segmentation, POS tagging, and dependency parsing in Chinese, showing improvements particularly for out-of-vocabulary words. This study contributes to a comprehensive understanding of the methods used to address challenges in machine translation and natural language processing. Expanding on these foundations, the 11-th reference paper introduces a framework for learning predictive structures from multiple tasks and unlabeled data. This framework presents a general approach for formulating and analyzing the structural learning problem in the context of learning with unlabeled data, demonstrating its relevance to the challenges in machine translation. The proposed algorithm for joint empirical risk minimization is particularly notable, as it addresses the problem of learning predictive structures on hypothesis spaces from multiple learning tasks, aligning with the multi-task learning framework proposed in the target paper',\n",
       " 'Furthermore, the experiments presented in the 11-th reference show significant performance improvements over supervised methods in various tasks, indicating the effectiveness of the proposed framework in semi-supervised learning settings. In summary, the integrated literature on machine translation and natural language processing contributes valuable insights for the development of machine translation systems, offering innovative approaches to enhance translation quality, particularly for language pairs with limited resources. The introduction of the framework for learning predictive structures from multiple tasks and unlabeled data adds a new dimension to the existing research landscape, emphasizing the potential for semi-supervised learning to address challenges in machine translation and natural language processing. These advancements collectively pave the way for potential future research directions in the field of machine translation.ChatCite without Reflective Incremental Generator Related Work The related work section provides an overview of the literature relevant to the target paper’s research topic, which aims to address the problem of learning a machine translation model that can simultaneously translate sentences from one source language to multiple target languages',\n",
       " 'The related work encompasses various studies in the field of machine translation, natural language processing, and neural network models. [1] Hua Wu and Haifeng Wang (2007) proposed a pivot language approach for phrase-based statistical machine translation, which addresses the translation problem for language pairs with scarce resources by using a pivot language and making use of large bilingual corpora without language-dependent resources or deep linguistic processing. The study demonstrated the effectiveness of the pivot language method for translation on language pairs with a small bilingual corpus. [2] Trevor Cohn and Mirella Lapata (2007) introduced the method of triangulation for translation modeling, which translates from a source to a target language via an intermediate third language, to exploit multi-parallel corpora for training and improve the coverage and quality of phrase-based statistical machine translation. The research focused on addressing the issue of poor performance of current phrase-based SMT systems when using small training sets. [3] Jacob Devlin et al',\n",
       " '(2014) formulated a neural network joint model (NNJM) for machine translation, along with techniques to overcome the high cost of using NNLM-style models in MT decoding. The study demonstrated significant improvements in machine translation performance using the proposed NNJM and its variations. [4] Jianfeng Gao et al. (2014) introduced the Continuous-space Phrase Translation Model (CPTM) to address the sparsity problem in estimating phrase translation probabilities by learning continuous phrase representations. The study demonstrated substantial improvement over the baseline system with a statistically significant margin. [5] Martin Sundermeyer et al. (2014) explored the effectiveness of recurrent neural networks in translation modeling, specifically focusing on word-based and phrase-based approaches, as well as the inclusion of bidirectional architectures. The research demonstrated improvements over strong baselines in translation modeling. [6] Zhenghua Li et al. (2011) proposed a joint optimization approach for Chinese POS tagging and dependency parsing, showcasing significant improvements in parsing accuracy',\n",
       " 'The study addressed the issue of error propagation in parsing accuracy due to using automatic POS tags instead of gold ones. [7] Nal Kalchbrenner and Phil Blunsom (2013) introduced Recurrent Continuous Translation Models (RCTMs), demonstrating their translation capabilities and low perplexities with respect to reference translations. The study highlighted the sensitivity of RCTMs to word order, syntax, and meaning despite lacking alignments. [8] Ilya Sutskever et al. (2014) presented a general end-to-end approach to sequence learning using Deep Neural Networks (DNNs) for mapping sequences to sequences, showcasing the outperformance of the proposed LSTM-based approach over a mature SMT system. [9] Ronan Collobert et al. (2011) proposed a unified neural network architecture and learning algorithm for various natural language processing tasks, demonstrating the effectiveness of leveraging large unlabeled datasets and multitask supervised training to improve performance. [10] Jun Hatori et al',\n",
       " '(2012) introduced an incremental joint approach to word segmentation, POS tagging, and dependency parsing for Chinese, showcasing substantial improvements in the accuracies of the three tasks over baseline models. [11] Rie Kubota Ando and Tong Zhang (2005) proposed a framework for learning predictive structures from multiple tasks and unlabeled data, demonstrating significant performance improvements over supervised methods in various tasks through structural learning. These studies collectively contribute to the field of machine translation, natural language processing, and neural network models, providing insights and advancements that are relevant to the target paper’s research on learning a machine translation model for translating sentences from one source language to multiple target languages',\n",
       " 'The innovations and findings from these studies serve as valuable background and insights for the target research, highlighting the significance of the related work to the target study and potential future research directions in the field.GPT-3.5 with zero shot Related Work Section: The proposed multi-task learning framework for translating sentences from one source language to multiple target languages using a machine translation model builds upon and is related to several key works in the field of machine translation and natural language processing. 1. Pivot language approach for phrase-based statistical machine translation The article ¨Pivot language approach for phrase-based statistical machine translation ¨proposes a method for phrase-based statistical machine translation using a pivot language to address translation problems for language pairs with scarce resources. This method is related to the challenge of translating between languages with limited parallel data, which is also addressed in the target paper. The pivot language approach demonstrates the effectiveness of utilizing large bilingual corpora from a pivot language to improve translation quality, especially for language pairs with limited training data. 2',\n",
       " 'Machine translation by triangulation: Making effective use of multi-parallel corpora The article discusses the method of triangulation, which involves translating from a source to a target language via an intermediate third language, aiming to improve machine translation systems by exploiting multi-parallel corpora. This work is relevant to the target paper as it addresses the issue of improving translation quality using a wider range of parallel corpora, particularly with small training sets and for translating between low-density language pairs. 3. Fast and robust neural network joint models for statistical machine translation The article presents a novel neural network joint model (NNJM) for statistical machine translation, which is related to the use of neural network models in machine translation. The NNJM augments a neural network language model with a source context window and is purely lexicalized, demonstrating significant improvements in BLEU scores. This work is relevant to the target paper’s exploration of neural machine translation and the effectiveness of neural network-based models in improving translation quality. 4',\n",
       " 'Learning continuous phrase representations for translation modeling The article introduces a novel phrase translation model, the Continuous-space Phrase Translation Model (CPTM), which addresses the sparsity problem in estimating phrase translation probabilities. This work is related to the target paper’s exploration of continuous representations and their use in improving translation accuracy. The CPTM significantly improves the accuracy of a state-of-the-art phrase-based SMT system, demonstrating its effectiveness in improving translation quality. 5. Translation modeling with bidirectional recurrent neural networks The article presents two different translation models using recurrent neural networks, demonstrating their capability to improve machine translation performance. This work is related to the target paper in showcasing the effectiveness of recurrent neural networks in improving translation quality, particularly with the use of bidirectional recurrent models. 6. Joint optimization for Chinese POS tagging and dependency parsing The article discusses the importance of joint optimization for Chinese POS tagging and dependency parsing, proposing a unique model to optimize both tasks',\n",
       " 'This work is related to the target paper’s exploration of joint learning frameworks and their impact on improving parsing accuracy, demonstrating the potential of joint optimization for improving translation quality. 7. Recurrent continuous translation models The article introduces a class of probabilistic continuous translation models called Recurrent Continuous Translation Models (RCTMs), which are purely based on continuous representations for words, phrases, and sentences. This work is related to the target paper’s exploration of continuous representations and their potential in estimating translation quality, highlighting the effectiveness of RCTMs in capturing syntactic and semantic information. 8. Sequence to sequence learning with neural networks The article discusses the use of Deep Neural Networks (DNNs) for sequence to sequence learning, particularly in the context of machine translation. This work is related to the target paper’s exploration of neural network-based models and their effectiveness in improving translation performance, demonstrating the potential of sequence to sequence learning with neural networks for various sequence to sequence problems. 9',\n",
       " 'Incremental joint approach to word segmentation, POS tagging, and dependency parsing in Chinese The article proposes a joint model for word segmentation, POS tagging, and dependency parsing in Chinese, demonstrating significant improvements in accuracies for all three tasks over baseline models. This work is related to the target paper’s exploration of joint learning frameworks and their impact on improving translation quality, particularly in the context of joint modeling for multiple language translation tasks. 10. A framework for learning predictive structures from multiple tasks and unlabeled data The article presents a framework for learning predictive structures from multiple tasks and unlabeled data, addressing the concept of semi-supervised learning and the problem of learning predictive structures on hypothesis spaces from multiple learning tasks. This work is related to the target paper’s exploration of multi-task learning frameworks and their effectiveness in improving translation quality, particularly in the context of learning from multiple tasks and unlabeled data',\n",
       " 'The related work presented here demonstrates the diverse approaches and techniques employed in the field of machine translation and natural language processing, providing valuable insights and methods that contribute to the advancement of multi-task learning frameworks and neural machine translation models for improving translation quality.GPT-3.5 with few shot Related Work Section: The related work section will include a review of existing literature and studies that are relevant to the topic of multi-task learning for machine translation and related methods for improving translation quality. The section will discuss the following papers: 1.¨Pivot language approach for phrase-based statistical machine translation ¨- This study proposes a new method for phrase-based statistical machine translation using a pivot language to address translation problems for language pairs with scarce resources. The method demonstrates the use of large bilingual corpora from a pivot language to improve translation quality for language pairs with limited training data',\n",
       " '2.¨Machine translation by triangulation: Making effective use of multi-parallel corpora ¨- The article discusses a method for improving machine translation systems by exploiting multi-parallel corpora. The proposed method, called triangulation, involves translating from a source to a target language via an intermediate third language, allowing the use of a wider range of parallel corpora for training. 3.¨Fast and robust neural network joint models for statistical machine translation ¨- This article discusses the development of a novel neural network joint model (NNJM) for statistical machine translation (SMT). The NNJM augments a neural network language model (NNLM) with a source context window and demonstrates significant improvements in translation quality. 4.¨Learning continuous phrase representations for translation modeling ¨- The study presents a novel phrase translation model for statistical machine translation (SMT) that addresses the sparsity problem in estimating phrase translation probabilities',\n",
       " 'The model utilizes continuous phrase representations to improve the accuracy of a state-of-the-art phrase-based SMT system. 5.¨Translation modeling with bidirectional recurrent neural networks ¨- The article introduces two different translation models using recurrent neural networks and demonstrates their effectiveness in improving machine translation performance on various tasks. 6.¨Recurrent continuous translation models ¨- This study introduces a class of probabilistic continuous translation models called Recurrent Continuous Translation Models (RCTMs) and demonstrates their potential in capturing syntactic and semantic information and estimating translation quality. 7.¨Sequence to sequence learning with neural networks ¨- The article discusses the use of Deep Neural Networks (DNNs) for sequence to sequence learning and demonstrates the effectiveness of this approach on an English to French translation task. 8',\n",
       " 'Ïncremental joint approach to word segmentation, POS tagging, and dependency parsing in Chinese ¨- The article proposes a joint model for word segmentation, POS tagging, and dependency parsing in Chinese and demonstrates significant improvements in accuracies for all three tasks over baseline models. 9. Ä framework for learning predictive structures from multiple tasks and unlabeled data ¨- The study presents a framework for learning predictive structures from multiple tasks and unlabeled data, demonstrating significant performance improvements over supervised methods in various text categorization, named entity chunking, part-of-speech tagging, and hand-written digit image classification tasks. GPT-4.0 with zero shot Based on the given information, here is a related work section for the target paper: Related Work The problem of learning from multiple tasks and utilizing unlabeled data has been an area of significant research interest in machine learning and natural language processing (NLP)',\n",
       " 'The concept of semi-supervised learning, which involves the use of both labeled and unlabeled data, has been explored in various studies with the aim of improving the performance of supervised learning algorithms. Vapnik introduced the notion of transductive inference, which is a form of semi-supervised learning, although its effectiveness has been debated (Vapnik, 1998; Zhang and Oles, 2000). Co-training, another semi-supervised approach, was proposed by Blum and Mitchell (1998) and is related to the bootstrap method used in NLP applications (Yarowsky, 1995). However, the effectiveness of co-training can be limited by the assumptions made by the method and the potential introduction of noise into the labels (Pierce and Cardie, 2001). The idea of learning predictive structures from multiple tasks, also known as structural learning or multi-task learning, has been discussed in the literature',\n",
       " 'Ando and Zhang (2005) presented a framework for structural learning where multiple tasks are used to discover a shared low-dimensional predictive structure. This approach is based on the principle that a good hypothesis space should have a small approximation error and a small estimation error. The authors proposed an algorithm for structural learning that finds a common low-dimensional feature space shared by multiple problems. Their method was shown to be effective in semi-supervised learning settings, improving the performance of various NLP tasks. In the context of NLP, the joint approach to tasks such as word segmentation, POS tagging, and dependency parsing has been explored. Hatori et al. (2012) proposed an incremental joint model for Chinese POS tagging and dependency parsing, demonstrating improvements over baseline models. The work by Kubota Ando and Zhang (2005) extends this idea to a joint model that simultaneously processes word segmentation, POS tagging, and dependency parsing, capturing global interactions among these tasks',\n",
       " 'Their model employs an efficient character-based decoding method that combines features from state-of-the-art segmentation, POS tagging, and dependency parsing models. The use of external resources, such as dictionaries, has also been considered in joint models to enhance performance. Wang et al. (2011) used semi-supervised methods with large auto-analyzed data to improve Chinese word segmentation and POS tagging. The incorporation of syntactic information has been shown to improve the segmentation of out-of-vocabulary words, which is a common challenge in languages like Chinese where transliterated words often include characters used as common or function words. Overall, the related work demonstrates the potential of joint and semi-supervised approaches in leveraging multiple tasks and unlabeled data to improve the performance of machine learning models in NLP tasks',\n",
       " 'The target paper builds upon these concepts by proposing a unified framework that avoids task-specific engineering and learns internal representations from vast amounts of unlabeled data, achieving good performance across various NLP tasks.GPT-4.0 with few shot The examples provided discuss the use of Large Language Models (LLMs) as proxies for human behaviors and the systematic study of LLMs’ personalities based on established personality trait theories. Here’s a summary of the key points from the examples: 1. LLMs Mimicking Human Behaviors: - Recent studies have shown that LLMs can mimic human behaviors, including reasoning and cognitive abilities, as well as participate in social science experiments. - These studies are mostly empirical and based on case-by-case observations. 2. Systematic Study of LLMs’ Personalities: - The authors propose a systematic and quantitative approach to study LLMs’ behaviors by evaluating and inducing personality traits in LLMs. - This approach does not require supervised fine-tuning or human evaluation of generated utterances. 3',\n",
       " 'Personality Trait Theories: - The Big Five and Sixteen Personality Factors (16PF) are two prominent theories that provide consistent descriptions of individual differences. - Psychometric tests based on these theories, such as NEO-PI-R, are effective in assessing personality traits and have shown that human differences can be categorized into continuous factor dimensions. 4. Correlation Between Personality and Behavior: - Empirical studies have confirmed a strong correlation between personality traits and real-world human behaviors. - Specifically, there is a significant link between the Big Five traits and language use, suggesting that personality influences how people communicate. The examples highlight the potential of LLMs to simulate complex human-like behaviors and the importance of understanding the personality traits of these models for various applications',\n",
       " 'LitLLM with GPT-4.0 The Unified Neural Network Model for NLP Tasks Natural Language Processing (NLP) tasks such as part-of-speech (POS) tagging, chunking, named entity recognition (NER), and semantic role labeling (SRL) are essential for understanding and generating human language. Traditional approaches to these tasks often involve task-specific feature engineering, which can be labor-intensive and may not generalize well to new tasks or datasets. To address these issues, researchers have proposed unified neural network models that can learn to perform multiple NLP tasks simultaneously without extensive feature engineering. These models leverage large amounts of both labeled and unlabeled data to learn useful representations for words, phrases, and sentences that capture syntactic and semantic information. One such model is the Long Short-Term Memory (LSTM) network, which has been shown to be effective for sequence-to-sequence learning tasks like machine translation',\n",
       " 'LSTMs can process input sequences of variable lengths and learn long-range dependencies, making them suitable for NLP tasks. They can be trained end-to-end with backpropagation and can learn from both supervised and unsupervised data. Another approach is the use of semi-supervised learning methods, which combine labeled and unlabeled data to improve model performance. For example, structural learning algorithms can learn predictive structures from multiple tasks and use them to enhance the performance of individual tasks. This can be particularly useful when there is a large amount of unlabeled data available. The success of these unified neural network models demonstrates the potential of using deep learning techniques for NLP tasks',\n",
       " 'By avoiding task-specific engineering and leveraging large datasets, these models can achieve state-of-the-art performance on a variety of benchmarks, making them valuable tools for researchers and practitioners in the field of NLP.\"A.2 Related work draft for this paper generated by ChatCite with GPT-4.0 Table 4: We show the related work summary using this paper and our collection of related work papers generated by the ChatCite model based on GPT-4.0 (gpt-4-turbo-preview version). It can be observed that the citations in the paper are consistent with those in the collection, the content is accurate at the same time. We utilized this summary as a draft and, completed our related work section after some minor modifications',\n",
       " 'Generated literature summary for this paper In the evolving landscape of automated scholarly writing, particularly in the domain of literature review summarization, the proposed ChatCite framework within our target paper represents a significant advancement, aiming to harness the capabilities of Large Language Models (LLMs) to generate high-quality related work summaries. The foundational work in this field began with hierarchical keyword structures for extractive summarization [Reference 1], and has progressed through various iterations including multi-source pointer-generator networks [Reference 2], and sophisticated models like the ARWG system [Reference 3], BACO [Reference 4], and the Relation-aware Related work Generator (RRG) [Reference 5]. The introduction of contrastive learning to improve summarization quality [Reference 6], and automatic citation sentence generation methods [Reference 7], have further refined the capabilities of LLMs in this space',\n",
       " 'Recent studies have concentrated on the unsupervised and few-shot learning capabilities of LLMs, notably GPT-3, establishing a solid groundwork for AI application in scholarly communication [References 8-9]. The exploration of AI tools such as ChatGPT by Huang, Jingshan, and Ming Tan (2023) [Reference 10] in crafting scientific review articles, sheds light on both the potential benefits and drawbacks of AI in academic writing, such as enhancement in speed and quality versus risks of inaccuracies and bias. Building on these insights, the LitLLM toolkit suggested by Shubham Agarwal, Issam H. Laradji et al. (2024) [Reference 11] brings novel approaches to overcome challenges like the generation of hallucinated content and the overlooking of recent studies by employing Retrieval Augmented Generation (RAG) principles, specialized prompting, and instructive techniques',\n",
       " 'This showcases a significant alignment with our target paper’s objectives, particularly in mitigating hallucinations and enhancing summarization accuracy through the ChatCite framework. The latest contribution in this domain is presented by Yang Liu, Dan Iter, et al. (2023) [Reference 12] through the G-EV AL framework, which introduces a methodology for evaluating the quality of texts generated by natural language generation (NLG) systems using LLMs, leveraging chain-of-thoughts (CoT) and a form-filling paradigm. This approach, which significantly outperforms previous methods in evaluating the creativity and diversity required in text generation tasks, aligns closely with the goals of the ChatCite framework, especially in its pursuit of generating high-quality literature summaries',\n",
       " 'The G-EV AL framework not only surpasses all previous state-of-the-art evaluators on the SummEval and Topical-Chat benchmarks but also underscores the importance of instruction sensitivity and the benefits of a CoT approach, which could potentially inform future enhancements in the ChatCite framework [Reference 12]. By evaluating the quality of NLG outputs, [Reference 12] addresses the limitations identified in prior works, including the potential bias of LLM-based evaluators towards LLM-generated texts, and calls for further research to understand the behavior of LLM-based evaluators fully. This contribution is particularly relevant to our target paper, which aims to enhance the quality and stability of literature review summarizations generated by LLMs. Thus, integrating insights from G-EV AL [Reference 12] can provide a more nuanced understanding of evaluating the effectiveness of automated scholarly writing tools, highlighting a potential area for future development within the scope of the ChatCite framework',\n",
       " 'In summary, the development of automated scholarly writing, particularly in literature review summarization, has progressed through key innovations in LLM capabilities, methodological enhancements, and now, through improved evaluation frameworks. This journey from extractive summarization to sophisticated LLM-based frameworks underscores a collaborative advancement in the field, with each contribution building upon the last to address emerging challenges and achieve greater accuracy, efficiency, and relevance in automated scholarly writing. The ChatCite framework, supported by insights from references [References 1-12], continues this trajectory by proposing innovative solutions to the challenges in literature review summarization, setting a platform for further exploration and innovation in the field.',\n",
       " '2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM) FABULA: Intelligence Report Generation Using Retrieval-Augmented Narrative Construction Priyanka Ranade Department of CSEE University of Maryland, Baltimore County Baltimore, MD, USA priyankaranade@umbc.eduAnupam Joshi Department of CSEE University of Maryland, Baltimore County Baltimore, MD, USA joshi@umbc.edu Abstract —Narrative construction is the process of representing disparate event information into a logical plot structure that models an end to end story. Intelligence analysis is an example of a domain that can benefit tremendously from narrative construc- tion techniques, particularly in aiding analysts during the largely manual and costly process of synthesizing event information into comprehensive intelligence reports. Manual intelligence report generation is often prone to challenges such as integrating dynamic event information, writing fine-grained queries, and closing information gaps',\n",
       " 'This motivates the development of a system that retrieves and represents critical aspects of events in a form that aids in automatic generation of intelligence reports. We introduce a Retrieval Augmented Generation (RAG) ap- proach to augment prompting of an autoregressive decoder by retrieving structured information asserted in a knowledge graph to generate targeted information based on a narrative plot model. We apply our approach to the problem of neural intelligence report generation and introduce FABULA, framework to aug- ment intelligence analysis workflows using RAG. An analyst can use FABULA to query an Event Plot Graph (EPG) to retrieve relevant event plot points, which can be used to augment prompting of a Large Language Model (LLM) during intelligence report generation. Our evaluation studies show that the plot points included in the generated intelligence reports have high semantic relevance, high coherency, and low data redundancy. Index Terms —retrieval augmented generation, large language models, knowledge graphs, narratives I',\n",
       " 'I NTRODUCTION The process by which information about critical events is disseminated, articulated, and shaped into news stories has greatly evolved since the proliferation of digital media and the World Wide Web. Intelligence analysts now take advantage of an abundance of online communication mediums to widely share and obtain reporting on a variety of critical events. Intelligence analysts rely heavily on manual techniques to extract evolving fine-grained event details over multiple Open Source Intelligence (OSINT) sources in real-time . Thisevaluated information is then manually documented within an intelligence report, which is used during tactical operations by decision makers to manage, evaluate, and keep updated on evolving events, such as breaking news occurrences. Intelligence reports are inherently structured to communi- cate narratives , which are accounts of interconnected event incidents and actors (plot points) evolving through some notion of time. In journalism and storytelling, there have been several types of narrative plot structures proposed to organize and convey event information',\n",
       " 'One of the most well suited for intelligence analysis is the Inverted Plot Pyramid (IPP) narrative structure (Figure 2, Section II-A) which is designed specifically for conveying news event details. It is becoming more clear that the intelligence analysis domain can bene- fit tremendously from techniques in computational narrative construction , which utilize existing Information Retrieval (IR) methods such as document collection, query processing, and ranking to aid end users in comprehending disparate event information. Specifically, integrating narrative construction tasks to intelligence analysis workflows can alleviate the costly nature of intelligence report generation in three primary ways: (a) Automatically extracting event information from a dense collection of documents based on a schema, (b) Aiding in information triage during intelligence report generation, (c) Tracking and integrating evolving event information over time. Recent advancements in Large Language Models (LLMs) have enabled state of the art results in automatic text genera- tion tasks, presenting new opportunities in the computational narrative construction domain',\n",
       " 'For example, an end user can issue directed prompts to a generative LLM to automatically generate summaries that communicate end to end narratives about an event. Similarly, we envision that an intelligence analyst can prompt an LLM to automatically generate accu- rate intelligence reports about queried events. Despite these potential benefits, a direct application of LLMs for automatic intelligence report generation presents several limitations, such as: (a) Output hallucinations where the generated text contains non-factual, non-event related, and incomplete information, (b) Lack of provenance, attribution, and trust for knowledge sources used to generate responses. The AI community has started to address these challenges through a general approach called Retrieval Augmented Generation (RAG) which usesPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page',\n",
       " 'Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. ASONAM ’23 , November 6-9, 2023, Kusadasi, Turkey © 2023 Association for Computing Machinery. ACM ISBN 979-8-4007-0409-3/23/11. $15.00 https://doi.org/10.1145/3625007.3627505arXiv:2310.13848v1 [cs.IR] 20 Oct 2023non-parametric memory to augment LLM generation',\n",
       " 'Inspired by these recent developments, we develop FAB- ULA, a framework that integrates a novel RAG approach for using narrative plot structures, LLMs, and knowledge graphs to automatically generate intelligence reports (Figure 1). The main contributions of this paper include: •FABULA: A framework to augment intelligence analysis workflows. Analysts can use the system to automatically generate intelligence reports for events utilizing contex- tual narrative features found in OSINT (Section III). •Retrieval-Augmented Generation (RAG) approach which retrieves plot points from a knowledge graph and provides them as input prompt sets for guided LLM intelligence report generation (Section V-C). II. R ELATED WORK In this section, we describe research on narratives, news event OSINT, knowledge representation, and data to text generation. A. Narratives, Stories, & News OSINT about events , are published via blogs, social net- works, news sources',\n",
       " 'Events contain plot points , which are incidents that directly impact what happens next [1]. Events are communicated through the form of narratives which are accounts of interconnected plot points [2]. A seminal example of a narrative plot structure is the Plot Pyramid Model by Gustav Freytag, a five component framework that outlines thematic and temporal stages in generic storytelling [3]. The components are, Introduction, Rising Action, Climax, Falling Action, and Denouement . The plot points in the Freytag pyramid develop and conclude progressively over time, first leading to the development of the climax (introduction and rising action) and successively concluding to the denouement as a direct result of the climax (falling action). Unlike the pyramid, other narrative plot structures organize plot points in varying ways. For example, the Fichtean Curve , begins immediately with the rising action component, followed by a series of crisis (falling action) [4]',\n",
       " 'There are several more examples of other narrative plot structures such The Hero’s Journey that model the development of events differently [4]. Our system FABULA, focuses specifically on modeling the plot structure of open source news events . A narrative plot structure specifically developed for communicating news stories is the Inverted Plot Pyramid (IPP) (Figure 2). IPP is a three component model that conveys the critical plot points in the first component (Lead) , the event developments (Body) , and the nonobligatory information at the end (Tail) [5]. B. Narrative Construction and Schemas Sequencing disparate events from a variety of sources is known as fragmented narrative construction [2]. While the disparate nature of OSINT provides opportunities for users to obtain insights, it presents challenges for chaining accurate data across noisy sources [6]. There have been several methods that address this problem. One is by sequencing causal andtemporal event shifts into story chains . Zhu et al',\n",
       " '[7] defines a story chain as “a construction of news articles that reveal hidden relationships among different events”. They utilize random walks on a bipartite graph to form a coherent story chain based on a query. Prior to this work, research projects have ordered news based on hierarchy [8], [9]. A novel method utilized in our FABULA system for extracting narratives is through the use of narrative schemas. Narrative schemas are models used to represent primary components of a narrative, such as actors, plot points, and actions [10]. C. Information Retrieval & Knowledge Representation Information Retrieval (IR) systems have evolved from symbolic-based methods [11] to neural retrieval models [12]. These capture semantic matches using neural networks to build vectorized knowledge representations. Representation tech- niques such as Knowledge Graphs (KG), have been popularly employed to support IR tasks [13]. D',\n",
       " 'Knowledge Graph (KG) to Text Generation The KG-to-text generation task is a form of semantic triple verbalization, which automatically generates descriptive text for a given KG [14], [15]. State of the art methods fine-tune text-to-text and generative decoder pre-trained models with KG-to-text datasets. One approach to this problem is Retrieval Augmented Generation (RAG), a method that aims to seed external data is a technique that uses retrieved data that is stored externally (like in a KG) from the foundation model, which is used to augment LLM prompting by injecting relevant retrieved information. III. M ETHODOLOGY Fig. 1. FABULA System Architecture and Data Flow',\n",
       " 'This work is guided by the following research question: Does incorporating narrative-based features during Retrieval- Augmented Generation (RAG) produce intelligence reports with high semantic relevance, high event coherency, and littleto no hallucination? Our approach is applied and evaluated specifically in the context of narrative construction for news events represented in open sourced news articles. Suppose we have a set of randomly ordered articles d1, d2...,dn, retrieved by a keyword search query about an event e, which contain several plot points p1,p2...,pn. Each plot point is extracted, ranked, and ordered into a chronological sequence. Consider a real-world example where an intelligence analyst requires information about a critical event e. The analyst will input a query about e, retrieve relevant information from a multiple set of sources (news blogs, social media posts) to write a condensed intelligence report',\n",
       " 'We develop FAB- ULA, an analyst-augmentation framework that integrates real- time news event retrieval, narrative schema-based information extraction and representation of event concept information, and retrieval-augmented generation (RAG) of intelligence reports. Our approach is displayed in Figure 1. We begin by creating anews intelligence corpus from popular news sources and publicly available U.S Intelligence Community (IC) reports, described in Section IV-A. This corpus is further condensed through information extraction of plot points contained within news articles and follows the Inverted Plot Pyramid (IPP) narrative structure (Section IV-B). The extracted plot points are then asserted into an Event Plot Graph (EPG) using our base Event Narrative Ontology (ENO) schema (Section IV-C). Next, we fine-tune the LLM, GPT-Neo [16] using our news intelligence corpus and the extracted plot points V-A)',\n",
       " 'FABULA’s EPG is queried using Retrieval Augmented Generation (RAG) to control GPT-Neo’s intelligence report generation process. Fig. 2. The Inverted Pyramid Plot (IPP) model and associated text features. IV. E VENT INTELLIGENCE COLLECTION AND REPRESENTATION In this section we describe methods for collecting open source news event data and organizing it in a knowledge representation based on the Inverted Pyramid Plot (IPP) news narrative model features. A. News Intelligence Corpus The first component of FABULA is a news intelligence corpus which contains streams of scraped public news articles, Dand open source intelligence reports IRreleased by theU.S government. FABULA utilizes Really Simple Syndication (RSS) feed triggers for sources such as CNN [17], New York Times [18], CBS News [19], U.S. Department of State [20], and U.S. Department of Defense [21]. Each feed contains article metadata such as headline, author(s), abstract, and a web link',\n",
       " 'When updates are pushed by sources on their RSS feeds, FABULA utilizes the RSS web links to retrieve the corresponding webpages. We further extract information such as timestamps, news text, image links, video links from each article, using the BeautifulSoup web parser1. Each individual news article is represented in the collection of OSINT news setD. D={d1, d2, ..., d k, ..., d n} Each dkrepresents a news article and its headlines, au- thor(s), timestamps, text, images, video links. SetIRis composed of publicly available intelligence re- ports released by the United States Office of the Director of National Intelligence (ODNI)2. The ODNI intelligence reports (2005-2023) have a common structure that matches the Inverted Plot Pyramid narrative scheme (Section IV-B). Our final news intelligence corpus D+IR, contains to 3000 Dnews articles and 165 IRreports. B',\n",
       " 'Event Plot Extraction FABULA solves a fragmented narrative construction prob- lem where given a set of relevant articles retrieved by a search query about event e, contain several plot points: P={p1, p2, ..., p i, ..., p o} Where, piis a plot point that is extracted from D. The associated plot points for an event e, can be determined through information extraction based on classes in the In- verted Plot Pyramid (IPP) (Figure 2), a standardized narrative structure for communicating news events (Section II-A). The IPP narrative structure has three sub-categories: Lead, Body, andTail. Definitions of the IPP sub-categories and associated sub-types are available in Table I. To extract the IPP-based plot points, we implement a Narrative Plot Concept Extractor (NPCE) that processes the set of news articles D. In the rest of this section, we further describe the methods used to extract the plot points described in Table I that form set P',\n",
       " 'Extraction occurs at each level of the IPP - Lead, Body, andTail. 1) The Lead: Event information contained in the IPP Lead class describes the most noteworthy event details. As indicated in Table I, these details are expressed through the 5W commu- nication device : who? ( pwho), what? ( pwhat), when? ( pwhen ), where? ( pwhere ), and why? ( pwhy). The answers to the 5W questions provide a circumstantial view of an event. The NPCE extracts the 5Ws using pre-trained Named Entity Recognition (NER) and Part of Speech (POS) Tagging models from the standardized spaCy NLP Framework [22]. The specific entity and relationship types extracted are provided in Table II',\n",
       " 'The spaCy NER was trained on the widely benchmarked 1https://www.crummy.com/software/BeautifulSoup/ 2https://www.dni.gov/index.php/newsroom/reports-publicationsInverted Pyramid Class Plot Element Notation Lead: Summary of the most noteworthy details and main story objective/event.Who: Identification of the subject or persons involved. pwho What: Occurences of scenes, incidents, artifacts, or actions. pwhat When: Recorded timestamps and dates. pwhen Where: Geographic regions and locations mentioned. pwhere Why: The cause and reason to describe event occurence. pwhy Body: Series of crucial delineated incidents that build main story objective/event.Evidence: Supporting details surrounding an event. pevidence Quotes: Phrases noted by involved persons',\n",
       " 'pquote Media (Photos): Digital Image Object (HTML DOM image element) pphoto Media (Video): Recorded Video Object (HTML DOM video element) pvideo Media (Audio): Recorded Audio Object (HTML Dom audio Element.) paudio Tail: Conclusory remarks and journalistic opinions.Journalistic Opinion: Non-fact based judgements about event. popinion Persuasion Tactic: Instances of rhetorical dimensions (ethos, pathos, logos) ptactic Sentiment: Emotional tone and affective state information. psentiment TABLE I TEXTUAL FEATURES REPRESENTING PLOT ELEMENTS FOR EACH INVERTED PYRAMID PLOT MODEL CLASS ',\n",
       " 'Lead Class Attributes OntoNotes Entity and Relationship Types Who PERSON, NORP, ORG WhatEVENT, FAC, PRODUCT, WORK_OF_ART, LAW, MONEY , LANGUAGE, PERCENT, QUANTITY , ORDINAL, CARDINAL When DATE, TIME Where GPE, LOC Whycause, causing, caused by, because, since, after, for, as and of TABLE II ENTITY AND RELATIONSHIP TYPES FOR THE 5W CLASSES OntoNotes dataset. [23]. The why category in particular, is extracted using the spaCy Part of Speech (POS) tagger, which locates sentences containing causal relationships (prepositions, verbs, conjunctions) between entities. 2) The Body: The most significant plot points, involving major incidents and themes of an event are communicated in the body of an article. The incidents are typically written as factual occurrences to form a delineated sequence of informa- tion that builds the main story objective and overall situational awareness of an event',\n",
       " 'FABULA’s NPCE utilizes a FAISS- based clustering [24] and regex approaches to extract Body category event information (Table I), which include evidences (pevidence ), quotes ( pquote ), and media objects stored as URLs (pphoto ,pvideo ,paudio ). 3) The Tail: The Tail category contains conclusive remarks, journalistic opinions ( popinion ), persuasion tactics ( ptactic ), and perceived sentiment ( psentiment ) of the article author and source organization. These features do not contain plot points that impact the development of an event, but rather can be used by an analyst to understand factors that may influence the author’s narrative. Opinion ( popinion ) and persuasion tactic ( ptactic ) identifica- tion is a multi-label task at the paragraph level. We utilize a gold standard model developed for the ACL Semantic Evalua- tion Task [25]. This was trained on the only publicly available human-labeled corpus specifically developed for persuasion language extraction [25]',\n",
       " 'We treat each article in our set D as a holdout sample and use the provided model to extract the persuasion tactics and the corresponding text sample. For sentiment detection, we utilize the spaCy sentiment analysis program polarity to extract positive, negative, and neutral sentiment for each article.The NPCE output of the 3-level Lead, Body, and Tail extraction populates the event plot points set P. We maintain the mapping between the extracted set Pand the associated documents in set Dfor LLM prompt tuning, described further in Section V-C. In the next subsection, we describe methods we use to assert set Pinto FABULA’s Event Plot Graph (EPG). C. Event Narrative Ontology & Event Plot Graph We introduce the Event Narrative Ontology (ENO), a Web Ontology Language (OWL)-based knowledge representation. ENO allows FABULA to store event information based on extracted plot point category features, described in the previous section. ENO serves as the base schema for FABULA’s Event Plot Graph (EPG)',\n",
       " 'NPCE’s output, set P(Section IV-B) is asserted in the EPG using ENO. ENO classes and properties have been constructed using the elements of the Inverted Plot Pyramid (IPP) narrative scheme (Figure 2, Section II-A). While we incorporate the IPP scheme due to its relevance to intelligence analysis in particular, variants of ENO can be built based on a variety of narrative theories. The EPG contains a set of stored as Resource Description Framework (RDF) triples donated as G, G={(s, p, o )|s, o ϵ I, p ϵ R } (1) where, IandRdenote the instances and relations stored in G.(s, p, o )is a single triple in Gand denotes the relation p between two entities sando. Below is a description of ENO classes and properties',\n",
       " 'Classes in ENO: ENO contains a total of 16 classes and subclasses: two generic classes: NewsArticle ,PlotPoint , and 14 subclasses, all of which are of type owl :Class . The classes organize the information extracted in Section IV-B in a form that incorporates the IPP narrative scheme. Descriptions are as follows: •NewsArticle : Instances contain identifiers for news ar- ticles and metadata such as publisher, author, URL, etc. •PlotPoint : Describes IPP narrative elements (Section IV-B). It has following subclasses: 1)Lead :: Plot points that include noteworthy details. Subclasses are categorized below: –Who: Person, affiliation, organization ( pwho).–What : Incidents, artifacts, or actions ( pwhat). –When : Recorded timestamps and dates ( pwhen ). –Where : Geographic locations/regions ( pwhere ). –Why: Event causal descriptions ( pwhy). 2)Body :: Plot points that describe news article objec- tive',\n",
       " 'It has the following subclasses: –Evidence Supporting details ( pevidence ). –Quote : Text demarcated by quotation marks ( pquote ). –MediaObject : Class representing photo ( pphoto ), au- dio (paudio ), and video ( pvideo ) DOM objects. 3)Tail :: Plot points representing closing remarks and opinions. It has the following subclasses: –Opinion : Extracted author opinion ( popinion ). –PersTactic : Persuasion technique ( ptactic ). –Sentiment : Tone, emotion, mood ( psentiment ). Properties in ENO: To encode extracted relations ENO incor- porates multiple object and data properties that can be asserted in the EPG. We describe some of these below: •articleHeadline : Extracted string literal from NewsAr- ticle instance denoting the article headline. •authorOfArticle : Extracted string literal from NewsAr- ticle instance denoting author(s) of the article',\n",
       " '•publishedBy : Data property denoting the publishing source of the NewsArticle instance. •publishedDate : Timestamp for NewsArticle instance. •hasPlotPoint : This object property helps codify rela- tions between instances of the extracted IPP PlotPoint and its associated NewsArticle . The property can be inherited by instances of PlotPoint subclasses. Fig. 3. Populated EPG Sub-graph for the 2023 Titan Submersible Implosion. For example, Figure 3, shows an EPG sub-graph about the 2023 Titan Submersible Implosion event. The graph represents one news article News937844 . This sub-graph displays the Lead narrative plot points about a catastrophic implosion (pwhat), involving the U.S Coast Guard ,OceanGate Expe- ditions , and Hamish Harding (pwho), occurring at the Titanic Wreck site, near Newfoundland, Canada (pwhere )',\n",
       " 'Though not shown in this subgraph, we were able to extract Body and Tail narrative plot points, which were asserted in the EPG. These include Body instances: four pevidence pieces,twopquote and one pimage , and Tail instances: an attack on reputation ptactic andnegative psentiment utilized by the article author James Bryan . The EPG Gconstructed from the news stream collection Dis next utilized in automatic intelligence report generation. V. R ETRIEVAL -AUGMENTED INTELLIGENCE REPORT GENERATION An intelligence analyst can use FABULA to delineate event plot elements stored in the EPG G, for automatic generation of intelligence report Yabout event e. FABULA implements a Retrieval-Augmented Generation (RAG) approach that queries the EPG to retrieve a narrative prompt set about event e (Figure V-A). The set serves as a prompt to a Large Language Model (LLM) during report generation',\n",
       " 'There are three pri- mary steps to our approach: (1) Fine-Tuning an LLM with D+IR, (2) Data-to-text prefix-tuning, and (3) SPARQL template LLM prompting for report generation. LetVdenote the vocabulary set of the report generation task. The desired target output is to generate report text denoted by Yutilizing the LLM where, Y= (w1, w2, ..., w j, ..., w T) wjϵ Vis a single word in the generated report Y. To generate Y, we first fine-tune the LLM GPT-Neo [16] with our news intelligence corpus D+IR. Fine-tuning GPT-Neo using D+IRhas two advantages. First, it augments the existing vocabulary of GPT-Neo ( VGPT−Neo) with the vocabulary of the news intelligence corpus ( VD+IR) which is equivalent to the vocabulary of FABULA’s EPG',\n",
       " 'After the fine-tuning report generation task, vocabulary Vincludes both VGPT−Neo and VD+IR. Second, fine-tuning with public intelligence reports IRprovides the LLM with examples of the desired document structure for output Y. To generate the intelligence report Y, GPT-Neo takes as input a narrative prompt set , i.e. a set of narrative plot points about the event estored in the subgraph G′ϵ G. G′={(se, p, o e)|se, oeϵ Ie, p ϵ R } where, Ieϵ IandRdenote the instances relevant to query e and relations stored in G(Equation (1). The determination of the narrative plot points in G′retrieved from G, is imple- mented using the SPARQL Protocol and RDF Query Language templates executed on FABULA’s EPG G',\n",
       " 'The narrative prompt set serves as input to the fine-tuned GPT-Neo LLM that outputs the intelligence report Y. Each component of our approach is further described in the rest of this section. A. Fine-Tuning GPT-Neo Fine-tuning is an example of transfer learning, a method that seeds additional domain knowledge to a pre-trained Large Language Model, without training all parameters from scratch. We fine-tune the 1.3B parameter GPT-Neo decoder [16]. The original GPT-Neo model was trained with the Pile dataset [26], which is an 800GB English text corpus that consists of22 high quality datasets',\n",
       " 'Fine-tuning GPT-Neo using D+IR (Section IV-A) augments the existing vocabulary of GPT-Neo (VGPT−Neo) with the vocabulary of the news intelligence corpus ( VD+IR) and allows GPT-Neo to model the format and syntactic style of known intelligence reporting, such as that available in set IR, which closely follows the IPP narrative structure. During fine-tuning, we divide the training set in a 35% train and test split. We use batch size 16 and learning rate 0.0001, trained for 12 hours. The output of the model is a conditional probability of each word in the target text given the input and the previously generated words. We report a perplexity value (the exponential of the cross-entropy loss) of 11.14. Fig. 4. FABULA’s Retrieval-Augmented Generation (RAG) of Intelligence Report about event e. B',\n",
       " 'Prefix-tuning with Narrative Prompt Sets Traditionally, an autoregressive decoder like GPT-Neo re- quires a sentence based prompt to initiate generation. To modify this requirement and to enable prompting using a narrative prompt set for intelligence report Ygeneration, we require data-to-text prefix-tuning [27]. Prefix-tuning is a lightweight supplement to the fine-tuned GPT-Neo. This method keeps the GPT-Neo model parameters frozen and optimizes a sequence of continuous task-specific virtual vectors to the key and value matrices. When the tuning process is complete, the virtual tokens are stored in a lookup table, used during inference. We use the article to plot point mappings generated by the NPCE, described in Section IV-B and the HuggingFace Parameter-Efficient Fine-Tuning (PEFT) module for prefix-tuning',\n",
       " 'We use a beam decoding scheme and observed that adding more keywords provides increased supervision to the model and narrows the distribution of keyword context in the entire training dataset, leading to more accurate generation. More information on our evaluation can be found in Section VI. C. Large Language Model Prompting using FABULA’s EPG A FABULA generated intelligence report Yon event e should contain reliable and consistent information. Yshould only contain plot points that are relevant to the input queryevent e, and should exclude non-event related details. Achiev- ing this criteria is not plausible by solely utilizing non- deterministic generative LLMs such as GPT-Neo, which are prone to output hallucinations [28]. We combat hallucinations and fulfill the above criteria by using a RAG-based approach by retrieving event narrative plot points stored in the EPG (Section IV-B) to control the prefix-tuned LLM generated output report. Our RAG approach is displayed in Figure V-A',\n",
       " 'To create a narrative prompt set for the intelligence analyst’s event query e, FABULA utilizes SPARQL Protocol and RDF Query Language (SPARQL) templates. These queries can be executed on the EPG to retrieve a set of plot points related to event query e. For example, the SPARQL query to output the Lead narrative plot points for the event query e=\"Oceangate \" has been shown in Listing 1. FABULA includes a set of SPARQL query templates that can be leveraged to build a narrative prompt set for the intelligence analyst query e. This prompt set serves as the input to the prefix-tuned GPT-Neo that outputs the intelligence report Y. In the next section, we describe evaluation of the generated intelligence reports. Excerpts from an intelligence report generated by FABULA are available in Table V-C. SELECT Distinct ?xWhere { WHERE { ?xrdf:type narr :Who. ?x rdf:type narr :What ',\n",
       " '?xrdf:type narr :When . ?x rdf:type narr :Where . ?xrdf:type narr :Why. ?y narr :hasPlotPoint ?x. ?yrdf:type narr :NewsArticle . ?znarr :ArticleHeadline ?y. FILTER regex(str(?z), \"Oceangate\").} Output : <OceanGate Expeditions, Stockton Rush, Paul-Henri Nargeloe, Hamish Harding, Shahzada Dawood, Suleman Dawood, Titanic, wreck, submersible, 18 June, 370 miles, Newfoundland, Canada, Atlantic Ocean> Listing 1. SPARQL query to retrieve Lead plot points for e=“Oceangate ” and corresponding output VI. E XPERIMENTATION & E VALUATION Our evaluation study is composed of two experimental approaches. First, we automatically evaluate the semantic and syntactic quality of the generated reports using Recall- Oriented Understudy for Gisting Evaluation (ROUGE) [29]',\n",
       " 'Second, we qualitatively evaluate the reports through a human evaluation done by a group of 3 analysts. Table V-C, provides samples of the generated intelligence reports for the 2023 Oceangate Submersible Disaster and the2023 Ohio Train Derailment Disaster events. Column one displays the narrative prompt templates that were used for EPG plot point instance extraction (See Section V-C). Each IPP class has an associated derived narrative prompt set (Column 2), which is converted into a linearized prompt of keywords, used as input to GPT-Neo for guided text generation (See Section V-C)',\n",
       " 'The bolded text in the generated samples (Table V-C, Column 3) represents occurrences of the prompt2023 Oceangate Submersible Disaster Prompt Template Prompt Generated Text Lead Template <pwho,pwhat , pwhen ,pwhere ,><OceanGate Expeditions, Stockton Rush, Paul-Henri Nargeloe, Hamish Harding, Shahzada Dawood, Suleman Dawood, Titanic, wreck, site, submersible, 18 June, 370 miles, Newfoundland, Canada, 1 hour and 45 minutes, Atlantic Ocean>The OceanGate Expeditions submarine is the subject of the rescue operation for Hamish Harding ,Stockton Rush , Paul-Henri Nargeloe ,Shahzada Dawood ,Suleman Dawood were on board for an expedition into the Titanic wreck site . The Titan submersible went missing 18 June about 370 miles off the coast of Newfoundland inCanada ',\n",
       " 'The submersible lost contact just 1 hour and 45 minutes after diving into the Atlantic Ocean . Body Template <pevidence , pquote ,><debris, ROV , seafloor, titanic, sonar, banging, noises, implosion, injury, dead, safety, regulations, failure, United States Coast Guard said “likely died from the failure of the craft”>Debris was found by a ROV near the Titanic wreck. Sonar detects banging sounds from underneath the water. The banging sounds indicate an unfortunate implosion .The United States Coast Guard claims the crew and passengers died from the implosion. Tail Template <ptactic ,><overshadowed the bigger Greece migrant vessel disaster>Coverage overshadowed the greater Mediterranean disaster',\n",
       " '2023 Ohio Train Derailment Disaster Prompt Template Prompt Generated Text Lead Template <pwho,pwhat , pwhen ,pwhere ,><Norfolk Southern Train, chemicals, East Palestine, Ohio, 9pm, 3 February>Norfolk Southern Train carrying hazardous chemicals suffered a mechanical failure. The derailment took place in the village ofEast Palestine, Ohio at9pm on3 February . Body Template <pevidence , pquote ,><derailment, cars, EPA, hazardous, chemicals, contaminants, cancer, gas, safety, The EPA said it “did not detect chemical contaminants at concerning levels in the hours after venting.”>The cars had derailed , including the cars that were carrying hazardous materials. The EPA claims no concerning health risks. The chemicals are linked to increased risk of cancer . Tail Template <ptactic ,><overblown characterisations about the derailment disaster>Reporters made overblown accusations about the derailment disaster',\n",
       " 'TABLE III GUIDED INTELLIGENCE REPORT GENERATION USING IPP PROMPT TEMPLATES . keywords present in the final generated intelligence report. We limit the generation to 500 words to avoid model hallucination and inclusion of non-event related information. We found prompting with longer sequences of keywords (such as those extracted from the Lead and Body templates) resulted in more tightly coherent and semantically relevant generations, versus the Tail template, which mostly only included the extracted persuasion tactic as a prompt. We found that for instances such as these, the model would deflect from the event and sometimes include non-relevant information. Therefore, for tail generation, we limit the output to 100 words. A. Quantitative Evaluation We utilize Rouge scores to quantitatively evaluate the effi- cacy of our system in generating syntactically accurate intelli- gence reports [29]. Rouge- nin particular, allows us to compute the ratios of overlapping n-grams between generated reports and reference text',\n",
       " 'In particular, we use event descriptions extracted from Wikipedia as a reference set to calculate the syntactic overlap between these event descriptions and FAB- ULA’s generated intelligence reports. The Wikipedia event descriptions are derived based on content from a variety of online sources and reporters, written by human volunteers and overseen by Wikipedia moderators. These Wikipedia reference descriptions help provide us with a lateral publicly available comparison for FABULA’s fragmented narrative construction. We use the Wikipedia Python library summaries endpoint [30] to extract event descriptors for 50 different public events we randomly selected from D+IRand calculate Rouge- 1and Rouge- 2. This provides term-based measures to quantify topic- level semantic relevance and syntactic quality [29]. Our resultsare displayed in Table VI-B. Rouge- 1refers to overlap of unigrams between FABULA’s reports and Wikipedia’s event descriptors while Rouge- 2refers to the overlap of bigrams. B',\n",
       " 'Human Evaluation (Qualitative) Study After evaluating the general efficacy of our model using quantitative metrics, we also conduct a human evaluation study to validate FABULA’s capability required specifically for the intelligence report generation task. Given the high cost of this evaluation, we task a group of 3 analysts to score reports across 5 randomly selected events with two aspects: factual correctness andlanguage fluency . The first criterion evaluates how well the generated report conveyed the overall narrative of the event. The second criterion evaluates grammatically correctness and fluency of the generated intelligence report. The analysts were given a set of 5 articles per event (total 5 events), and were tasked to manually create a single report to convey the critical aspects across the set of 5 articles, for each separate event. This helped the analysts understand the narrative details for each of the 5 events. We then tasked the analysts to recommend IPP plot points from each of the 5 events',\n",
       " 'We compute Cohen’s kappa [31] to measure inter- annotator agreement for each of the recommended IPP plot points, keeping only the plot points that scored higher than 0.6. This helped us derive a gold standard set of 78 plot points that analysts want in the generated report, referred to as set Gold . We then identify the number of IPP plot points in the FABULA’s generated reports for the 5 events. The number of IPP plot points in the generated reports overlapping with Gold is called support (denoted as #Supp). The number of missing plot points that were in Gold and not present in FABULA’sgenerated reports are called contradicting plot points (denoted as #Cont). The average scores are displayed in Table VI-B. These are computed against the Gold average of 15.6',\n",
       " 'Quantitative Results Rouge- 1 Rouge- 2 61.27 24.51 Qualitative Results #Supp #Cont Fluency 15.6 13.2 4.2 TABLE IV QUANTITATIVE QUALITATIVE RESULTS FOR GENERATED INTELLIGENCE REPORTS . To score grammatical correctness and linguistic fluency , we adopt a 5-point Likert scale [32] ranging from 1-point (“Unac- ceptable”) to 5-point (“Very Acceptable”) tasking analysts to score the 5 FABULA generated reports. The Fluency column in Table VI-B reports averaged score (4.2/5) from 5 human analysts over the 5 generated reports. VII. C ONCLUSION & F UTURE WORK Deriving narratives about events using disparately sourced information is a challenging task for an intelligence analyst. Analysts heavily rely on traditional, manual techniques to parse large amounts of noisy OSINT data to create cohesive intelligence reports',\n",
       " 'These manual methods do not provide complete situational awareness and are prone to information gaps and inaccurate representations of dynamic events.In this paper, we have described our framework FABULA (Figure 1), that integrates real-time news event retrieval, narrative schema-based information extraction and representation of event concept information, and retrieval-augmented generation (RAG) of intelligence reports. We evaluate the generated reports using quantitative Rouge evaluation metrics and through a qualitative human evaluation study. Our results show that the plot points constructed within the generated intelligence report have high semantic relevance, high coherency, and low data redundancy. In planned future work, we are exploring methods to train transformer based lan- guage models to automatically learn the structure of a variety of plot models. It is a non-uniform process to identify narrative features in natural language. We are pursuing strategies to transfer the classified plot relationships to broader events and domains. REFERENCES [1] Wendy G Lehnert. Plot units and narrative summarization',\n",
       " 'Cognitive science , 5(4):293–331, 1981. [2] Priyanka Ranade, Sanorita Dey, Anupam Joshi, and Tim Finin. Com- putational understanding of narratives: A survey. IEEE Access , 2022. [3] Ryan L Boyd, Kate G Blackburn, and James W Pennebaker. The narrative arc: Revealing core narrative structures through text analysis. Science advances , 6(32):eaba2196, 2020. [4] Kristin Thompson. Storytelling in the new Hollywood: Understanding classical narrative technique . Harvard University Press, 1999. [5] Brian Keith, Michael Horning, and Tanushree Mitra. Evaluating the inverted pyramid structure through automatic 5w1h extraction and summarization',\n",
       " 'Computational Journalism C+ J , 2020.[6] Faten El Outa, Matteo Francia, Patrick Marcel, Veronika Peralta, and Panos Vassiliadis. Supporting the generation of data narratives. In ER Forum/Posters/Demos , pages 168–172, 2020. [7] Xianshu Zhu and Tim Oates. Finding story chains in newswire articles. In2012 IEEE 13th International Conference on Information Reuse & Integration (IRI) , pages 93–100. IEEE, 2012. [8] Dafna Shahaf and Carlos Guestrin. Connecting the dots between news articles. In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining , 2010. [9] Gabriel Pui Cheong Fung, Jeffrey Xu Yu, Huan Liu, and Philip S Yu. Time-dependent event hierarchy construction',\n",
       " 'In Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 300–309, 2007. [10] Carlo Meghini, Valentina Bartalesi, and Daniele Metilli. Representing narratives in digital libraries: The narrative ontology. Semantic Web , 12(2):241–264, 2021. [11] Amit Singhal, Chris Buckley, and Manclar Mitra. Pivoted document length normalization. In Acm sigir forum , volume 51, pages 176–184. ACM New York, NY , USA, 2017. [12] Nick Craswell, W Bruce Croft, Maarten de Rijke, Jiafeng Guo, and Bhaskar Mitra. Neural information retrieval: introduction to the special issue. Information Retrieval Journal , 21:107–110, 2018. [13] Laura Dietz, Alexander Kotov, and Edgar Meij',\n",
       " 'Utilizing knowledge graphs for text-centric information retrieval. In The 41st international ACM SIGIR conference on research & development in information retrieval , pages 1387–1390, 2018. [14] Rik Koncel-Kedziorski, Dhanush Bekal, Yi Luan, Mirella Lapata, and Hannaneh Hajishirzi. Text generation from knowledge graphs with graph transformers. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: , 2019. [15] Pei Ke, Haozhe Ji, Yu Ran, Xin Cui, Liwei Wang, Linfeng Song, Xiaoyan Zhu, and Minlie Huang. Jointgt: Graph-text joint representation learning for text generation from knowledge graphs. arXiv preprint arXiv:2106.10502 , 2021. [16] Sid Black, Leo Gao, Phil Wang, Connor Leahy, and Stella Biderman',\n",
       " 'Gpt-neo: Large scale autoregressive language modeling with mesh- tensorflow. 2021. [17] CNN. https://www.cnn.com/services/rss/. [18] NYTimes. https://www.nytimes.com/rss/. [19] CBS New. https://www.cbsnews.com/rss/. [20] U.S. Department of State. https://www.state.gov/rss-feeds/. [21] U.S. Department of Defense. https://www.defense.gov/news/rss/. [22] spacy nlp framework. https://spacy.io/, version = , date = 2023,. [23] Xavier Schmitt, Sylvain Kubler, Jérémy Robert, Mike Papadakis, and Yves LeTraon. A replicable comparison study of ner software: Stanfordnlp, nltk, opennlp, spacy, gate. In 2019 Sixth International Conference on Social Networks Analysis, Management and Security (SNAMS) , pages 338–343. IEEE, 2019',\n",
       " '[24] Hervé Jégou, Matthijs Douze, Jeff Johnson, Lucas Hosseini, and Chengqi Deng. Faiss: Similarity search and clustering of dense vectors library. Astrophysics Source Code Library , pages ascl–2210, 2022. [25] Jakub Piskorski, Nicolas Stefanovitch, Giovanni Da San Martino, and Preslav Nakov. Semeval-2023 task 3: Detecting the category, the framing, and the persuasion techniques in online news in a multi- lingual setup. In Proceedings of the The 17th International Workshop on Semantic Evaluation (SemEval-2023) , pages 2343–2361, 2023. [26] Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, et al',\n",
       " 'The pile: An 800gb dataset of diverse text for language modeling. arXiv preprint arXiv:2101.00027 , 2020. [27] Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv preprint arXiv:2101.00190 , 2021. [28] Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. Retrieval augmentation reduces hallucination in conversation. arXiv preprint arXiv:2104.07567 , 2021. [29] Chin-Yew Lin. Rouge: A package for automatic evaluation of sum- maries. In Text summarization branches out , pages 74–81, 2004. [30] Wikipedia. Wikipedia python library. https://pypi.org/project/wikipedia/. [31] Mary L McHugh. Interrater reliability: the kappa statistic',\n",
       " 'Biochemia medica , 22(3):276–282, 2012. [32] I Elaine Allen and Christopher A Seaman. Likert scales and data analyses. Quality progress , 40(7):64–65, 2007.',\n",
       " 'LitLLM: A Toolkit for Scientific Literature Review Shubham Agarwal1,2,3, Issam H. Laradji1,4, Laurent Charlin2,3,5, Christopher Pal1,2,5 1ServiceNow Research,2Mila - Quebec AI Institute,3HEC Montreal, Canada 4UBC, Vancouver, Canada,5Canada CIFAR AI Chair Correspondence: shubham.agarwal@mila.quebec Abstract Conducting literature reviews for scientific papers is essential for understanding research, its limitations, and building on existing work. It is a tedious task which makes an automatic literature review generator appealing. Unfortunately, many existing works that generate such reviews using Large Language Models (LLMs) have significant limitations. They tend to hallucinate—generate non-factual information—and ignore the latest research they have not been trained on',\n",
       " 'To address these limitations, we propose a toolkit that operates on Retrieval Augmented Generation (RAG) principles, specialized prompting and instructing techniques with the help of LLMs. Our system first initiates a web search to retrieve relevant papers by summarizing user-provided abstracts into keywords using an off-the-shelf LLM. Authors can enhance the search by supplementing it with relevant papers or keywords, contributing to a tailored retrieval process. Second, the system re-ranks the retrieved papers based on the user-provided abstract. Finally, the related work section is generated based on the re-ranked results and the abstract. There is a substantial reduction in time and effort for literature review compared to traditional methods, establishing our toolkit as an efficient alternative',\n",
       " 'Our open-source toolkit is accessible at https://github.com/ shubhamagarwal92/LitLLM and Huggingface space ( https://huggingface.co/spaces/ shubhamagarwal92/LitLLM ) with the video demo at https://youtu.be/E2ggOZBAFw0 1 Introduction Scientists have long used NLP systems like search engines to find and retrieve relevant papers. Schol- arly engines, including Google Scholar, Microsoft Academic Graph, and Semantic Scholar, provide additional tools and structure to help researchers further. Following recent advances in large lan- guage models (LLMs), a new set of systems pro-vides even more advanced features. For example, Explainpaper1helps explain the contents of papers, and Writefull2helps with several writing tasks, in- cluding abstract and title generation. There are, of course, many other tasks where similar technolo- gies could be helpful',\n",
       " 'Systems that help researchers with literature re- views hold promising prospects. The literature review is a difficult task that can be decomposed into several sub-tasks, including retrieving rele- vant papers and generating a related works section that contextualizes the proposed work compared to the existing literature. It is also a task where factual correctness is essential. In that sense, it is a challenging task for current LLMs, which are known to hallucinate. Overall, creating tools to help researchers more rapidly identify, summarize and contextualize relevant prior work could signifi- cantly help the research community. Recent works explore the task of literature re- view in parts or in full. For example, Lu et al. (2020) proposes generating the related works sec- tion of a paper using its abstract and a list of (rel- evant) references',\n",
       " 'Researchers also look at the whole task and build systems using LLMs like ChatGPT for literature review (Haman and Školník, 2023; Huang and Tan, 2023). While these LLMs tend to generate high-quality text, they are prone to hallucinations (Athaluri et al., 2023). For exam- ple, the Galactica system was developed to reason about scientific knowledge (Taylor et al., 2022). While it outperforms contemporary models on var- ious scientific tasks, it generates made-up content like inaccurate citations and imaginary papers.3 As a step forward, we explore retrieval- augmented-generation (RAG) to improve factual correctness (Lewis et al., 2020)',\n",
       " 'The idea is to use the retrieval mechanism to obtain a relevant list of 1https://www.explainpaper.com/ 2https://x.writefull.com/ 3see e.g., What Meta Learned from GalacticaarXiv:2402.01788v1 [cs.CL] 2 Feb 2024Generated Related W ork User input Plan based generation (Section 3.3.2)Retrieved and reranked papers (Section 3.2)LLM based keyword summarization (Section 3.1)Figure 1: LitLLM on Huggingface Space. Our system works on the Retrieval Augmented Generation (RAG) principle to generate the literature review grounded in retrieved relevant papers. User needs to provide the abstract in the textbox (in purple) and press send to get the generated related work (in red). First, the abstract is summarized into keywords (Section 3.1), which are used to query a search engine',\n",
       " 'Retrieved results are re-ranked (in blue) using the Paper Re-Ranking module (Section 3.2), which is then used as context to generate the related work (Section 3.3). Users could also provide a sentence plan (in green) according to their preference to generate a concise, readily usable literature review (See Section 3.3.2).Research idea/ AbstractSearch Engine Query Generator ModuleAPI Relevant papers Related workPlanRe-ranking ModuleRe-ranked papersRelevant papers Relevant papers Relevant papersRelevant papers Re-ranked papersRe-ranked papers (Section 3.2) (Section 3.3)(Section 3.3.2)(Section 3.1)Figure 2: Schematic diagram of the modular pipeline used in our system. In the default setup, we summa- rize the research abstract into a keyword query, which is used to retrieve relevant papers from an academic search engine',\n",
       " 'We use an LLM-based reranker to select the most relevant paper relative to the provided abstract. Based on the re-ranked results and the user-provided summary of their work, we use an LLM-based genera- tive model to generate the literature review, optionally controlled by a sentence plan. existing papers to be cited which provides relevant contextual knowledge for LLM based generation. LitLLM is an interactive tool to help scientists write the literature review or related work section of a scientific paper starting from a user-provided abstract (see Figure 1). The specific objectives of this work are to create a system to help users navigate through research papers and write a litera- ture review for a given paper or project. Our main contributions are: •We provide a system based on a modular pipeline that conducts a literature review based on a user-proposed abstract. •We use Retrieval Augmented Generation (RAG) techniques to condition the generated related work on factual content and avoid hal- lucinations using multiple search techniques',\n",
       " '•We incorporate sentence-based planning to promote controllable generation. 2 Related Work LLMs have demonstrated significant capabilities in storing factual knowledge and achieving state- of-the-art results when fine-tuned on downstreamNatural Language Processing (NLP) tasks (Lewis et al., 2020). However, they also face challenges such as hallu- cination, outdated knowledge, and non-transparent, untraceable reasoning processes (Huang et al., 2023; Gao et al., 2023; Li et al., 2024). These lim- itations have motivated the development of RAG (Retrieval Augmented Generation), which incor- porates knowledge from external databases to en- hance the accuracy and credibility of the models, particularly for knowledge-intensive tasks (Gao et al., 2023). RAG has emerged as a promising solution to the challenges faced by LLMs',\n",
       " 'It syner- gistically merges LLMs’ intrinsic knowledge with the vast, dynamic repositories of external databases (Gao et al., 2023). This approach allows for contin- uous knowledge updates and integration of domain- specific information in an attempt to limit the effect of outdated knowledge. The proposed work builds upon the advancements around RAG to provide a more efficient solution for academic writing. On the other hand, there has been a notable em- phasis on utilizing Large Language Models (LLMs) for tasks related to information retrieval and rank- ing (Zhu et al., 2023). The work by Sun et al. (2023) leverages generative LLMs such as Chat- GPT and GPT-4 for relevance ranking in informa- tion retrieval, demonstrating that these models can deliver competitive results to state-of-the-art su- pervised methods. Pradeep et al',\n",
       " '(2023b,a) intro- duce different open-source LLM for listwise zero- shot reranking, further motivating the proposed approach of using LLMs for reranking in our work. The exploration of large language models (LLMs) and their zero-shot abilities has been a sig- nificant focus in recent research. For instance, one study investigated using LLMs in recommender systems, demonstrating their promising zero-shot ranking abilities, although they struggled with the order of historical interactions and position bias (Hou et al., 2023). Another study improved the zero-shot learning abilities of LLMs through in- struction tuning, which led to substantial improve- ments in performance on unseen tasks (Wei et al., 2021)',\n",
       " 'A similar approach was taken to enhance the zero-shot reasoning abilities of LLMs, with the introduction of an autonomous agent to instruct the reasoning process, resulting in significant per- formance boosts (Crispino et al., 2023). The ap- plication of LLMs has also been explored in the context of natural language generation (NLG) as- sessment, with comparative assessment found to besuperior to prompt scoring (Liusie et al., 2023). In the domain of Open-Domain Question Answering (ODQA), a Self-Prompting framework was pro- posed to utilize the massive knowledge stored in LLMs, leading to significant improvements over previous methods (Li et al., 2022)',\n",
       " 'Prompt en- gineering has been identified as a key technique for enhancing the abilities of LLMs, with various strategies being explored (Shi et al., 2023).4 3 Pipeline Figure 2 provides an overview of the pipeline. The user provides a draft of the abstract or a research idea. We use LLM to first summarize the abstract in keywords that can be used as a query for search engines. Optionally, the users could provide rel- evant keywords to improve search results. This query is passed to the search engine, which re- trieves relevant papers with the corresponding in- formation, such as abstracts and open-access PDF URLs. These retrieved abstracts with the origi- nal query abstract are used as input to the other LLM Re-ranker, which provides a listwise ranking of the papers based on the relevance to the query abstract',\n",
       " 'These re-ranked abstracts with the origi- nal query are finally passed to the LLM generator, which generates the related work section of the pa- per. Recently, Agarwal et al. (2024) showed that prompting the LLMs with the sentence plans re- sults in reduced hallucinations in the generation outputs. These plans contain information about the number of sentences and the citation description on each line, providing control to meet author pref- erences. We include this sentence-based planning in the LLM generator as part of this system. In the following, we provide more details about each of the modules. 3.1 Paper Retrieval Module In our toolkit, we retrieve relevant papers using the Semantic Scholar API. Other platforms could be used, but the S2 Platform is well-adapted to this use case. It is a large-scale academic corpus com- prising 200M+ metadata records across multiple research areas, providing information about papers’ metadata, authors, paper embedding, etc',\n",
       " 'The Rec- ommendations API also provides relevant papers similar to any seed paper. Figure 3 shows our sys- 4This paragraph was generated using our platform with some minor modifications based on a slightly different version of our abstract. AbstractLLM based keyword summarization User provided keywords Seed paper for recommendationFigure 3: Different retrieval strategies as discussed in Section 3.1 tem’s different strategies. We describe these three settings that we use to search for references: •User provides an abstract or a research idea (roughly the length of the abstract). We prompt an LLM (see Figure 4) to summarize this abstract in keywords which can be used as a search query with most APIs. •Users can optionally also provide keywords that can improve search results. This is sim- ilar (in spirit) to how researchers search for related work with a search engine',\n",
       " 'This is par- ticularly useful in interdisciplinary research, and authors would like to include the latest re- search from a particular domain, which could not be captured much in the abstract. •Lastly, any seed paper the user finds relevant enough to their idea could be used with the Recommendations API from search engines to provide other closely related papers. Keyword summarization prompt You are a helpful research assistant who is helping with literature review of a research idea. You will be provided with an abstract of a scientific document. Your task is to summarize the abstract in max 5 keywords to search for related papers using API of academic search engine',\n",
       " '```Abstract: {abstract}``` Figure 4: Prompt used to summarize the research idea by LLM to search an academic engine 3.2 Paper Re-Ranking Module Recent efforts have explored the application of pro- prietary LLMs for ranking (Sun et al., 2023; Ma et al., 2023) as well as open-source models like(Pradeep et al., 2023a,b). These approaches pro- vide a combined list of passages directly as input to the model and retrieve the re-ordered ranking list (Zhang et al., 2023). Typically, a retriever first filters top-k potential candidates, which are then re-ranked by an LLM to provide the final output list',\n",
       " 'In our work, we use the instructional permuta- tion generation approach (Sun et al., 2023) where the model is prompted to generate a permutation of the different papers in descending order based on the relevance to the user-provided abstract, thus producing an ordered list of preferences against providing intermediate scores. Figure 5 showcases the prompt we used for LLM-based re-ranking. Ranking prompt You are a helpful research assistant who is helping with literature review of a research idea. You will be provided with an abstract or an idea of a scientific document and abstracts of some other relevant papers. Your task is to rank the papers base d on the relevance to the query abstract. Provide only the ranks as [] > [] > []. Do not output anything apart from the ranks. ```Abstract: {abstract} References: [1]: {text} [2]: {text} ..',\n",
       " '``` Figure 5: Ranking prompt based on the permutation generation method 3.3 Summary Generation Module We explore two strategies for generation: (1) Zero- shot generation and (2) Plan-based generation, which relies on sentence plans for controllable gen- eration, described in the following 3.3.1 Zero-shot generation While LLMs can potentially search and gener- ate relevant papers from their parametric memory and trained data, they are prone to hallucinating and generating non-factual content. Retrieval aug- mented generation, first introduced in Parvez et al. (2021) for knowledge tasks, addresses this by aug- menting the generation model with an information retrieval module',\n",
       " 'The RAG principles have been subsequently used for dialogue generation in task- oriented settings (Thulke et al., 2021), code gen- eration (Liu et al., 2020; Parvez et al., 2021) and RAG p rompt You will be provided with an abstract of a scientific document and other references papers in triple quotes. Your task is to write the related work section of the document using only the provided abstracts and other references papers. Please write the related work section creating a cohesive storyline by doing a critical analysis of prior work comparing the strengths and weakn esses while also motivating the proposed approach. You should cite the other related documents as [#] whenever you are referring it in the related work. Do not write it as Reference #. Do not cite abstract. Do not include any extra notes or newline characters at the end. Do not copy the abstracts of reference pape rs directly but compare and contrast to the main work concisely ',\n",
       " 'Do not provide the output in bullet points. Do not provide references at the end. Please cite all the provided reference papers. ```Abstract: {abstract} References: [1]: {text} [2]: {text} ```Figure 6: Prompt for Retrieval Augmented Generation product review generation (Kim et al., 2020). RAG drastically reduces hallucinations in the generated output (Gao et al., 2023; Tonmoy et al., 2024). Our work builds upon the principles of RAG, where we retrieve the relevant papers based on the query and augment them as context for generating the literature review. This also allows the system to be grounded in the retrieved information and be updated with the latest research where the training data limits the parametric knowledge of the LLM. Figure 6 shows our system’s prompt for effective Retrieval Augmented Generation (RAG)',\n",
       " '3.3.2 Plan based generation To get the best results from LLM, recent research shifts focus on designing better prompts (Prompt Engineering) including 0-shot chain-of-thought prompting (Kojima et al., 2022; Zhou et al., 2022), few-shot prompting (Brown et al., 2020) tech- niques, few-shot Chain-of-thought prompting (Wei et al., 2022) and in-context prompting (Li and Liang, 2021; Qin and Eisner, 2021). However, the longer context of our problem statement (query pa- per and multiple relevant papers) hinders the appli- cation of these techniques for response generation',\n",
       " 'We utilized sentence plan-based prompting tech-niques drawing upon insights from the literature of traditional modular Natural Language Genera- tion (NLG) pipelines with intermediary steps of sentence planning and surface realization (Reiter and Dale, 1997; Stent et al., 2004). These plans provide a sentence structure of the expected output, which efficiently guides the LLM in generating the literature review in a controllable fashion as demon- strated in concurrent work (Agarwal et al., 2024). Figure 7 (in Appendix) shows the prompt for plan- based generation with an example template as: Please generate {num_sentences} sentences in {num_words} words. Cite {cite_x} at line {line_x}. Cite {cite_y} at line {line_y}. 4 Implementation Details We build our system using Gradio (Abid et al., 2019), which provides a nice interface to quickly and efficiently build system demos',\n",
       " 'Our user inter- face is also available at HuggingFace Space5. We query the Semantic Scholar API available through the Semantic Scholar Open Data Platform (Lo et al., 2020; Kinney et al., 2023) to search for the relevant papers. Specifically, we use the Academic Graph6 and Recommendations7API endpoint. In this work, we use OpenAI API8to generate results for LLM using GPT-3.5-turbo and GPT-4 model. At the same time, our modular pipeline allows using any LLM (proprietary or open-sourced) for different components. We also allow the end-user to sort the retrieved papers by relevance (default S2 results), citation count, or year. 5 User Experience As a preliminary study, we provided access to our user interface to 5 different researchers who worked through the demo to write literature reviews and validate the system’s efficacy. We also provide an example in the demo with an abstract for a quick start',\n",
       " 'Particularly, the users found the 0-shot gener- ation to be more informative about the literature in general while the plan-based generation to be more accessible and tailored for their research paper, as also evident in our demo video.9. Table 1 (in Ap- 5https://huggingface.co/spaces/ shubhamagarwal92/LitLLM 6https://api.semanticscholar.org/api-docs/ graph 7https://api.semanticscholar.org/api-docs/ recommendations 8https://platform.openai.com/docs/guides/gpt 9https://youtu.be/E2ggOZBAFw0pendix) shows the output-related work for a recent paper (Li et al., 2023) that was randomly chosen with a number of cited papers as 4',\n",
       " 'Our system gen- erated an informative query Multimodal Research: Image-Text Model Interaction and retrieved rele- vant papers where the top recommended paper was also cited in the original paper. While zero-shot generation provides valuable insights into existing literature, plan-based generation produces a more succinct and readily usable literature review. 6 Conclusion and Future Work In this work, we introduce and describe LitLLM, a system which can generate literature reviews in a few clicks from an abstract using off-the-shelf LLMs. This LLM-powered toolkit relies on the RAG with a re-ranking strategy to generate a lit- erature review with attribution. Our auxiliary tool allows researchers to actively search for related work based on a preliminary research idea, research proposal or even a full abstract. We present a mod- ular pipeline that can be easily adapted to include the next generation of LLMs and other domains, such as news, by changing the source of retrieval information',\n",
       " 'Given the growing impact of different LLM- based writing assistants, we are optimistic that our system may aid researchers in searching relevant papers and improve the quality of automatically generated related work sections of a paper. While our system shows promise as a helpful research assistant, we believe that their usage should be disclosed to the readers, and authors should also observe caution in eliminating any possible hallu- cinations. In the future, we would also like to explore academic search through multiple APIs, such as Google Scholar. This work only considered ab- stracts of the query paper and the retrieved papers, which creates a bottleneck in effective literature review generation. With the advent of longer con- text LLMs, we envision our system ingesting the whole paper (potentially leveraging an efficient LLM-based PDF parser) to provide a more relevant background of the related research',\n",
       " 'We consider our approach as an initial step for building intelli- gent research assistants which could help academi- cians through an interactive setting (Dwivedi-Yu et al., 2022).References Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman Alfozan, and James Zou. 2019. Gradio: Hassle-free sharing and testing of ml models in the wild. arXiv preprint arXiv:1906.02569 . Shubham Agarwal, Issam Laradji, Laurent Charlin, and Christopher Pal. 2024. LLMs for Literature Review generation: Are we there yet? Under submission . Sai Anirudh Athaluri, Sandeep Varma Manthena, V S R Krishna Manoj Kesapragada, Vineel Yarlagadda, Tirth Dave, and Rama Tulasi Siri Duddumpudi. 2023',\n",
       " 'Exploring the boundaries of reality: Investigating the phenomenon of artificial intelligence hallucination in scientific writing through chatgpt references. Cureus , 15. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners',\n",
       " 'Nicholas Crispino, Kyle Montgomery, Fankun Zeng, Dawn Song, and Chenguang Wang. 2023. Agent instructs large language models to be general zero- shot reasoners. ArXiv , abs/2310.03710. Jane Dwivedi-Yu, Timo Schick, Zhengbao Jiang, Maria Lomeli, Patrick Lewis, Gautier Izacard, Edouard Grave, Sebastian Riedel, and Fabio Petroni. 2022. Editeval: An instruction-based benchmark for text improvements. arXiv preprint arXiv:2209.13331 . Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang. 2023. Retrieval-augmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997 ',\n",
       " 'Michael Haman and Milan Školník. 2023. Using chat- gpt to conduct a literature review. Accountability in Research , pages 1–3. Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian McAuley, and Wayne Xin Zhao. 2023. Large language models are zero-shot rankers for recommender systems. ArXiv , abs/2305.08845. Jingshan Huang and Ming Tan. 2023. The role of chat- gpt in scientific communication: writing better sci- entific review articles. American Journal of Cancer Research , 13(4):1148. Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et al. 2023',\n",
       " 'A survey on hallucination in large language models:Principles, taxonomy, challenges, and open questions. arXiv preprint arXiv:2311.05232 . Jihyeok Kim, Seungtaek Choi, Reinald Kim Amplayo, and Seung-won Hwang. 2020. Retrieval-augmented controllable review generation. In Proceedings of the 28th International Conference on Computational Linguistics , pages 2284–2295. Rodney Kinney, Chloe Anastasiades, Russell Authur, Iz Beltagy, Jonathan Bragg, Alexandra Buraczyn- ski, Isabel Cachola, Stefan Candra, Yoganand Chan- drasekhar, Arman Cohan, et al. 2023. The se- mantic scholar open data platform. arXiv preprint arXiv:2301.10140 ',\n",
       " 'Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu- taka Matsuo, and Yusuke Iwasawa. 2022. Large lan- guage models are zero-shot reasoners. Advances in neural information processing systems , 35:22199– 22213. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Hein- rich Küttler, Mike Lewis, Wen-tau Yih, Tim Rock- täschel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neu- ral Information Processing Systems , 33:9459–9474. Hang Li, Jindong Gu, Rajat Koner, Sahand Sharifzadeh, and V olker Tresp. 2023',\n",
       " 'Do dall-e and flamingo understand each other? In Proceedings of the IEEE/CVF International Conference on Computer Vision , pages 1999–2010. Junlong Li, Zhuosheng Zhang, and Hai Zhao. 2022. Self-prompting large language models for zero-shot open-domain qa. Junyi Li, Jie Chen, Ruiyang Ren, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen. 2024. The dawn after the dark: An empirical study on factuality hallucination in large language models. arXiv preprint arXiv:2401.03205 . Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning: Optimizing continuous prompts for generation. arXiv preprint arXiv:2101.00190 . Shangqing Liu, Yu Chen, Xiaofei Xie, Jingkai Siow, and Yang Liu. 2020. Retrieval-augmented generation for code summarization via hybrid gnn',\n",
       " 'arXiv preprint arXiv:2006.05405 . Adian Liusie, Potsawee Manakul, and Mark John Fran- cis Gales. 2023. Llm comparative assessment: Zero- shot nlg evaluation through pairwise comparisons using large language models. Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kin- ney, and Daniel Weld. 2020. S2ORC: The semantic scholar open research corpus. In Proceedings of the 58th Annual Meeting of the Association for Compu- tational Linguistics , pages 4969–4983, Online. Asso- ciation for Computational Linguistics.Yao Lu, Yue Dong, and Laurent Charlin. 2020. Multi- XScience: A large-scale dataset for extreme multi- document summarization of scientific articles. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) , pages 8068–8074. Association for Computational Linguistics',\n",
       " 'Xueguang Ma, Xinyu Zhang, Ronak Pradeep, and Jimmy Lin. 2023. Zero-shot listwise document reranking with a large language model. arXiv preprint arXiv:2305.02156 . Md Rizwan Parvez, Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. 2021. Retrieval augmented code generation and sum- marization. arXiv preprint arXiv:2108.11601 . Ronak Pradeep, Sahel Sharifymoghaddam, and Jimmy Lin. 2023a. Rankvicuna: Zero-shot listwise doc- ument reranking with open-source large language models. arXiv preprint arXiv:2309.15088 . Ronak Pradeep, Sahel Sharifymoghaddam, and Jimmy Lin. 2023b',\n",
       " 'Rankzephyr: Effective and robust zero- shot listwise reranking is a breeze! arXiv preprint arXiv:2312.02724 . Guanghui Qin and Jason Eisner. 2021. Learning how to ask: Querying LMs with mixtures of soft prompts. arXiv preprint arXiv:2104.06599 . Leigang Qu, Meng Liu, Jianlong Wu, Zan Gao, and Liqiang Nie. 2021. Dynamic modality interaction modeling for image-text retrieval. Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval . Ehud Reiter and Robert Dale. 1997. Building applied natural language generation systems. Natural Lan- guage Engineering , 3(1):57–87. Fobo Shi, Peijun Qing, D. Yang, Nan Wang, Youbo Lei, H. Lu, and Xiaodong Lin. 2023. Prompt space optimizing few-shot reasoning success with large language models',\n",
       " 'ArXiv , abs/2306.03799. Krishna Srinivasan, Karthik Raman, Jiecao Chen, Michael Bendersky, and Marc Najork. 2021. Wit: Wikipedia-based image text dataset for multimodal multilingual machine learning. Proceedings of the 44th International ACM SIGIR Conference on Re- search and Development in Information Retrieval . Amanda Stent, Rashmi Prasad, and Marilyn Walker. 2004. Trainable sentence planning for complex in- formation presentations in spoken dialog systems. In Proceedings of the 42nd Annual Meeting of the As- sociation for Computational Linguistics (ACL-04) , pages 79–86, Barcelona, Spain. Weiwei Sun, Lingyong Yan, Xinyu Ma, Pengjie Ren, Dawei Yin, and Zhaochun Ren. 2023. Is chatgpt good at search? investigating large lan- guage models as re-ranking agent',\n",
       " 'arXiv preprint arXiv:2304.09542 .Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic. 2022. Galactica: A large language model for science. arXiv preprint arXiv:2211.09085 . David Thulke, Nico Daheim, Christian Dugast, and Hermann Ney. 2021. Efficient retrieval augmented generation from unstructured knowledge for task- oriented dialog. arXiv preprint arXiv:2102.04643 . SM Tonmoy, SM Zaman, Vinija Jain, Anku Rani, Vip- ula Rawte, Aman Chadha, and Amitava Das. 2024. A comprehensive survey of hallucination mitigation techniques in large language models. arXiv preprint arXiv:2401.01313 ',\n",
       " 'Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V . Le. 2021. Finetuned language mod- els are zero-shot learners. ArXiv , abs/2109.01652. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed H Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits rea- soning in large language models. In Advances in Neural Information Processing Systems . Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Ye- ung, Mojtaba Seyedhosseini, and Yonghui Wu. 2022. Coca: Contrastive captioners are image-text founda- tion models. Trans. Mach. Learn. Res. , 2022',\n",
       " 'Xinyu Zhang, Sebastian Hofstätter, Patrick Lewis, Raphael Tang, and Jimmy Lin. 2023. Rank-without- gpt: Building gpt-independent listwise rerankers on open-source large language models. arXiv preprint arXiv:2312.02969 . Zijia Zhao, Longteng Guo, Xingjian He, Shuai Shao, Zehuan Yuan, and Jing Liu. 2022. Mamo: Fine- grained vision-language representations learning with masked multimodal modeling. Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval . Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. 2022. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910 ',\n",
       " 'Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Zhicheng Dou, and Ji-Rong Wen. 2023. Large language models for information retrieval: A survey. arXiv preprint arXiv:2308.07107 .Appendix Plan based generation prompt You are a helpful research assistant who is helping with literature review of a research idea. You will be provided with an abstract of a scientific document and other references papers in triple quotes. Your task is to write the related work section of the document using only the provided abstracts and other references papers. Please write the related work section creating a cohesive storyline by doing a critical analysis of prior work comparing the strengths and weaknesses while also motivating the proposed approach. You are also provided a sentence plan menti oning the total number of lines and the citations to refer in different lines',\n",
       " 'You should cite all the other related docu ments as [#] whenever you are referring it in the related work. Do not cite abstract. Do not include any extra notes or newline characters at the end. Do not copy the abstracts of reference papers directly but compare and contrast to the main work concisely . Do not provide the output in bullet points. Do not provide references at the end. Please cite all the provided reference papers. Please follow the plan when generating sentences, especially the number of lines and citations to generate. ```Abstract: {abstract} References: [1]: {text} [2]: {text} Plan: {plan} ``` Figure 7: Prompt for sentence plan-based generation In the following, we provide snippets of code to retrieve results from the Semantic Scholar API for both recommendation and query-based search: # QUERY BASED SEARCH def query_search_s2 ( query : str , num_papers_api : int , fields : str ): rsp = requests . get (\" https :// api ',\n",
       " 'semanticscholar . org / graph /v1/ paper / search \", headers ={\"X-API - KEY \": S2_API_KEY }, params ={\" query \": query , \" limit \": num_papers_api , \" fields \": fields }) rsp . raise_for_status () results = rsp . json () # Total papers found total = results [\" total \"] papers = results [\" data \"] return papers# PAPER SEARCH def get_paper_data ( paper_url : str , fields : str ): \"\"\" Retrieves data of one paper based on URL \"\"\" rsp = requests . get (f\" https :// api . semanticscholar . org / graph /v1/ paper / URL :{ paper_url }\", headers ={\"X-API - KEY \": S2_API_KEY }, params ={\" fields \": fields }) results = rsp ',\n",
       " 'json () return rewsults # RECOMMENDATION API def get_recommendations_from_s2 ( arxiv_id : str , num_papers_api : int , fields : str ): \"\"\" Get recommendations from S2 API \"\"\" query_id = f\" ArXiv :{ arxiv_id }\" rsp = requests . post (\" https :// api . semanticscholar . org / recommendations / v1/ papers /\", json ={ \" positivePaperIds \": [ query_id ]}, params ={\" fields \": fields , \" limit \": num_papers_api }) results = rsp . json () papers = results [\" recommendedPapers \" ] return papersAbstract for paper: Do DALL-E and Flamingo Understand Each Other? (Li et al., 2023) The field of multimodal research focusing on the comprehension and creation of both images and text has witnessed significant strides',\n",
       " 'This progress is exemplified by the emergence of sophisticated models dedicated to image captioning at scale, such as the notable Flamingo model and text-to-image generative models, with DALL-E serving as a prominent example. An interesting question worth exploring in this domain is whether Flamingo and DALL-E understand each other. To study this question, we propose a reconstruction task where Flamingo generates a description for a given image and DALL-E uses this description as input to synthesize a new image. We argue that these models understand each other if the generated image is similar to the given image. Specifically, we study the relationship between the quality of the image reconstruction and that of the text generation. We find that an optimal description of an image is one that gives rise to a generated image similar to the original one. The finding motivates us to propose a unified framework to finetune the text-to-image and image-to-text models',\n",
       " 'Concretely, the reconstruction part forms a regularization loss to guide the tuning of the models. Extensive experiments on multiple datasets with different image captioning and image generation models validate our findings and demonstrate the effectiveness of our proposed unified framework. As DALL-E and Flamingo are not publicly available, we use Stable Diffusion and BLIP in the remaining work. Project website: https://dalleflamingo.github.io',\n",
       " 'LLM summarized query: Multimodal Research: Image-Text Model Interaction Retrieved papers: (User Input: 4) [1]CoCa: Contrastive Captioners are Image-Text Foundation Models (2022) Cited by 702 (Yu et al., 2022) [2]MAMO: Fine-Grained Vision-Language Representations Learning with Masked Multimodal Modeling (2022) Cited by 0 (Zhao et al., 2022) [3]Dynamic Modality Interaction Modeling for Image-Text Retrieval (2021) Cited by 88 (Qu et al., 2021) [4]WIT: Wikipedia-based Image Text Dataset for Multimodal Multilingual Machine Learning (2021) Cited by 185 (Srinivasan et al., 2021) Zero shot Generation (Section 3.3.1) The field of multimodal research has seen significant advancements in recent years, with the development',\n",
       " 'of models such as Flamingo and DALL-E that focus on image captioning and text-to-image generation respectively',\n",
       " 'However, the question of whether these models can understand each other and work in harmony is a topic of interest. In this context, the work of [1] presents the Contrastive Captioner (CoCa), a model that combines contrastive loss and captioning loss to pretrain an image-text encoder-decoder foundation model. This model, while efficient, does not fully address the interaction between image and text modalities at a fine-grained level. The work of [2] addresses this gap by proposing a jointly masked multimodal modeling method that focuses on fine-grained multimodal representations. This method performs joint masking on image-text input and integrates both implicit and explicit targets for the masked signals to recover. However, this approach, while effective, does not fully address the challenges of intra-modal reasoning and cross-modal alignment that are inherent in image-text retrieval. The work of [3] presents a novel modality interaction modeling network based on the routing mechanism, which is the first unified and dynamic multimodal interaction framework towards image-text retrieval',\n",
       " 'This model can dynamically learn different activated paths for different data, providing a more flexible approach to modality interaction. However, the design of interaction patterns in this model still relies heavily on expert experience and empirical feedback, which may limit its applicability in different contexts. The work of [4] introduces the Wikipedia-based Image Text (WIT) Dataset, a large-scale dataset for multimodal, multilingual learning. This dataset, while providing a rich resource for multimodal learning, does not directly address the question of how different models can understand each other and work together. In light of these previous works, our study proposes a reconstruction task where Flamingo generates a description for a given image and DALL-E uses this description as input to synthesize a new image. We argue that these models understand each other if the generated image is similar to the given image',\n",
       " 'This approach allows us to study the relationship between the quality of the image reconstruction and that of the text generation, and to propose a unified framework to finetune the text-to-image and image-to-text models. Our extensive experiments validate our findings and demonstrate the effectiveness of our proposed unified framework. Plan based generation (Section 3.3.2) : Generate the output using 5 sentences. Cite [1] on line 2. Cite [2], [3] on line 3. Cite [4] on line 5. The field of multimodal research has seen significant advancements in the comprehension and creation of both images and text, with models like Flamingo and DALL-E leading the way. In a similar vein, the Contrastive Captioner (CoCa) model presented in [1] pretrains an image-text encoder-decoder foundation model with contrastive loss and captioning loss, achieving state-of-the-art performance on a broad range of downstream tasks',\n",
       " 'Other works have also focused on improving the fine-grained image-text interaction, with [2] proposing a jointly masked multimodal modeling method and [3] developing a dynamic multimodal interaction framework for image-text retrieval. These models, while effective, often rely on expert experience and empirical feedback, which may limit their flexibility. The introduction of the Wikipedia-based Image Text (WIT) Dataset in [4] provides a large, multilingual dataset for pretraining multimodal models, offering a more diverse set of concepts and real-world entities for model training. This diversity and scale could potentially enhance the performance of models like Flamingo and DALL-E, further advancing the field of multimodal research. Table 1: We show an example generated related work for a randomly chosen recent paper (Li et al., 2023) with LLM summarized query and retrieved papers. We show the generated related work from our system using both zero-shot and plan-based generation, producing a more succinct and readily usable literature review',\n",
       " 'Note: The number of citations is retrieved by Semantic Scholar at the date of submission of this work.',\n",
       " 'arXiv:1901.09492v1 [cs.CL] 28 Jan 2019Neural Related Work Summarization with a Joint Context-dri ven Attention Mechanism Yongzhen Wang1∗, Xiaozhong Liu2,3, Zheng Gao2 1School of Maritime Economics and Management, Dalian Mariti me University, Dalian, China 2School of Informatics, Computing and Engineering, Indiana University Bloomington, Bloomington, IN, USA 3Alibaba Group, Hangzhou, China ∗kuadmu@163.com liu237@indiana.edu gao27@umail.iu.edu Abstract Conventional solutions to automatic related work summarization rely heavily on human- engineered features',\n",
       " 'In this paper, we develop a neural data-driven summarizer by leverag- ing the seq2seq paradigm, in which a joint context-driven attention mechanism is pro- posed to measure the contextual relevance within full texts and a heterogeneous bibliog- raphy graph simultaneously. Our motivation is to maintain the topic coherency between a related work section and its target document, where both the textual and graphic contexts play a big role in characterizing the relation- ship among scientiﬁc publications accurately. Experimental results on a large dataset show that our approach achieves a considerable im- provement over a typical seq2seq summarizer and ﬁve classical summarization baselines. 1 Introduction In scientiﬁc ﬁelds, scholars need to contextualize their contribution to help readers acquire an un- derstanding of their research papers',\n",
       " 'For this pur- pose, the related work section of an article serves as a pivot to connect prior domain knowledge, in which the innovation and superiority of current work are displayed by a comparison with previ- ous studies. While citation prediction can assist in drafting a reference collection ( Nallapati et al. , 2008 ), consuming all these papers is still a labo- rious job, where authors must read every source document carefully and locate the most relevant content cautiously. As a solution in saving authors’ efforts, au- tomatic related work summarization is essen- tially a topic-biased multi-document problem (Cong and Kan ,2010 ), which relies heavily on human-engineered features to retrieve snippets ∗Corresponding authorfrom the references. Most recently, neural net- works enable a data-driven architecture sequence- to-sequence (seq2seq) for natural language gener- ation ( Bahdanau et al',\n",
       " ',2014 ,2016 ), where an en- coder reads a sequence of words/sentences into a context vector, from which a decoder yields a sequence of speciﬁc outputs. Nonetheless, com- pared to scenarios like machine translation with an end-to-end nature, aligning a related work section to its source documents is far more challenging. To address the summarization alignment, for- mer studies try to apply an attention mechanism to measure the saliency/novelty of each candidate word/sentence ( Tan et al. ,2017 ), with the aim of locating the most representative content to retain primary coverage. However, toward summarizing a related work section, authors should be more cre- ative when organizing text streams from the refer- ence collection, where the selected content ought to highlight the topic bias of current work, rather than retell each reference in a compressed but bal- anced fashion',\n",
       " 'This motivates us to introduce the contextual relevance and characterize the relation- ship among scientiﬁc publications accurately. Generally speaking, for a pair of documents, a larger lexical overlap often implies a higher sim- ilarity in their research backgrounds. Yet such a hypothesis is not always true when sampling con- tent from multiple relevant topics. Take “DSSM”1 as an example, from viewpoint of the abstract sim- ilarity, those references investigating “Information Retrieval”, “Latent Semantic Model” or “Click- through Data Mining” could be of more impor- tance in correlation and should be greatly sampled for the related work section. But in reality, this ar- ticle spends a bit larger chunk of texts (about 58%) to elaborate “Deep Learning” during the litera- ture review, which is quite difﬁcult for machines 1Learning deep structured semantic models for web search using clickthrough data ( Huang et al',\n",
       " ',2013 )to grasp the contextual relevance therein. In addi- tion, other situations like emerging new concepts also suffer from the terminology variation or para- phrasing in varying degrees. In this study, we utilize a heterogeneous bibli- ography graph to embody the relationship within a scalable scholarly database. Over the recent past, there is a surge of interest in exploiting diverse re- lations to analyze bibliometrics, ranging from lit- erature recommendation ( Yu et al. ,2015 ) to topic evolvement ( Jensen et al. ,2016 ). In a graphical sense, interconnected papers transfer the credit among each other directly/indirectly through var- ious patterns, such as paper citation, author col- laboration, keyword association and releasing on series of venues, which constitutes the graphic context for outlining concerned topics. Unfortu- nately, a variety of edge types may pollute the in- formation inquiry, where a slice of edges are not so important as the others on sampling content',\n",
       " 'Meanwhile, most existing solutions in mining het- erogeneous graphs depend on the human supervi- sion, e.g., hyperedge (Bu et al. ,2010 ) and metap- ath(Swami et al. ,2017 ). This is usually not easy to access due to the complexity of graph schemas. Our contribution is threefold: First, we explore theedge-type usefulness distribution (EUD) on a heterogeneous bibliography graph, which en- ables the relationship discovery (between any pair of papers) for sampling the interested informa- tion. Second, we develop a novel seq2seq summa- rizer for the automatic related work summariza- tion, where a joint context-driven attention mech- anism is proposed to measure the contextual rel- evance within both textual and graphic contexts',\n",
       " 'Third, we conduct experiments on 8,080 papers with native related work sections, and experimen- tal results show that our approach outperforms a typical seq2seq summarizer and ﬁve classical summarization baselines signiﬁcantly. 2 Related Work This study touches on several strands of research within automatic related work summarization and seq2seq summarizer as follows. The idea of creating a related work section au- tomatically is pioneered by Cong and Kan (2010 ) who design two rule-based strategies to extract sentences for general and detailed topics respec- tively. Subsequently, Hu and Wan (2014 ) ex- ploit probabilistic latent semantic indexing toAuthors Number of papers Cong and Kan (2010 ) 20 Hu and Wan (2014 ) 1,050 Widyantoro and Amin (2014 ) 50 Chen and Hai (2016 ) 3 Table 1: Data scales of previous studies on automatic related work summarization',\n",
       " 'split candidate texts into different topic-biased parts, then apply several regression models to learn the importance of each sentence. Similarly, Widyantoro and Amin (2014 ) transform the sum- marization problem into classifying rhetorical cat- egories of sentences, where each sentence is rep- resented as a feature vector containing word fre- quency, sentence length and etc. Most recently, Chen and Hai (2016 ) construct a graph of repre- sentative keywords, in which a minimum steiner treeis ﬁgured out to guide the summarization as ﬁnding the least number of sentences to cover the discriminated nodes. In general, compared to traditional summaries, the automatic related work summarization receives less concerns over the past. However, these existing solutions can- not work without manual intervention, which lim- its the application scale to an extremely small size (see Table 1). The earliest seq2seq summarizer stems from Rush et al',\n",
       " '(2015 ) which utilizes a feed-forward network for compressing sentences, and later is expanded by Chopra et al. (2016 ) with a re- current neural network (RNN). On this basis, Nallapati et al. (2016a ,c) and Chen et al. (2016 ) both present a set of RNN-based models to ad- dress various aspects of abstractive summariza- tion. Typically, Cheng and Lapata (2016 ) pro- pose a general seq2seq summarizer, where an encoder learns the representation of documents while a decoder generates each word/sentence us- ing an attention mechanism. With further re- search, Nallapati et al. (2016b ) extend the sen- tence compression by trying a hierarchical atten- tion architecture and a limited vocabulary during the decoding phase. Next, Narayan et al. (2017 ) leverage the side information as an attention cue to locate focus regions for summaries',\n",
       " 'Recently, inspired by PageRank ,Tan et al. (2017 ) introduce a graph-based attention mechanism to tackle the saliency problem. Nonetheless, these methods all discuss the single-document scenario, which is far from the nature of automatic related work summa- rization.In this study, derived from the general seq2seq summarizer of Cheng and Lapata (2016 ), we pro- pose a joint context-driven attention mechanism to measure the contextual relevance within full texts and a heterogeneous bibliography graph simulta- neously. To our best knowledge, we make the ﬁrst attempt to develop a neural data-driven solution for the automatic related work summarization, and the practice of using the joint context as an atten- tion cue is also less explored to date. Besides, this study is launched on a dataset with up to 8,080 pa- pers, which is much greater than previous studies and makes our results more convincing',\n",
       " 'Since text summarization via word-by- word generation is not mature at present (Cheng and Lapata ,2016 ;Nallapati et al. ,2016b ; Tan et al. ,2017 ), we adopt the extractive senten- tial fashion for our summarizer, where a related work section is created by extracting and linking sentences from a reference collection. Meanwhile, this study follows the mode of Cong and Kan (2010 ) who assume that the collection is given as part of the input, and do not consider the citation sentences of each reference. 3 Methodology 3.1 Problem Formulation To adapt the seq2seq paradigm, we formulate the automatic related work summarization into a se- quential text generation problem as follows. Given an unedited paper t(target document) and itsn-size reference collection Rt={rt 1:n}, we draw up a related work section for tby select- ing sentences from Rt',\n",
       " 'To be speciﬁc, each refer- ence (source document) will be traversed one time sequentially, and without loss of generality, in the descending order of their signiﬁcance to t. Con- sequently, all sentences to be selected are concate- nated into an m-length sequence St={st 1:m}to feed the summarizer. For each candidate sentence st j, once being visited, a label yt j∈ {0,1}will be determined synchronously based on whether or not this sentence should be covered into the output. Our objective is to maximize the log- likelihood probability of observed labels Yt= {yt 1:m}underRt,Stand summarizer parameters θ, as shown below',\n",
       " 'maxm/summationdisplay j=1logPr(yt j|Rt;St;θ) (1)3.2 Random Walk on Heterogeneous Bibliography Graph author paper keyword venuewritten bycite publish contributecontributecoauthor contributerelevantjoin investigate Figure 1: Heterogeneous bibliography graph. Prior works have illustrated that one of the most promising channels for information recommen- dation is the community network ( Guo and Liu , 2015 ). In this study, we verify this hypothesis toward the content sampling of scientiﬁc summa- rization, by investigating heterogeneous relations among different kinds of objects such as papers, authors, keywords and venues. For measuring the relationship among scien- tiﬁc publications, we introduce a directed graph G= (V,E)to contain various bibliographical con- nections, as shown in Figure 1, which involves four objects and ten edge types in total',\n",
       " 'Each edge ej,i∈Eis assigned a valueπ(ej,i) z∈[0,1]to indi- cate the transition probability between two nodes vj,vi∈V, whereπ(ej,i)∈Rreturns the un- known edge-type usefulness of ej,i, andz∈Ris a normalizing weight. For most of edge types, we model the weight as one divided by the number of outgoing links of the same kind. But regard- ing the “contribution” category, the weight mod- eling is accomplished by PageRank with Priors (White and Smyth ,2003 ). Note that different edge types usually take very uneven importance in one particular task ( Yu et al. ,2015 ), and it is quite dif- ﬁcult to enable the classical heterogeneous graph mining without expert deﬁned paths for random walk (Bu et al. ,2010 ;Swami et al. ,2017 )',\n",
       " 'In this study, we propose an unsupervised ap- proach to capture the connectivity diversity, by introducing an optimal EUD for navigating ran- dom walkers on the heterogeneous bibliography graph. Given a target document t, the optimizedusefulness assignment can help those walkers lock a top-nrecommendation ¯Rtto best match the ref- erence collection Rt, as shown in Eq. 2. On this basis, a well-performing algorithm node2vec (Grover and Leskovec ,2016 ) is adopted to con- duct an unsupervised random walk to vectorize ev- ery node ∀v∗∈Vinto ad-dimensional embed- dingϕ(v∗)∈Rdso that any edge ∀e∗∈Ecan be calculated therefrom. Speciﬁcally, we employ evolutionary algorithm (EA) to tune the EUD, which enjoys advantages over conventional gradi- ent methods in both convergence speed and accu- racy',\n",
       " 'argmax/summationdisplay tn/summationdisplay j=1logPr(rt j∈¯Rt|EUD)(2) EA Setup We use an array of real numbers x1:10 to code an individual in the population, where xj∈[0,1]denotes the usefulness of j-th edge type. Given an EUD, PageRank (Page ,1998 ) runs on graph to infer the relative importance of each node for each target document, and a ﬁtness func- tion is applied to judge how well this EUD satis- ﬁes locating the ground truth references as Eq. 3, in which if rt jbelongs to ¯Rt, thenα(rt j,¯Rt)∈N returns the ranking of rt jwithin¯Rt, and otherwise a big penalty coefﬁcient to prevent irrelevant ref- erences to be recommended',\n",
       " 'Like most other op- timizations, this procedure starts with a randomly generated population. max1 /summationtext t/summationtextn j=1/vextendsingle/vextendsingle/vextendsinglej−α(rt j,¯Rt)/vextendsingle/vextendsingle/vextendsingle(3) EA Operator We choose the operator from dif- ferential evolution (Das and Suganthan ,2011 ) to generate offsprings for each individual. The basic idea is to utilize the difference between different individuals to disturb each trial object. First, three distinct individuals xr1 1:10,xr2 1:10,xr3 1:10are sampled randomly from current population to create a vari- antxvar 1:10, as shown in Eq. 4, wheref∈Rin- dicates the scaling factor',\n",
       " 'Next, xvar 1:10is crossed with a trial object xtri 1:10to build a hybrid one xhyb 1:10 as Eq. 5, in which c∈[0,1]denotes the crossover factor and u∈[0,1]represents an uniform random number. At last, the ﬁtnesses of xtri 1:10andxhyb 1:10are compared, and the better one will be saved as the offspring into a new round of evolution. xvar j=xr1 j+f×(xr2 j−xr3 j) (4)xhyb j=\\uf8f1 \\uf8f2 \\uf8f3xvar j,ifu≤c xtri j,otherwise(5) 3.3 Neural Extractive Summarization As Figure 2shows, we model our seq2seq summa- rizer with a hierarchical encoder and an attention- based decoder, as described below',\n",
       " 'Hierarchical Encoder Our encoder consists of two major layers, namely a convolutional neu- ral network (CNN) and a long-short-term mem- ory(LSTM)-based RNN. Speciﬁcally, the CNN deals with word-level texts to derive sentence- level meanings, which are then taken as inputs to the RNN for handling longer-range dependency within lager units like a paragraph and even a whole paper. This conforms to the nature of docu- ment that is composed from words, sentences and higher levels of abstraction ( Narayan et al. ,2017 ). Consider a sentence of pwordsst j={wt j,1:p}, where each word wt j,ican be represented by a d- dimensional embedding φ(wt j,i)∈Rd. Previ- ous studies have illustrated the strength of CNN in presenting sentences, because of its capability to learn compressed expressions and address sen- tences with variable lengths ( Kim,2014 )',\n",
       " 'First, a convolution kernel k∈Rd×q×dis applied to each possible window of qwords to construct a list of feature maps as: gt j,i= tanh/parenleftbig k×φ(wt j,i:i+q−1)+b/parenrightbig (6) whereb∈Rddenotes the bias term. Next, max- over-time pooling (Collobert et al. ,2011 ) is per- formed on all generated features to obtain the sen- tence embedding as: φ(st j) = max 1≤i≤d/parenleftbig gt j,1:p−q+1[i,:]/parenrightbig (7) where[i,:]denotes the i-th row of matrix',\n",
       " 'Given a sequence of sentences St={st 1:m}, we then take the RNN to yield an equal-length array of hidden states, in which LSTM has proved to al- leviate the vanishing gradient problem when train- ing long sequences ( Hochreiter and Schmidhuber , 1997 ). Each hidden state can be viewed as a lo- cal representation with focusing on current and former sentences together, which is updated as: ht j=LSTM/parenleftbig φ(st j),ht j−1/parenrightbig ∈Rd. In practice, we use multiple kernels with vari- ous widths to produce a group of embeddings forhidden state ( )tsj \\x01 word embeddingfeature map sentence embeddingmax-over-time pooling convolution average( )t ,1wj \\x00 ( )t ,6wj \\x02( )t ,2wj \\x03..',\n",
       " 'Hierarchical Encodert 1yj \\x04tyjtymt 1yi+t 2yi+t 1yt 2ytyi thjt 1hj\\x05thmt 1hi+t 2hi+t 1ht 2hthi context vectorbinary decision()t \\x06( )t 1r \\x07( )t 2r \\x08( )trn node embedding t 1r t 2r trnt ... ... ...... ... ... ... ... ... Attention-based Decoderthj 1 2 3 4 5 1 2 3 4attention Figure 2: Framework of our seq2seq summarizer. each sentence, and average them to capture the information inside different n-grams',\n",
       " 'As Figure 2(bottom) shows, the sentence st jinvolves six words, and two kernels of widths two (orange) and three (green) abstract a set of ﬁve and four fea- ture maps respectively. Meanwhile, since rhetori- cal structure theory (Mann and Thompson ,2009 ) points out that association must exist in any two parts of coherent texts, RNN is only applicable to manage the sentence relation within a single doc- ument, because we cannot expect the dependency between two sections from different references. Attention-based Decoder Our decoder labels each sentence st jas 0/1 sequentially, according to whether it is salient or novel enough, plus if rele- vant to the target document tor not. As shown in Figure 2(top), the binary decision yt jis made by both the hidden state ht jand the context vector ¯ht j from an attention mechanism (grey background)',\n",
       " 'In particular, this attention (red dash line) is acted as an intermediate stage to determine which sen- tences to highlight so as to provide the contextual information for current decision ( Bahdanau et al. , 2014 ). GivenHt={ht 1:m}, this decoder returnsthe probability of yt j= 1as below: Pr(yt j= 1|Rt;St;θ) =sigmoid/parenleftbig δ(ht j,¯ht j)/parenrightbig (8) ¯ht j=m/summationdisplay i=1aj,iht i (9) whereδ(ht j,¯ht j)∈Rdenotes a fully connected layer with as input the concatenation of ht jand¯ht j, andaj,i∈[0,1]is the attention weight indicating how much the supporting sentence st icontributes to extracting the candidate one st j. Apart from saliency and novelty two traditional attention factors ( Chen et al',\n",
       " ',2016 ;Tan et al. , 2017 ), we focus on the contextual relevance within both textual and graphic contexts to distinguish the relationship from near to far, as shown in Eq. 10 and Eq. 11. To be speciﬁc: 1) htT jWsht irepre- sents the saliency of st itost j; 2)−dtT jWnht iindi- cates the novelty of st ito the dynamic output dt j; 3)φ(t)TWtht idenotes the relevance of st itot from the textual context; 4) ϕ(t)TWgϕ(ht i)refers to the relevance from the graphic context',\n",
       " 'Moreconcretely, W∗∈Rdcharacterizes the learnable matrix,φ(t)returns the average of hidden states fromt,ϕ(t)andϕ(ht i)return the node embed- dings of both tand the source document that ht i belongs to respectively. Note that φ(·)andϕ(·) represent two distinct embedding spaces, where the former reﬂects the lexical collocations of cor- pus, and the latter embodies the connectivity pat- terns of associated graph',\n",
       " 'aj,i=htT jWsht i# saliency −dtT jWnht i# novelty +φ(t)TWtht i# relevance 1 +ϕ(t)TWgϕ(ht i)# relevance 2(10) dt j=j−1/summationdisplay i=1Pr(yt j= 1|Rt;St;θ)×ht i (11) The basic idea behind our attention mechanism is as follows: if a supporting sentence more re- sembles a candidate one, or overlaps less with the dynamic output, or is more relevant to the target document, then it can provide more contextual in- formation to facilitate current decision on being extracted or not, thereby taking a higher weight in the generated context vector',\n",
       " 'This innovative at- tention will guide our goal related work section to maximize the representativeness of selected sen- tences (saliency & novelty), while minimizing the semantic distance to the target document (rele- vance). This is consistent with the way that schol- ars consume a reference collection, with the min- max objective in their minds. 4 Experiment 4.1 Experimental Setup This section presents the experimental setup for assessing our approach, including 1) dataset used for training and testing, 2) implementation details, 3) contrast methods and evaluation metrics. Dataset We conduct experiments on a dataset2 created from the ACM digital library, where meta- data and full texts are derived from PDF ﬁles. To be detailed, this dataset includes 371,891 papers, 2To help readers reproduce the experiment outcome, we share part of the experiment data while the copyrighted information is removed',\n",
       " 'https://github.com/kuadmu/2018EMNLP779,810 authors, 9,204 keywords and 807 venues in total. Note that we ignore the keyword with frequency below a certain threshold, and adopt greedy matching ofGuo et al. (2013 ) to generate pseudo keywords for papers lacking topic descrip- tions. For each target document, the references are traversed by the descending order of the cited number in related work section (primary) and in full paper (secondary) successively. We ﬁrst ap- ply a series of pre-processings such as lowercasing and stemming to standardize candidate sentences, then remove those which are too short/long ( <7 or>80words). On this basis, a total of 8,080 papers are selected to evaluate our approach, each containing more than 15 references found in the dataset and a related work section of at least 500 words',\n",
       " 'But as for the heterogeneous bibliography graph, all source data have to be imported to en- sure the structural integrity of communities. Be- sides, this graph should be constructed year-by- year to preclude the effect of later publications on earlier ones. Implementation We use Tensorﬂow for imple- mentation, where both the dimensions of embed- ding and hidden state are equally 128. For the CNN, word2vec (Mikolov et al. ,2013 ) is utilized to initialize the word embeddings, which can be further tuned during the training phase. Mean- while, we follow the work of Kim (2014 ) to ap- ply a list of kernels with widths {3,4,5}. As for the RNN, each LSTM module is set to one single layer, and all input documents are padded to the same length, along with a mark to indicate the real number of sentences',\n",
       " 'Based on these settings, we train our summarizer using Adam with the default inKingma and Ba (2014 ), and perform mini-batch cross-entropy training with a batch of one target document for 20 epochs. To create training data for our summarizer, each reference needs to be annotated with the ground truth in advance, i.e., candidate sentences are tagged with 0/1 for indicating summary-worthy or not. Speciﬁcally, we follow a heuristic practice ofCao et al. (2016 ) and Nallapati et al. (2016b ) to compute ROUGE-2 score ( Lin and Hovy ,2003 ) for each sentence, in terms of the native related work sections (gold standards). Next, those sen- tences with high scores are chosen as the positive samples, and the rest as the negative ones, such that the total score of selected sentences is max- imized with respect to the gold standard',\n",
       " 'As fortesting, we relax the number of sentences to be se- lected, and focus on the classiﬁcation probability from Eq. 8. In this study, cross validation is ap- plied to split the dataset into ten parts equally at random, in which nine are used for training and the other one for testing. Evaluation We adopt the widely used toolkit ROUGE ( Lin and Hovy ,2003 ) to evaluate the summarization performance automatically. In par- ticular, we report ROUGE-1 and ROUGE-2 (uni- gram and bigram overlapping) as a way to assess the informativeness, and ROUGE-L (the longest common subsequence) as a means to assess the ﬂuency, in terms of ﬁxed bytes of gold standards',\n",
       " 'To validate the proposed attention mecha- nism, we compare our approach (denoted as P.S+N+Rteg+EUD ) against six variants, including: 1) P.void: a plain seq2seq summarizer without atten- tions; 2) P. S: use the saliency as an only atten- tion factor; 3) P. S+N: leverage both the saliency and novelty; 4) P. S+N+Rt : incorporate the relevance from the textual context; 5) P. S+N+Rtog : gain the relevance from the graphic context of a homo- geneous citation graph; 6) P. S+N+Rteg : utilize the heterogeneous bibliography graph, but with each edge type the same usefulness. In addition, we also select six representative summarization methods as a benchmark group',\n",
       " 'The ﬁrst one is the general seq2seq summarizer byCheng and Lapata (2016 ), denoted as Pointer- Net, which employs an attention mechanism to ex- tract sentences directly after reading them. Fol- lowing are ﬁve classical generic solutions, includ- ing: 1) Luhn ( Luhn ,1958 ): a heuristic summa- rization based on word frequency and distribu- tion; 2) MMR ( Carbonell and Goldstein ,1998 ): a diversity-based re-ranking to produce summaries; 3) LexRank ( Erkan et al. ,2004 ): a graph-based summary technique inspired by PageRank and HITS ; 4) SumBasic ( Nenkova and Vanderwende , 2005 ): a frequency-based summarizer with du- plication removal; 5) NltkSum ( Acanfora et al',\n",
       " ', 2014 ): a natural language tookit (NLTK)-based implementation for summarization. For clarity, Luhn, LexRank and SumBa- sic are analogous to the work of Hu and Wan (2014 ) which extracts sentences scoring the high- est in signiﬁcance, and they are also con- trasted in the latest studies on neural summariz- ers ( Chen et al. ,2016 ;Tan et al. ,2017 ). Mean- while, MMR often serves as a part/post-processingof existing techniques to avoid the redundancy (Cohan and Goharian ,2017 ), and we introduce NltkSum to investigate the impact of grammat- ical/semantic analysis to the automatic related work summarization. Note that former studies specially for this task require extensive human in- volvements (see Table 1), thus we cannot apply them to such a large dataset of this study',\n",
       " '4.2 Results and Discussion Table 2reports the evaluation comparison over ROUGE metrics. From the top half, all scores ap- pear a gradual upward trend with incorporation of saliency, novelty, relevance (from both textual and graphic contexts) and EUD into consideration one after another, which demonstrates the validity of our attention mechanism for summarizing related work sections. To be speciﬁc, we further reach the following conclusions: 1) P. voidvs. P. Svs. P. S+N: Both saliency and novelty are two effective factors to locate the re- quired content for summaries, which is consistent with prior studies. 2) P. S+Nvs. P. S+N+Rt : Contextual relevance does contribute to address the alignment between a re- lated work section and its source documents. 3) P. S+N+Rt vs. P. S+N+Rtog : Textual context alone cannot provide entire evidence to characterize the relationship among scientiﬁc publications exactly. 4) P',\n",
       " 'S+N+Rtog vs. P. S+N+Rteg : Heterogeneous bib- liography graph involves richer contextual infor- mation than a homogeneous citation graph. 5) P. S+N+Rteg vs. P. S+N+Rteg+EUD : EUD plays an indispensable role in organizing accurate contex- tual relevance on a heterogeneous graph. Figure 3: Number of extracted words on each reference cluster under different attention factors',\n",
       " 'Continuing the “DSSM”, Figure 3visualizes the number of extracted words on each referenceMethods ROUGE-1 ROUGE-2 ROUGE-L P.void 26.85* 6.38* 14.22* P.S 26.98* 6.48* 14.36* P.S+N 27.29* 6.65* 14.43* P.S+N+Rt 27.63* 6.72* 14.46* P.S+N+Rtog 27.82* 7.00* 14.55* P.S+N+Rteg 28.56* 7.40 14.70* P.S+N+Rteg+EUD 29.18 7.63 14.89 Luhn 25.76* 5.08* 13.50* MMR 25.55* 5.14* 13.99* LexRank 25.07* 5.12* 13.95* SumBasic 28.01*',\n",
       " '5.44* 13.93* NltkSum 28.07* 6.36* 14.87 PointerNet 27.06* 6.53* 14.41* * indicates Wilcoxon signed-rank test p <0.01, compared with P',\n",
       " 'S+N+Rteg+EUD Table 2: Rouge evaluation (%) on 8,080 papers from ACM digita l library. cluster3under different attention factors. It can be seen that only after adding the relevance es- pecially that from the graphic context into atten- tions, our summarizer can correctly sample the content from “Deep Learning” (yellow line), and eliminate that originated from “Other Sources” by a big margin (green line). As this example falls into the methodology transferring, a host of its in- volved word collocations are not idiomatic com- binations yet, such as “Deep Neural Network” co- occurs with “Clickthrough Data” that is more fre- quently related to “Latent Semantic Analysis” at that time, which results in a somewhat biased tex- tual context',\n",
       " 'By contrast, the graphic context will suffer less from this bias because it characterizes the connectivity patterns (real-time setup) instead ofn-gram statistics, thus offering a more robust measure for the contextual relevance. The bottom half of Table 2illustrates the superi- ority of our approach over six representative sum- marization methods. Above all, Luhn, LexRank and MMR three summarizers that simply exploit shallow text features (word frequency and asso- ciated sentence similarity) to measure either sig- niﬁcance or redundancy fall far behind the plain variant P. void, which partly reﬂects the strength of seq2seq paradigm in summarizing a related work section',\n",
       " 'Second, with combination of sig- niﬁcance and redundancy, SumBasic achieves a drastic increase on ROUGE-1 and a mild raise on 3We pack the references cited in the same subsection of the related work section as one reference cluster.ROUGE-2 respectively, but it still cannot improve ROUGE-L marginally. This is because simple text statistics cannot present deeper levels of natu- ral language understanding to catch larger-grained units of co-occurrence. Third, NltkSum beneﬁts from a NLTK library so as to access grammati- cal/semantic supports, thereby having the best in- formativeness (ROUGE-1 and ROUGE-2) among the ﬁve generic baselines, and meanwhile a com- parable ﬂuency (ROUGE-L) with our approach',\n",
       " 'Finally, as a deep learning solution, although PointerNet takes both hidden states and previously labeled sentences into account, at each decoding step it focuses on only current and just one pre- vious sentences, lacking a comprehensive consid- eration on saliency, novelty and more importantly the contextual relevance ( <P.S+N). To better verify the summarization perfor- mance, we also conduct a human evaluation on 35 papers containing more than 30 references in the dataset',\n",
       " 'We assign a number of raters to com- pare each generated related work section against the gold standard, and judge by three independent aspects as: 1) How compliant is the related work section to the target document? 2) How intuitive is the related work section for readers to grasp the key content? 3) How useful is the related work section for researchers to prepare their ﬁnal liter- ature reviews? Note that we do not allow any ties during the comparison, and each property is as- sessed with a 5-point scale of 1 (worst) to 5 (best)',\n",
       " 'Table 3displays how often raters rank each summarizer as the 1st, 2nd and so on, in terms ofMethods 1st 2nd 3rd 4th 5th 6th 7th Mean Ranking Luhn 0.04 0.07 0.09 0.13 0.17 0.23 0.29 5.26 MMR 0.05 0.07 0.11 0.16 0.19 0.22 0.20 4.82 LexRank 0.06 0.09 0.11 0.14 0.17 0.19 0.27 4.93 SumBasic 0.09 0.13 0.18 0.18 0.18 0.15 0.10 4.10 NltkSum 0.21 0.21 0.20 0.15 0.10 0.07 0.04 3.00 PointerNet 0.14 0.20 0.18 0.15 0.13 0.11 0.08',\n",
       " '3.54 P.S+N+Rteg+EUD 0.40 0.22 0.14 0.09 0.06 0.04 0.02 2.34 Table 3: Human evaluation (proportion) on 35 papers with mor e than 30 references in the dataset',\n",
       " 'best-to-worst. Speciﬁcally, our approach comes the 1st on 40% of the time, which is followed by NltkSum that is considered the best on 21% of the time (almost half of ours), and Pointer- Net with quite equal proportions on each rank- ing. Furthermore, the other four summarizers ac- count for obviously lower ratings in general. To attain the statistical signiﬁcance, one-way analy- sis of variance (ANOV A) is performed on the ob- tained ratings, and the results show that our ap- proach is better than all six contrast methods sig- niﬁcantly ( p <0.01), which means that the con- clusion drawn by Table 2is sustained',\n",
       " '5 Conclusion In this paper, we highlight the contextual rele- vance for the automatic related work summariza- tion, and analyze the graphic context to charac- terize the relationship among scientiﬁc publica- tions accurately. We develop a neural data-driven summarizer by leveraging the seq2seq paradigm, where a joint context-driven attention mechanism is proposed to measure the contextual relevance within full texts and a heterogeneous bibliogra- phy graph simultaneously. Extensive experiments demonstrate the validity of the proposed attention mechanism, and the superiority of our approach over six representative summarization baselines. In future work, an appealing direction is to or- ganize the selected sentences in a logical fash- ion, e.g., by leveraging a topic hierarchy tree to determine the arrangement of the related work section ( Cong and Kan ,2010 )',\n",
       " 'We also would like to take the citation sentences of each refer- ence into consideration, which is another concise and universal data source for scientiﬁc summariza- tion ( Chen and Hai ,2016 ;Cohan and Goharian , 2017 ). At the end of this paper, we believe that extractive methods are by no means the ﬁnal so- lutions for literature review generation due to pla-giarism concerns, and we are going to put forward a fully abstractive version in further studies. Acknowledgement We would like to thank the anonymous reviewers for their valuable comments. This work is partially supported by the National Science Foundation of China under grant No. 71271034. References Joseph Acanfora, Marc Evangelista, David Keimig, and Myron Su. 2014. Natural language process- ing: generating a summary of ﬂood disasters. Cell, 41(2):383–94',\n",
       " 'Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben- gio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473 . Dzmitry Bahdanau, Jan Chorowski, Dmitriy Serdyuk, Philemon Brakel, and Yoshua Bengio. 2016. End- to-end attention-based large vocabulary speech recognition. In Proceedings of the 41st IEEE ICASSP International Conference on Acoustics, Speech and Signal Processing, Shanghai, China , pages 4945–4949. Jiajun Bu, Shulong Tan, Chun Chen, Can Wang, Hao Wu, Lijun Zhang, and Xiaofei He. 2010. Music rec- ommendation by uniﬁed hypergraph:combining so- cial media information and music content',\n",
       " 'In Pro- ceedings of the ACM SIGMM International Con- ference on Multimedia, Amsterdam, Netherlands , pages 391–400. Ziqiang Cao, Wenjie Li, Sujian Li, Furu Wei, and Yan- ran Li. 2016. Attsum: Joint learning of focusing and summarization with neural attention. arXiv preprint arXiv:1604.00125 . Jaime Carbonell and Jade Goldstein. 1998. The use of mmr, diversity-based reranking for reordering doc- uments and producing summaries. In Proceedings of the 21st International ACM SIGIR Conference on Research and Development in Information Re- trieval, New York, USA , pages 335–336.Jingqiang Chen and Zhuge Hai. 2016. Summarization of related work through citations. In Proceedings of the 12th IEEE SKG International Conference on Semantics, Knowledge and Grids, Beijing, China , pages 54–61',\n",
       " 'Qian Chen, Xiaodan Zhu, Si Wei, Si Wei, and Hui Jiang. 2016. Distraction-based neural networks for modeling documents. In Proceedings of the ACM IJCAI International Joint Conference on Artiﬁcial Intelligence, New York, USA , pages 2754–2760. Jianpeng Cheng and Mirella Lapata. 2016. Neural summarization by extracting sentences and words. InProceedings of the 54th ACL Annual Meeting of the Association for Computational Linguistics, Berlin, Germany . Sumit Chopra, Michael Auli, and Alexander M. Rush. 2016. Abstractive sentence summarization with at- tentive recurrent neural networks. In Proceedings of the NAACL Conference of the North American Chapter of the Association for Computational Lin- guistics, San Diego, USA , pages 93–98. Arman Cohan and Nazli Goharian. 2017. Scien- tiﬁc article summarization using citation-context and article’s discourse structure',\n",
       " 'arXiv preprint arXiv:1704.06619 , pages 390–400. Ronan Collobert, Jason Weston, Michael Karlen, Ko- ray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing (almost) from scratch. Journal of Machine Learning Research , 12(1):2493–2537. Duy Vu Hoang Cong and Min Yen Kan. 2010. Towards automated related work summarization. In Pro- ceedings of the 23rd ACM COLING International Conference on Computational Linguistics, Beijing, China , pages 427–435. Swagatam Das and Ponnuthurai Nagaratnam Sugan- than. 2011. Differential evolution: A survey of the state-of-the-art. IEEE Transactions on Evolutionary Computation , 15(1):4–31. Erkan, Radev, and R Dragomir. 2004',\n",
       " 'Lexrank: graph- based lexical centrality as salience in text summa- rization. Journal of Qiqihar Junior Teachers Col- lege, 22:2004. Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceed- ings of the 22nd ACM SIGKDD International Con- ference on Knowledge Discovery and Data Mining, San Francisco, Usa , pages 855–864. Chun Guo and Xiaozhong Liu. 2015. Automatic fea- ture generation on heterogeneous graph for music recommendation. In Proceedings of the 38th In- ternational ACM SIGIR Conference on Research and Development in Information Retrieval, Santi- ago, Chile , pages 807–810. Chun Guo, Jinsong Zhang, and Xiaozhong Liu. 2013. Scientiﬁc metadata quality enhancement for schol- arly publications',\n",
       " 'Ischools .Sepp Hochreiter and Jrgen Schmidhuber. 1997. Long short-term memory. Neural Computation , 9(8):1735–1780. Yue Hu and Xiaojun Wan. 2014. Automatic gener- ation of related work sections in scientiﬁc papers: an optimization approach. In Proceedings of the ACL EMNLP Conference on Empirical Methods in Natural Language Processing, Doha, Qatar , pages 1624–1633. Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. 2013. Learning deep structured semantic models for web search using clickthrough data. In Proceedings of the 22nd ACM CIKM international Conference on Informa- tion & Knowledge Management, San Francisco, USA, pages 2333–2338. Scott Jensen, Xiaozhong Liu, Yingying Yu, and Stasa Milojevic. 2016',\n",
       " 'Generation of topic evolution trees from heterogeneous bibliographic networks. Jour- nal of Informetrics , 10(2):606–621. Yoon Kim. 2014. Convolutional neural networks for sentence classiﬁcation. Eprint Arxiv . Diederik Kingma and Jimmy Ba. 2014. Adam: a method for stochastic optimization. Computer Sci- ence. Chin Yew Lin and Eduard Hovy. 2003. Auto- matic evaluation of summaries using n-gram co- occurrence statistics. In Proceedings of the NAACL The Annual Conference of the North American Chapter of the Association for Computational Lin- guistics, Stroudsburg, USA , pages 71–78. H. P. Luhn. 1958. The automatic creation of literature abstracts . IBM Corp. William C. Mann and Sandra A. Thompson. 2009. Rhetorical structure theory: Toward a functional the- ory of text organization. Text & Talk , 8(3):243–281',\n",
       " 'Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efﬁcient estimation of word represen- tations in vector space. Computer Science . Ramesh Nallapati, Bing Xiang, and Bowen Zhou. 2016a. Sequence-to-sequence rnns for text summa- rization. In Proceedings of the International Confer- ence on Learning Representations, Workshop track, San Juan, Puerto Rico . Ramesh Nallapati, Feifei Zhai, and Bowen Zhou. 2016b. Summarunner: A recurrent neural network based sequence model for extractive summarization of documents. arXiv preprint arXiv:1611.04230v1 . Ramesh Nallapati, Bowen Zhou, Cicero Nogueira Dos Santos, Caglar Gulcehre, and Bing Xiang. 2016c. Abstractive text summarization using sequence- to-sequence rnns and beyond',\n",
       " 'arXiv preprint arXiv:1602.06023v5 .Ramesh M. Nallapati, Amr Ahmed, Eric P. Xing, and William W. Cohen. 2008. Joint latent topic models for text and citations. In Proceedings of the 14th ACM SIGKDD International Conference on Knowl- edge Discovery and Data Mining, Las Vegas, Usa , pages 542–550. Shashi Narayan, Nikos Papasarantopoulos, Shay B. Cohen, and Mirella Lapata. 2017. Neural extrac- tive summarization with side information. arXiv preprint arXiv:1704.04530 . Ani Nenkova and Lucy Vanderwende. 2005. The im- pact of frequency on summarization. Microsoft Re- search . L Page. 1998. The pagerank citation ranking : Bring- ing order to the web, online manuscript. Stanford Digital Libraries Working Paper , 9(1):1–14',\n",
       " 'Alexander M Rush, Sumit Chopra, and Jason Weston. 2015. A neural attention model for abstractive sen- tence summarization. In Proceedings of the ACL EMNLP Conference on Empirical Methods in Nat- ural Language Processing, Lisbon, Portugal , pages 379–389. Ananthram Swami, Ananthram Swami, and Anan- thram Swami. 2017. metapath2vec: Scalable rep- resentation learning for heterogeneous networks. InProceedings of the 23rd ACM SIGKDD Inter- national Conference on Knowledge Discovery and Data Mining, Halifax, Canada , pages 135–144. Jiwei Tan, Xiaojun Wan, Jianguo Xiao, Jiwei Tan, Xi- aojun Wan, and Jianguo Xiao. 2017. Abstractive document summarization with a graph-based atten- tional neural model',\n",
       " 'In Proceedings of the 55th ACL Annual Meeting of the Association for Computa- tional Linguistics, Vancouver, Canada , pages 1171– 1181. Scott White and Padhraic Smyth. 2003. Algorithms for estimating relative importance in networks. In Proceedings of the 9th ACM SIGKDD International Conference on Knowledge Discovery and Data Min- ing, Washington, USA , pages 266–275. Dwi H Widyantoro and Imaduddin Amin. 2014. Ci- tation sentence identiﬁcation and classiﬁcation for related work summarization. In Proceedings of the ICACSIS International Conference on Advanced Computer Science and Information Systems , pages 291–296. Yingying Yu, Xiaozhong Liu, and Zhuoren Jiang. 2015. Random walk and feedback on scholarly network. InProceedings of the 1st ACM GSB@SIGIR Inter- national Workshop on Graph Search and Beyond, Santiago, Chile , pages 33–37.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "directory = r\"D:\\Pycharm_Projects\\report-generate-webui\\web-backend\\uploads\\paper\\auto-repo\"\n",
    "texts, sources = load_and_process_files(directory,\n",
    "                                        chunk_size=200,\n",
    "                                        separator=None)\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c1da81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0680689 ,  0.00551877,  0.00143983, ...,  0.0187787 ,\n",
       "        -0.01534847,  0.02933168],\n",
       "       [-0.06267904, -0.00338958,  0.00220995, ...,  0.02435057,\n",
       "         0.02295191,  0.00729517],\n",
       "       [-0.0395328 ,  0.01240805, -0.01798805, ..., -0.01062775,\n",
       "        -0.03672544,  0.00798598],\n",
       "       ...,\n",
       "       [-0.04526855, -0.03402655, -0.01438121, ...,  0.02615087,\n",
       "         0.04906716,  0.00921457],\n",
       "       [-0.05698714, -0.03978408,  0.01568518, ...,  0.01993834,\n",
       "         0.00073283,  0.00862336],\n",
       "       [-0.04859588, -0.02439854, -0.00411001, ...,  0.02195255,\n",
       "         0.03852823, -0.01623105]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "KG_class = KG_Class(texts=texts,\n",
    "                      source=sources,\n",
    "                    main_topic=main_topic,\n",
    "                      embedding=True,\n",
    "                           args=args)\n",
    "\n",
    "KG_class.vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3900756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(to_keep): 433\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# step one: remove duplicates\n",
    "to_keep, to_delete, remains = KG_class.remove_same_text(use_nn=True, n_neighbors=25, thresh=1e-6, update=True)\n",
    "print('len(to_keep):',len(to_keep))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c9e891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Post Process: 10\n",
      "After Post Process: 9\n",
      "Number of keywords selected: 9\n",
      "Token used: 4035\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# step two: extract keywords with two methods\n",
    "core_list_1, all_tokens = KG_class.cluster(15,\n",
    "                                           clustering_method='NgJordanWeiss',\n",
    "                                           max_texts=15,\n",
    "                                           select_mtd='similarity',\n",
    "                                           prompt_language='English',\n",
    "                                           num_topics=10,\n",
    "                                           max_length=3,\n",
    "                                           post_process=True,\n",
    "                                           add_keywords=False,\n",
    "                                           verbose=False)\n",
    "print(\"Number of keywords selected:\", len(core_list_1))\n",
    "print(\"Token used:\", all_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "507e86f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neural networks',\n",
       " 'Automatic summarization',\n",
       " 'Literature abstracts',\n",
       " 'Natural language processing',\n",
       " 'Computational linguistics',\n",
       " 'Scientific paper summarization',\n",
       " 'Text generation',\n",
       " 'Related work',\n",
       " 'Citation analysis']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b03267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Post Process: 10\n",
      "After Post Process: 10\n",
      "Number of keywords selected: 10\n",
      "Token used: 3751\n",
      "Number of keywords: 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Neural networks',\n",
       " 'Automatic summarization',\n",
       " 'Literature abstracts',\n",
       " 'Natural language processing',\n",
       " 'Computational linguistics',\n",
       " 'Scientific paper summarization',\n",
       " 'Text generation',\n",
       " 'Related work',\n",
       " 'Citation analysis']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "core_list_2, all_tokens = KG_class.cluster(15,\n",
    "                                           clustering_method='k_means',\n",
    "                                           max_texts=15,\n",
    "                                           select_mtd='similarity',\n",
    "                                           prompt_language='English',\n",
    "                                           num_topics=10,\n",
    "                                           max_length=3,\n",
    "                                           post_process=True,\n",
    "                                           add_keywords=True)\n",
    "print(\"Number of keywords selected:\", len(core_list_2))\n",
    "print(\"Token used:\", all_tokens)\n",
    "\n",
    "print(\"Number of keywords:\", len(KG_class.keywords))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62b7c821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RAG principles',\n",
       " 'Literature review generation',\n",
       " 'Related work section',\n",
       " 'Automatic generation',\n",
       " 'Research papers',\n",
       " 'User-provided abstract',\n",
       " 'Citation description',\n",
       " 'Sentence-based planning',\n",
       " 'Retrieval Augmented Generation',\n",
       " 'LLM-based toolkit']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4ea156f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keywords: 18\n"
     ]
    }
   ],
   "source": [
    "_ = KG_class.sub_entry_filter()\n",
    "print(\"Number of keywords:\", len(KG_class.keywords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bfe53b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token used: 1338\n",
      "Number of keywords: 17\n"
     ]
    }
   ],
   "source": [
    "\n",
    "_, all_tokens = KG_class.final_keywords_filter()\n",
    "print(\"Token used:\", all_tokens)\n",
    "print(\"Number of keywords:\", len(KG_class.keywords))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9c531cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "KG_class.make_graph(30)\n",
    "pred_mat, U_mat, A = KG_class.coretexts_seg_individual(k=30, trust_num=5, negative_multiplier=7, seg_mtd='laplace',\n",
    "                                                       return_mat=True, connect_threshold=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "963ed1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "KG_class.get_dist_mat()\n",
    "print(KG_class.check_completion())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f37701e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 直方图显示不同度数的节点数量  可视化图的度分布，以便更好地理解图的结构和特征\n",
    "deg_mat = np.sum(np.array(A.todense()) > 0, axis=0)\n",
    "plt.hist(deg_mat)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2468a3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully save to KG_data\\realted_work_ref_KG.npy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not os.path.exists('KG_data'):\n",
    "    os.mkdir('KG_data')\n",
    "KG_class.save_data(os.path.join('KG_data', 'realted_work_ref_KG.npy'), include_texts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3705a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Chat_KG_class = KG_Class(texts=None,\n",
    "                      source=None,\n",
    "                    main_topic=None,\n",
    "                      embedding=False,\n",
    "                           args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bde056a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load from KG_data\\realted_work_ref_KG.npy\n"
     ]
    }
   ],
   "source": [
    "Chat_KG_class.load_data(os.path.join('KG_data', 'realted_work_ref_KG.npy'), include_texts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1227f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "Please write a srvey about automatic related work generation.\n",
    "\"\"\"\n",
    "record = Chat_KG_class.KG_prompt(query,\n",
    "                                 search_nums=(15, 7, 3, 4, 2),\n",
    "                                 search_mtd='pair_dist',\n",
    "                                 use_u=False)\n",
    "response, keywords_info, ref_info, all_tokens = Chat_KG_class.completion_from_record(\n",
    "                               record,\n",
    "                               output_tokens=1024,\n",
    "                               prompt_language='English',\n",
    "                               show_prompt=False,\n",
    "                               prompt_keywords=False,\n",
    "                               include_source=False,\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d6cebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8496\n",
      "Automatic related work generation is a challenging task in the field of academic paper writing. The goal of this process is to automatically generate a related work section for a target paper by utilizing multiple reference papers. This generated related work section can serve as a draft for authors to complete their final related work section, reducing the time and effort required in the writing process.\n",
      "\n",
      "Various approaches have been proposed to tackle this task, including the use of neural networks, sequence-to-sequence models, and optimization frameworks. These methods typically involve extracting information from the target paper's abstract and introduction sections, as well as from the reference papers' abstracts, introductions, related work, and conclusions. By grouping sentences into topic-biased clusters and learning the importance of each sentence, these systems aim to generate a related work section that follows a structured format and highlights the differences and advantages of the author's work compared to previous research.\n",
      "\n",
      "Experimental results have shown that these automatic methods outperform traditional summarization techniques, such as rule-based strategies and classical summarization baselines. The quality of the generated related work sections is evaluated using metrics like ROUGE scores and user ratings, indicating that the automated systems can produce sections that are more relevant, readable, and useful for authors.\n",
      "\n",
      "Overall, automatic related work generation systems offer a promising solution to the time-consuming task of writing related work sections in academic papers. By leveraging advanced technologies and optimization approaches, these systems can assist authors in summarizing and contextualizing previous research effectively.\n"
     ]
    }
   ],
   "source": [
    "print(all_tokens)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7ebcf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Chat_KG_class.draw_graph_from_record(record,\n",
    "                                     node_colors=([0, 1, 1], [0, 1, 0.5], [1, 0.7, 0.75]),\n",
    "                                     node_shape='o',\n",
    "                                     edge_color='black',\n",
    "                                     edge_widths=(2, 0.5),\n",
    "                                     node_sizes=(500, 150, 50),\n",
    "                                     font_color='black',\n",
    "                                     font_size=6,\n",
    "                                     show_text=False,\n",
    "                                     save_fig=True,\n",
    "                                     save_path='KG_outputs/Subgraph_vis.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f88052ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7876\n",
      "Automatic related work generation is a challenging task that involves automatically generating a related work section for a target academic paper based on its reference papers. The goal is to create a related work section that describes the related works and establishes the relationship between the target paper and the reference papers. This process typically involves utilizing various sections of the target paper and its reference papers, such as abstracts, introductions, related work, and conclusions, to generate a coherent and informative related work section. Several models and frameworks, such as ARWG (Automatic Related Work Generation), have been proposed to address this task, incorporating techniques like probabilistic latent semantic indexing, support vector regression, and global optimization to improve the quality of the generated related work sections. These automated methods aim to reduce the author's time and effort in completing the final related work section by providing a structured and comprehensive overview of the existing literature related to the target paper.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "Please tell me what is automatic related work generation.\n",
    "\"\"\"\n",
    "record = Chat_KG_class.KG_prompt(query,\n",
    "                                 search_nums=(15, 7, 3, 4, 2),\n",
    "                                 search_mtd='pair_dist',\n",
    "                                 use_u=False)\n",
    "response, keywords_info, ref_info, all_tokens = Chat_KG_class.completion_from_record(\n",
    "                               record,\n",
    "                               output_tokens=1024,\n",
    "                               prompt_language='English',\n",
    "                               show_prompt=False,\n",
    "                               prompt_keywords=False,\n",
    "                               include_source=False,\n",
    "                               )\n",
    "print(all_tokens)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0defc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACaD0lEQVR4nOzdd3hUZdrH8e/MpPeE9AIBQkjoJQGClABSFZAiIJbFti6rrru2VRfrqy4qq6uiWAFxUUEERBSkJohAIKGFEkiAQHrvfcr7x5BjAgkQMun357q4mHLOmWcGkvzylPtRGQwGA0IIIYQQos1Tt3QDhBBCCCGEaUiwE0IIIYRoJyTYCSGEEEK0ExLshBBCCCHaCQl2QgghhBDthAQ7IYQQQoh2QoKdEEIIIUQ7IcFOCCGEEKKdMLuRg/R6Pampqdjb26NSqZq6TUIIIYQQ4jKDwUBRURHe3t6o1dfuk7uhYJeamoqfn59JGieEEEIIIRouKSkJX1/fax5zQ8HO3t5euaCDg0PjWyaEEEIIIW5IYWEhfn5+Sh67lhsKdtXDrw4ODhLshBBCCCFawI1Mh5PFE0IIIYQQ7YQEOyGEEEKIdkKCnRBCCCFEOyHBTgghhBCinZBgJ4QQQgjRTkiwE0IIIYRoJyTYCSGEEEK0ExLshBBCCCHaCQl2QgghhBDthAQ7IYQQQoh2QoKdEEIIIUQ7IcFOCCGEEKKdkGAnhBBCCNFOSLATQgghhGgnJNgJIYQQQrQTEuyEEEIIIdoJCXZCCCGEEO2EBDshhBBCiHZCgp0QQgghRDshwU4IIYQQop2QYCeEEEII0U5IsBNCCCGEaCck2AkhhBBCtBMS7IQQQggh2gkJdkIIIYQQ7YQEOyGEEEKIdsKspRsghBBCiNahmEpyKAXABWvssWzhFomGkmAnhBBCdGCV6NhIHB8SxV6Saj03DB8eZyizCMZSIkObIP9KQgghRAe1jlMs5GeyKUWD6qrnD5LK3aznMaz4kMncTb8WaKVoCJljJ4QQQnRAH3GQO/me7MtDrzoMVx2jv/xYHuXcwwbe4fdmbaNoOAl2QgghRAfzPSd5jC0NPu9ZdrCKY03QImEqEuyEEEKIDqQCLY+w+abPf5RfKKHShC0SpiTBTgghhDCxoqIipk6dSnh4OGFhYWzZ0vDesabyA6fJo7z2gxEX4Gz2DZ1fTCXfcqIJWiZMQYKdEEIIYWKrVq1i0qRJREREsG/fPsLCwlq6SYoPOYj6yoUSEYlwNueGzlcDHxCFoY45eaLlSbATQgghTMza2poDBw6QkZGBSqXCycmJlStXMnLkSIYPH86uXbsA2LFjB4MGDWLmzJmEhYWRmJjIypUrWbp0KQCbN2/mlVdeAajz/PDwcJ588klGjRrFY489BkBZWRl33XUXo0ePZty4cQBER0czZswYwkbewoEla5RFEcYTqmDlUXh+J9y3HnR6uOcHGL0CblsNeWW13ps+t5TY8Le4Zcxopk+fDsD58+eZOHEi4eHh/OMf/wCgoKCASZMmMWnSJObNm6e8j5CQEOVa1bfrOn/lypXMmjWLqVOnEhoaSlpaGgArVqxg2LBhhIeHs337dsrLy7nnnnsYO3Ys06ZNo7CwsNH/fm2ZBDshhBDCxO6991569uzJxIkTCQsLIyoqiu+++449e/awfft2XnvtNQAWLVrEjh07+Pbbb0lNTa33ejk5OXWeD3DHHXewZ88eYmJiKCgo4PPPPyckJITIyEi2b98OwHPPPcf69etZ9dsmiLwIGcV/XNzaHBYMgH+Pg1UzYcNp8HWAyPthXh/4MKp2Y46kwxAflu1ey4YNG5Trf/zxx0RERFBeXk50dDSff/45M2fOZOvWrfj7+1/z86rrfABHR0d++uknHnjgAb7//nuysrL47LPP2LNnDxEREYwbN44vvviCsWPHsmvXLu6++24+++yzG/xXap+kjp0QQghhYubm5ixatIhFixaxfft2nn/+eeLj4xkzZgwAWVlZAOh0OlxcXADo189YI06l+mOY1GAw9qydO3eOkydPXnU+wMCBAwHw8fEhPz+f06dP8+CDDwKgVhv7b44fP86MGTMopQryCiCpAJ7ZBpcK4F+jajc+IRdCfYy3Q71h2znYdR5eiwQfB/jqDth7iefv/itjBw7n6aefJi4uTnnNoqIiJk6cSEJCAg8//LDxMqGhxMbGXvU5Vb+/us6v+d78/PyIiYnh/PnzDB48GAsLC+X9nTp1ikOHDrFq1SqqqqoYOXLkjfwTtVsS7IQQQggTu3jxIl5eXlhYWODu7o5KpaJfv35s3rwZlUpFVVUVABqNhry8PGxsbJTg4+zszOnTpwE4dsxYWqRbt251ng9XB8Hg4GD27NlDSEgIer0etVpN//79WbduHZWOZrjr3ga1ytg7V+1gCuguD88GuBjvz+oFh1KhhwuM7Wb8A8ah25fDWcYTPDxhDnPmzKFnz54sWbKELl26YDAY0Ol0JCQkcOTIEQYPHkx0dDSWlsbtycrLy9HpdKSkpJCXlwdQ5/n/+9//rnpv3bt35/Dhw1RVVWFubo5erycoKIiwsDDuvfdegFqfTUckwU4IIYQwsdjYWObOnYuVlRUGg4GPPvqII0eOMHr0aDQaDX379uWDDz7gtddeY9y4cfj7+9O5c2cAbr31VpYsWcKUKVPw8fHBx8cHV1dX5s2bd9X5dXn44YdZsGABo0ePxszMjJ07d7J48WJmzpyJXq/HzjKTkg0zMFib/3HS2K7wz+2w6wL8ZwKsPw2jloOdBfxvZu0XOJSC1b/2cJ96F76+vvj6+vLWW2/xl7/8hfLycjQaDcuXL+ehhx5izpw5rF27Fi8vL7p27QrA3XffTVhYGKNGjcLJyQmgzvPr4urqykMPPcQtt9yCra0tL7zwAn/+85/585//zIoVKwB46qmnuO222xrxr9e2qQzV/aDXUFhYiKOjIwUFBTg4ODRHu4QQQogOZfbs2SxZsuS689Ea63Ni+HMj6tipgP8yib8x9IbP2bx5M9HR0coCCtEwDclhsnhCCCGE6EDm0xc7LG76fEvMuI/+JmyRMCXpsRNCCCE6mE+J5i/8fFPn/ocJPEnrqcvXEUiPnRBCCCHq9QghvMio6x94hX8wjH8wrAlaJExFgp0QQgjRAb2iH80Dhz0x0wIGUNUxfqe6/McCDUsYz3+YgOrKXStEqyKrYoUQQogO6PTp0wyNVtH3uAcnBmmI6FfGOfJqHdMZRx5nCPczEBesW6iloiEk2AkhhBAdTEVFhbK7g02lmjc9p+OGGwnkkksZBsAFawJwuXpfWdGqSbATQgghOpiYmBgqKioA6NGjB+7u7sbbdGrJZgkTkDl2QgghRAeSn5/PqVOnADAzM2PIkCEt3CJhShLshBBCiA5k//796PV6AAYMGICtrW0Lt0iYkgQ7IYQQooNISkoiKSkJADs7O/r169fCLRKmJsFOCCGE6AD0ej379+9X7g8ZMgQzM5lq395IsBNCCCE6gFOnTpGfnw+Ah4cHAQEBLdsg0SQk2AkhhBDtXHl5OTExMcr94cOHt2BrRFOSYCeEEEK0c4cPH1bKmwQGBuLm5tbCLRJNRYKdEEII0Y7l5eVx8uRJwFjeJDQ0tIVbJJqSBDshhBCiHTtw4AAGg3EjWClv0v5JsBNCCCHaqUuXLkl5kw5Ggp0QQgjRDun1eg4cOKDcHzp0qJQ36QAk2AkhhBDtUM3yJp6ennTv3r1lGySahQQ7IYQQop0pLy8nOjpauR8WFtaCrRHNSYKdEKLN+/333xkzZgzh4eGMHj2aH3744aauY8DAAZJ5kl+5m/XM4Xse4SdWcYxytLWOTUxMZNu2bcr9Rx55pFHvQQhTiomJobKyEpDyJh2NDLYLIdq0nJwc/vrXv7J161a8vLyoqqqq1VNxI7ToWclRPiCKWDIxQ40BAwZApTfwmfowf2MLf2Ywf2cY3tgrwW7ChAkAfPrpp03w7oRouLy8PE6dOgUYy5sMGTKkhVskmpP02Akh2rRffvmFGTNm4OXlBYC5uTlhYWFER0czZswYRo4cyZIlSwB45ZVXuPfee5kyZQqjR4+mrKyMYirp/eY8Hh49k9hRiyE2Ay16dIOWoX/iF3T3/gCxGRSM/oR3wh6g22MTiSGVZcuWsWbNGsLDw8nNzSUkJISqqipuueUWpW333nsvcXFxnD9/nokTJxIeHs4//vGPFvmcRMexf/9+pbzJwIEDsbGxaeEWieYkwU4I0aalpqYqoW7Xrl2Eh4czbdo0nnvuOdavX89vv/1GZGQkGRkZAPTo0YNffvmFYcOG8cv2Xwk/8TbxZ85C5P3w3WxYtMt44bxyeHwIrJ4FAS4QsQD2P0RFUi4j45cwceFc5s6dS0REBC4uLoAxVAYHB3Ps2DHKy8u5ePEiQUFBPPfcc3z88cdERERcNfdJCFO6dOkSycnJgLG8Sd++fVu4RaK5yVCsEKJN8/b2Jj4+HoCxY8cyduxYQkJCuHTpEjNmzACMQ1PVtbwGDhwIgJ+fH5/n7eXwqUsY9iVB+ArjBTWXf991toKATsbbF/LgqW1QWgXn86hIzedZdnAvVle1Z968eaxZs4bQ0FCmTJkCQFxcHA8++CAARUVFTJw4kZCQkCb5PETHpdfr2b9/v3J/2LBhUt6kA5J/cSFEmzZlyhTCw8P5y1/+gre3N1qtcZFD//79WbduHY6Ojuh0OtRqNZs3b0alUgFQjpZdhgsYgtxhdBf4YrrxglU6499q1R8vsiwangqDW7vDtG/QG/TkmFcQpyu6qj1jxozhpZde4sKFC/z73/8GoGfPnixZsoQuXbpgMBjQ6XRN94GIDuvkyZMUFBQAxvIm3bp1a+EWiZYgwU4I0aZ16tSJTz75hPnz56NSqVCr1fz9738nODiYmTNnotfrsbS0ZMOGDbXOO0gKVeignyf06ASjVxjD3Phu8MKo2i8yNRCe2ApBrqA3zl1S9fXg9+fXceedd/L5558rh2o0GgYNGsTRo0fx9/cH4K233uIvf/kL5eXlaDQali9fTufOnZv0cxEdS3l5OTExMcr94cOHt2BrREtSGapnWF5DYWEhjo6OFBQU4ODg0BztEkKIJtWHjzlFFtf9BngdJ/krvZBSEqJl7d27V1kJ27NnT0aPHt3CLRKm1JAcJosnhBAdUgK5jQ51APHkmOAqQty83NxcTp8+DRgX8ISGhrZwi0RLkmAnhOhwdOipwDTz3AqpMMl1hLhZUt5E1CTBTgjRoZSVlZF47gLmetX1D74B9lhe9VhiYiKzZ882yfWFuJaLFy+SkpICgL29vZQ3EbJ4QgjRvmm1WtLS0khJSSElJYWcHOPQaac71aQ76aC+fKfXg/r6v/sG4GLC1gpx4+oqb6LRaFqwRaI1kGAnhGhX0tLSmD17NqWlpdjY2HDbbbfxxRdf4OjoSE5ODrNnzyYoKAjd2JVwSyc4ng4DveD9ybDyCGxNgJIqWBgCcdnw/SnQqOCDyTDIG57cCjFpUKal92cP0GeAOwcPHuTJJ5/EzMyM2267jTvvvJO0tDTmzp3LqVOneP/99xk7dmxLfzSinTlx4gSFhYUAeHl50bVr1xZukWgNJNgJIdq8goICkpOTSUlJ4dKlS9xzzz1oNBrWrFnD6dOnKSws5KmnnqKiooJPP/2UefPm4W/tSv7UIKqWToF538PhVOPFzDXw052QXgSL98LvD8ClAnj4J9h+H7w+Fmws4EgaDu9Ew2r4xz/+wXfffYefnx96vZ5Lly6RnZ1NZGQk8fHx/Otf/5JgJ0yqvLycw4cPK/fDwsJasDWiNZFgJ0QHNnz4cCZNmsRLL71U5/P5+fls27aNOXPm1Pl8FiWs4hhnyKGISmwxJwAX7qM/3tjX+7oRERF4e3sTGBjI0aNH2b9/PwsXLrzhdpeVlSlDqykpKRQXFyvPFRQUsHr1akpLSykoKMDZ2ZmePXsyefJkvL29+fbbbxkyZAg2Flb8KWQyyzmDPtQH4nONFwj1Nv6dmA/9PY3Dsf7OkF9ufPydfbDjPOZoMDcz1qKrrKzEz88PAPXl4ds+ffpgZmaGn58feXl5N/zehLgRhw4dorKyEoCgoCBcXV1buEWitZDFE0J0UElJSfj6+hIREVHvMfn5+axdu/aqx2NI5R7W4827PMsOVnCUtZzkK46xiF348R6zWcteLtV53YiICM6ePQvAgAEDrhvqqqqqSEpK4sCBA6xbt46vv/6aXbt2cebMmVqhDuDw4cOMHTuWTZs2cccdd3D77beTlpaGr68vpaWltbZYmnHEiaH4oIpONe4HC3/sOOHvBEfTjXPtEvPAyQpySmH7eax/+zMr/rsM1eV6KZaWlsoEdr1eD6DscAFwA+VChbhhubm5xMXFAVLeRFxNeuyE6KDWrVvH3Xffza+//kpcXBzfffcdISEh3H777SxduhQ7OztOnz5NZGQk4eHhfPzxxxw/fpwX3nudC6oC1K+OQT+xO4SvQD/IC/YloZ8UADllsD+JDff054e/n2be1zrSvtxDYWEh//jHP5g9ezYrV67khx9+YO3atTzwwANs3ryZJUuW8Msvv/Daa69hZWXF7NmzGT58OCkpKWRkZCiB6UoajQYvLy98fHzw8fEhNDSU++67j3PnzmFtbQ2Ar68vd911FxcuXODtt99Wzt25ZRu8FoV3fw9SB3tjiM3448Ke9jC9Jwz/0hj2PpyCxtkalYstQeGbiR32x3Zi7777LnPmzMHc3FyZYydEU9m3b1+t8ibV/8+FANl5QogOa/LkyWzcuJGDBw8SERGBTqe7KtiFh4fz9NNPs27dOnQ6Hf6DgkmOmgOVOhj7FUQ/AuEr4I1xEOYLnd+DzfOhjzsM/QJiHoHSSt62mcJjZYO45ZZbOHz4MK+88oryWhEREWzevJkXXniBsLAwFi9eTEFBAeXl5cqw5pXc3Nzw8fHB19cXDw+Pa64ETExMVN5DTeHh4WzevBk7Ozuq0PEZMXzAQc6Sg1oPBhUYAI1KhQ4DtpjzIAN5kjC64GTCfwkhblxiYiLbtm0DwMHBgTvvvFNWwnYADclh0mMnRAeUnJzMiRMnmD59OgaDgYKCAiZPnqw8X9fvezuzTpDcWQVW5sY/5hrQXi7y28/DOBfN0844L02lAvPLoezXczz7/t38z+DBhYQE5XoVFRUkJCRw9OhRTp8+zfLly7G0tCQrKwugVqhzcHDA19cXHx8fvL29sbS8unZcY5ij4VGGsKC0Ny/vXE50t3KqXCzo5OWOM9aMwI/59MUWC5O+rhANodPpOHDggHJ/6NChEurEVSTYCdEBrVu3jvfee08povvXv/4VJycnkpOTATh27BgjRozA3Nwcnc4Y3r5yi4eLBVBeZeyxq9SB2eUfKjVrwamuKAz3+h7Uex7AzeBPWrcX2L9/P2fOnCEzM5OcnBySkpKoqqrCzs6OvLw8ysvLcXJywsvLCz8/P3x8fLC3r38hxvX4+/tf1VsH1Dm3MCszi8A0SwLTLOnfvz9DvYbe9OsKYWo1y5t4e3tLeRNRJwl2QnRAP/zwAxs3blTujxkzhlOnTvHTTz/xyy+/KEHKy8uLsrIyps6ewZZ/d4HnboFRK4xzzl6/wfIdM4PRj/ySnQO9cDNXExsbS+fOnVm/fj1nzpxhwIABqFQqOnfuzD//+U9WrFiBg4MDDzzwAOPHj2+Cd1+/6t5CMA73CtFalJWVSXkTcUNkjp0Q4rreZT/PsB09N7+6U62HicdsueOQAyqVSpkn5+Pjc915cs3ll19+UXot58+fj52dXQu3SAijPXv2KCthg4KCGDVqVAu3SDQnmWMnhDCpM2SjRtWoYGdQQamfDROcJ+Dl5WXyeXKmUN1jZ2VlJaFOtBo5OTlS3kTcMAl2QojrKqKyUaEOjMHOzNUOf1d/0zTKxAoLC6moqADA3d29hVsjxB9q7gc7aNAgKW8irkkKFAshrssOC9Sorn9gfY6mwcFkHLEiPT2dl19+2XSNMxGZXydao8TERFJTjdvdOTg40KdPnxZukWjtpMdOCHFd3XG+sR47vd5Y9uRKR9NRF1fRfYgznp6evPrqq6ZvZCNJsBOtzZXlTYYNG9Yq5qKK1k2CnRAdjFarZd68eeTn59OzZ09KSkqYN28eb7zxBjqdjscff5y77rqLBQsWYGVlxblz59DYWsKGUMAAf9sCJzJBo4KVd4CvI/RaCkN9wdESbguE1/dAaRXMCobnRsKyaPS5Zfy+6U0SP+uhFAzevXs3zz//PGAsuXLffffVel1bW1s2bNhQa3uupiLBTrQ2V5Y38ff3b9kGiTZBhmKF6GA2btxIYGAgO3bsoH///hgMBv7v//6PnTt38ttvv7F06VKldt3w4cPZvn07jpa2jIu1Rf1zAjhbwe4Fxt0mFu81XjS5EN6dCP+dDLf4QeT9EPUQ/HAayqpQLQwl4Ikp/L5td622PP/882zevJnffvuNDz74gLKyslqva2lpSWxsbJN/JgaDQQl2dnZ2ModJtLia5U1UKhXDhw9v4RY1n7KyMsLDwwkPD8fe3l65nZubW+85jzzyiPFcqkihkCQKKKESoNVO/2gq0mMnRAeTkJDA4MGDARg8eDAbN27k7NmzTJgwAYD8/Hwl5AwcOBAAPz8/RuV1YfupX2FDHOy5aNxvy+/ysvsAF3C+HIZi0uDVCKjSQ2I+ZJZgwMA4ri6mqtPpcHV1NV4iIECZS1TzdfPy8prgU6gtPz8frVYLSG+daB0OHTpEVVUVYCxv4uLi0sItaj7W1tZKAfGQkJBaxcT1ev1VWw3q0HPbp08ynq/Zwflaz4Xizd88h/L8qy82dbNbDQl2QnQwAQEBHDlyhFmzZnHkyBFcXV0JCgpi27ZtWFhYUFVVhbm5OUCtIdDeBjceCBrP8jk6eHG08cGqy1uKqWsMlb79O3xyO3RzhkGfgsHAdPNeBOs6XdUWtVpNdnY2jo6OxMfH4+3tfdXr3kCpzUaTYVjRmmRnZyvlTSwsLAgJCWnhFrWsV155hcTERDIzM3nzzTd5++23SUlJQafT8fA3b/BC5xhSQ5agif4LvLIbzuVBTimUVBG99V7uzTjJA0/v5NN1q/gq/B8MGjSI6Oho+vXrx9KlS8nPz2fOnDmo1Wo8PT3x9/fnlVdeaem3fdNkKFaIDuaOO+4gLi6OcePGERUVhaWlJYsWLWL8+PGMGTOGu+++u95zv5j6DCNzXGHMShi7ElYdu/qgWcEwYw3csx7sLXmUIfwn7EG+//575s+fX+vQN998k9tuu42RI0fy2GOPtdgQaGZmpnJbgp1oaVLe5Gp+fn788ssvDBgwgC+++ILIyEgGPTWTBZ++SBpFAOiqF3j1cIFf7oFhvhi2G/enrkLHA2ziIvnccccd7Nmzh5iYGAoKCvjiiy+YPXs2W7duVX65bMukx06IDsbMzIxvv/0Wc3NzPvvsM/Ly8pg4cSITJ06sddzKlSuV20uWLFFu7/nvWnbozvFU6jqO+5aj1gOH/oIeAyoDqO4biH7BQIJSLXnLYzrTNMEA7N27V7lG9d6t1eHyRl63KUmPnWgtLly4QFpaGiDlTWqqLsqs0+l49tlniTgexcmyVOjjfvV6/YFexr/9HCCvvNZTieRzdCCMAnx8fMjPzychIYGHH34YME5PaY55vU1Jgp0QHdD06dMpLi7G0tKSNWvWNPj8bhdVPLrDmWw7LaeHW1Phb0cB5dirLLFILiFoXxmeBWb0GmsOAU3wBkxIr9eTk5MDgKOjIxYWFi3cItFRXVneJCws7Kr5ZB1V9edw9OhR8vLzyNtzF/wQBT+dufrgmovo65jK8YxqO/cx5PLTBmV6yuDBgzly5AhmZm07GrXt1gshbsovv/zSqPPPnDF+M3UtNuMti4l488fwRbp5OpsKNgFw9uxZAgJad7LLyclBr9cD0lsnWlZsbCxFRcZhRR8fH7p06dLCLWp9goKCOHrxDKnjD0CQ601doxIdq/hjGslDDz3EnXfeyffff4+rqyu9evUyVXNbhAQ7IUSDlJSUkJycDBhLg3h5edV63tPTEwcHBwoLC0lOTqakpARbW9uWaOoNqTkMK1uJiZZSWlrKkSNHAOPiobCwsBZuUesQHR1d676trS0+vz3BGS78MacOINpY7oRXxvzx2GND/7i9bq7x74j7UQEfEEX8uu9RoUKv17N161Y0Gg0vvPBCq/9l9Hqkj1cI0SDx8fHKStXAwMA6iwcHBgbWOr41k/l1ojWoWd4kODi4Q5U3aYhytOzgfO1Q10AG4Bx5nMU4BaO6bt6IESOIi4tjxowZJmpty5AeOyFEg1QPw0LtAFdTjx49lN+0z549y4ABA5qjaTelOtipVCo6dbq6JIsQTS07O1v5upLyJteWS1kjIl1t2ZTSE2Mv4G+//Waiq7Y86bETQtywjIwMCgoKAPDy8sLBwaHO4+zt7ZUh2vz8/FrlRFoTrVarFEB2cXFp85OmRdu0b98+5fbgwYOxsrJqwda0bje0Z3ULXKs1kWAnhLhhNXvrevbsec1ja/bmnT17tsna1BjZ2dnKsLIMw4qWcP78edLT0wHjquzevXu3cItalxMnTrBgwQJKSkqIi4vj6K4/avyx8ghUam/62i4Y6wOuXLmSysrKxja11ZBgJ4S4IVqtlnPnzgFgbm5Ot27drnl8t27dlB6wc+fOKfvPtiYyv060JK1WK+VN6qHX60lNTSU2NpbExERWr17Nnj17SE24SNcMc1R6YOVRqLy57yte2NET46ra9hbsZNxBCHFDLly4oEzurhna6mNubk7Xrl2Jj4+noqKCixcvXjcMNjcJdqIlxcbGUlxcDICvry+dO3du4Ra1rOLiYpKSkkhMTOSll16iuLiYTp06odfrWbt2LZcuXaKqqorBmnlc6JUFR9Nh8mqYEQR9PeD1PVBaZdz95rmR8GMcvLEHbC1gTm9YGGrs5fvyCGY6e/a8PhBra2uOHj3K5MmTmTFjBjY2Nixfvhw7Ozsef/zxNrmQQoKdEOKGNGQYtlpgYKCyKvbs2bOtLthVz/3TaDSyClE0KylvYizInJ6eTlJSEklJScp815iYGFxdXXn44YeJjIzkwoULPPTQQwQEBFBQUMDny7/A+cEB5A3whM3zwc4SSish8n7Q62HoF/DEMFh3ClbeAb3cjY/nlMJ3J9DseZCI0kd44La5REREMGDAADZv3oydnR1jx45lx44dODg4KPUt2xoJdkKI6youLiY1NRUwbnPk6el5Q+d5e3tjZ2en/CZeVlbWava9rKiooLCwEIBOnTrJEJhoVgcPHkSrNc4P69WrF87Ozi3couZRVFSkBLmUlBTlM6gpKyuLgIAAAgICcHd354cffuDMmTN89NFHgHFbxP8yiT+x7I+TYtLg1Qio0kNiPmSWwIujYMk+KNPCo6GgVsHJLHzHrOcBdtXqsa+2ePFinnjiCQwGA88///wN/xLbmkiwE0JcV83FDw35RqdSqejRowdHjhzBYDAQHx9Pv379mqKJDSbDsKKlZGVlKV9TFhYWDB48uIVb1HR0Oh1paWlKmMvPz6/zOJVKhbu7O35+fpiZmXHu3DnGjh3Lp59+Sn5+Ptu3b2fv3r3ExMTw1FNPcR/9ec3cjXO6yytb3/4dPrkdujnDoE+NW4n5OcJn0yC1EO5ZD2vvxLdfD85vPohapVamlpibmytzgPv27cuKFSvYt28fb731FsuXL2+Oj8mkJNgJIa7JYDDUGobt0aNHg86vDnZgDIgS7ERHt3//Hys7Q0JC2l15k8LCQiXIpaam1tkrB2BtbY2fnx9+fn74+Pgon0O/fv2YN28e48aNIzAwEGdnZ1QqFeHh4QwbNkw5/4lp9/HJnG+In+VB1axgmLEG+rqDvaXxgFcjYH8yVOpQPz6Ml1yn0HVeH8JHh6PRaOjbty8ffPAB06ZNY86cOcyaNYt9+/aRmJhIRUUFb7zxRlN/VE1CZTDUsUPuFQoLC3F0dKSgoKDeulVCiPYpNTWVzZs3A8YJ3lOmTGnwNX788UcyMjIAmDlzJq6uN7fHoylt27aNxMREAObMmYOTk1OLtkd0DOfOnWPnzp0AODk5MXv27DY/DUCr1ZKamkpycjKXLl1SpjhcSaVS4eHhoYS5Tp061blzTUMVUM4qjvEBB0kgt9ZzXtjxGEN4kIF4YNfo12opDclh0mMnhLimmsOw9e00cT2BgYFKsDt79myrCHbVPXbm5uY4Ojq2cGtER6DVaomKilLuDxs2rM2Guvz8fKVXLi0trd5yRjY2NkqQ8/X1xcLCwuRtccSKxxnKYwwhnlxyKEWHAResCaQTZh2sspsEOyFEvaqqqjh//jxgnAvk7+9/U9fp3r07+/btQ6fTkZCQ0OI/0EpLSykpKQGMw7Cm6DUQ4nqOHz/eZsubVFVVkZqaqoS5oqKiOo9Tq9VX9co1FxUqAukEdOytASXYCSHqdf78eWV+TPfu3W96yy0LCwu6dOnC+fPnKS8vJykpiS5dupiyqQ0i8+tEcyspKeHo0aNA2ylvkpeXV6tXrr7yH7a2tvj5+dG5c2e8vb2bpFdO3DgJdkKIet1M7br69OzZU+n9O3PmjAQ70aEcOnSo1Zc3qaysrNUrV927eCW1Wo2npyedO3fGz8+vVb6XjkyCnRCiToWFhcoelk5OTri7uzfqej4+PtjY2FBaWsqlS5coLy9vsdWAEuxEc8rMzFTmqlpaWraq8ia5ublKkEtPT6+3V87Ozk4Jct7e3pibmzdzS8WNkmAnhKiTKXvrwPhbfkBAAMePH0ev13Pu3LkW2/C8OthZWVlhb2/fIm0QHUfN8iaDBw9u0fImlZWVJCcnk5ycTFJSkjLX9EoajQYvLy9lrpysGm87JNgJIa5iMBiUHobqIsOmEBgYyPHjxwHj6tiWCHZFRUWUl5cD0lsnml5CQoKyItzJyYlevXo1exuys7OVXrmMjAzqq3Lm4OCgBDlvb++bnlMrWpb8qwkhrpKSkqL8Ju/n54eNjY1Jruvi4oKrqyvZ2dlkZWWRl5fX7PNzZBhWNBetVsvBgweV+2FhYc2yGryiokLpkUtOTqa0tLTO4zQaDd7e3kqYk7I/7YMEOyHEVUxRu64+gYGBZGdnK68zdOhQk17/ejIzM5XbEuxEU6pZ3qQ6PDUFg8FQq1cuMzOz3l45R0dHZQWrp6en9Mq1Q/IvKoSopbKykgsXLgDGid6mXr0aEBDAgQMH0Ov1xMfHExoa2qw17aTHTlQrKipi/vz5FBUVUVFRwUsvvcTkyZNv6loGjEFKhbEmYlOXNykvL1d65ZKSkpTpBVcyMzPD29ubzp074+vrK7tHdQAS7IQQtZw7d06pIt+jRw80Go1Jr29lZUXnzp1JTEyktLSUlJSUJuvJuFJ1zwYYa2+ZaohZtE2rVq1i0qRJPProoxgMBgoKCm74XAMGDpHKRxxiM2cpwBisHLFiGj0ZelqF+nJ5k969ezd68YHBYCArK6tWr1x9nJyclBWsnp6eJv8aFq2bBDshRC01V8Oaehi25nWr92k9e/ZsswW7/Px8qqqqAOmtE8ZN6Hfv3s3s2bPx8PDAycmJlStX8uWXX6LT6Xj99dcZO3YsO3bs4Nlnn8Xf35+0tDSe/HYJT0V8RlJxFmaPhaHdfBqiU+GVMeSu3MfKLz9ipU6P2zPjecRyKP977jlCQkKIjo6mX79+LF26lLKyMh544AFSU1MxMzNj586dREdH88wzz6DVapk+fTqPPvqoMk8uOTm53l45c3NzfHx8lOFeO7u2uyeqaDwJdkIIRX5+vtITUL3QoSl07twZKysrysvLSUxMpLKyslmq1dcchm1sXT7R9t17772kpqYyceJErK2t+e9//8t3333Hnj17KC0t5bbbbmPs2LEsWrSIHTt2YGtri29gV+7iB/QYN7rXUqPuW04pfHcC9twPpVVk3baaxbv96fl2OXfccQfvvvsuYWFhFBQU8NVXXxESEsJTTz2l1I577rnnWLZsGUVFRSxcuBCg3qFTFxcXJch5enq22T1nhelJsBNCKExdu64+1TXtTpw4gU6n49y5cwQHBzfZ61WT+XWiJnNzcxYtWsSiRYvYvn07zz//PPHx8YwZMwb44/+LTqfDxcWFXVwgp589BvRQc3vh6nUK53LhZBaMWWm8n2XcjP4kWZQONO5f6uPjQ35+PqdPn+bBBx+ktLRUGV49ePAg06dPB4z7Gefm5irBzsLColavnK2tbVN/PKKNkmAnhABQFjOAMXiZqnZdfQIDAzlx4gRgHI6VYCea28WLF/Hy8sLCwgJ3d3dUKhX9+vVj8+bNqFQqZdheo9GQmZfNXTZrMMRentvmbAWnL/9/OmbcoYVuztDPAzbPB5UKqnQYLgfA+1WbSCYYg8FARkYGNjY2LF26lOHDh6PX61Gr1fj6+vLII49gbW2NXq/H1dVVmSvn4eEhvXLihkiwE0IA1Kp3VT1U2pRcXV1xcXEhNzeXjIwMCgoKmrSOll6vJycnBzCWfJCNykVsbCxz587FysoKg8HARx99xJEjRxg9ejQajYa+ffvywQcf8NprrzFs3Cgy/Q3Q+fLQ6K3dYMk+mPI/8HEAH3twtYV5fWD0CtCooa87fDAFMJBOEW8c/Z5Lly6xY8cOunbtSmRkJPv27UOtVvPkk08yZ84cVq5ciYWFBQ4ODmzatAlra+sW/YxE26My1FfspobCwkIcHR0pKCiQpdJCtFPbt29XypxMnDjR5GVO6nL8+HEOHDgAwMCBAwkNDW2y18rOzmb9+vWAseTK2LFjm+y1RPsTzkr2cgnd7O9gyQTwb1hhbbUeeqZa8PdfOtV6vGavnJubm/TKiTo1JIdJj50QgvLyci5evAgYVwo21yrVgIAAoqKiMBgMxMfHExISgkqluv6JN0GGYcXNyqKESC426hp6NZz2rUTnYE5P9y74+fnh6+srPXLC5CTYCSFISEhQVub16NGj2XoNbGxs8PPz49KlSxQXF5OWloa3t3eTvJYEO3GzMin54866uY261ti5U+mpaprV5kIASJ+vEKJJtxC7npqvV7MdplZdxkWlUjVZGRfRPlXVLGnS2GupTHctIeoiwU6IDi4nJ0fZjcHNzQ0XF5dmff0uXbooCxnOnz+vrEQ0Ja1WS15eHgDOzs6yP6a4SkREBE8//XStx8rKyoiPj+f0/iM3d9G/b4Gy2v+fnWnaRUlCyHc3ITq4mr1kTVm7rj4ajYbu3btz+vRptFotFy5cMHmvYXZ2trIpugzDivro9XpSU1OVPVirV1HrVQYc+6kpsLmift0fJ0Jd0xf+W2PfWQP4qRzwwr5pGi/EZdJjJ0QHdmXtuu7du7dIO2oGyqYYjpX5daI++fn5nDhxgoMHD3Ly5EkWL17M3XffzbPPPsvBgwcBOLg/CvNRX8HgT+DrY8YTX9kNCzYYy50cz4BbvoS530Pfj2HXeeMx4SuguAJWHoHZa9CM/x9DQ4eQlpYGwJtvvklYWBh/+9vfGDRoUEu8fdEOSY+dEB3YpUuXlP0n/f39sbS0bJF2uLu7K0v5U1NTKSoqwt7edD0bspWYqFZZWUlKSoqyB2txcTEAGRkZ6PV6fvnlF5588knUajX//e9/efDBBxk3bhyvd/0vnSuWoLvlc7i3v/Fifo6wcgYk5kF2KUQugPhc+NdOGNut1uuqHCx5fNrDnIg8yCeffMLChQv59ddf2bdvH/Hx8fz000/N/EmI9kqCnRAdWHNtIXYjAgMDOXToEADx8fEm7cGoDnZqtbrZ5xCKlmUwGMjKylKCXGZmJvWVb62srCQ7O5uvvvoKS0tLNBoNXbt2Zf/+/bz/4Pt4GXJJTsj944TQGiu4+7iDmQb8HCCv/IpGQJC7P3YVamxsbDh8+DCrV68mMDAQlUpFYGAgdnZ2TfDuRUckwU6IDqqsrIxLly4BxrIjvr6+LdqeHj16KMHu7NmzJgt2lZWVFBQUAMZisFIAtv0rLi4mOTlZ+VNZWVnncWq1Gi8vL3x9ffHw8MBgMKDX69m5cycWFhZUVVVhbm7O66+/zp49e9CrDLh186WSy9vDqmtMuKu1d2zt4DhE5cMMl854e3tz/PhxwDgNYs+ePezduxdnZ2el51CIxpJgJ0QHFR8fr/RcVPcctCQ7Ozt8fHxISUmhsLCQ9PR0PD09G31dmV/X/mm1WtLS0pReufz8/HqPdXJywtfXFz8/P7y8vJQV0nl5eajVahYtWsT48eNRq9W4ubmxdu1aZs6cyciRIxk0aBBdnb0YRygfsRs16noLoZihRgssJJQQ8ii1LeX2228nPT2dtLQ0HB0dCQ4O5r777qNbt27Y2Ngoe8YK0RiypZgQHdS6devIzTUOK82ZMwcnJ6eWbRDGsLl7924AgoKCGDVqVKOvefToUWUSfHh4eLPX6RNNIycnR+mRS0tLUwpsX8nCwgJfX1/lj6mGPE+QyTIOsYKjlKGt9ZwN5jzAABYSSi+u/mVCp9Nx/PhxpYc6IyODtWvX8vLLLzN8+PAmK9It2i7ZUkwIcU1ZWVlKqPPw8GgVoQ6ga9eu7N27l6qqKs6fP8/w4cMbXXNOeuzah7KyMlJSUpQwV1paWudxKpUKd3d3pVfOzc2tSXqj++DOR9zGYm5lL5fIpQyATtgwgs7YYVHvuRqNhoEDB/LNN9+wbds2CgsLueuuu8jNzWXz5s1069aNYcOGybw7cVMk2AnRAbWmRRM1mZmZ0a1bN86cOUNlZSWJiYkEBAQ06prVwc7MzKzVBFhxfXq9nvT0dCXIVRfRroudnZ2y96qPj49S8Lo52GPJZHrc1LnvvPMO77zzDunp6ezbt095j+fPn+fixYv079+fAQMGSEFt0SDyv0WINiYxMZHQ0FB69+5NSUkJ//d//8ekSZOuOu6VV16hZ0hfUm/34n8cJ41iKtHhaLDE21OLw+oYZofeSrdu3ep4ldqWLl2KnZ0dCxYsaIJ3VFtgYKASPM+ePduoYFdWVqZMSm+qnhthOgUFBUqQS01NrXcXEjMzM7y9vZXh1bYe2D09PZkxYwZnzpzh0KFDlJWVodPpOHz4MGfOnGHYsGEtVmNStD0S7IRog0aPHs26detITk5mxowZVwW7bErZSBwnOYeeHuj5YyptnqqcS91AfyiSs+8MxtMikdtoPfPOPD09sbe3p6ioiJSUFEpKSrC1tb2pa8kwbOtWWVlJamqqsuihqKio3mM7deqk9Mp5eHig0WiasaVNT6VSERQURLdu3Th8+DAnTpxAr9dTUlLCzp07OXnyJMOHD5d9jsV1SbATog3Lz8/HYDAQHR3NM888g1arZcT08Xz3tCMXycCAF+h1MOFrqNKDhQZ+mIN+dSycyeH87Uu5/aVYnnIYQ8wzX6HVapk+fTpPP/00SUlJzJ8/Hzs7OywtLbnjjjua5T1V1/WKiYnBYDAQHx/PgAEDbupamZmZym0Jdi2vuqZcda9cRkZGvTXlrK2tlR45Hx8fbGxsmrm1LcPCwoJhw4YRFBTE/v37SUpKAiA9PZ3169cTHBxMaGgoVlay56yomwQ7IdqgyMhIRowYwdGjR1m/fj3PPfcc69evR+tsQZepQ6m89zYM1b10ajVsugtsLOC9/bDmJCwMhS8PQ8T9APzn1tf4aP1K/uo8iqlTp3Lvvffy1ltv8eKLLzJhwgTmzZvXrO+vR48exMTEAMbh2JsNdtJj1/JKSkqUvVdTUlKoqKio8zi1Wo2np6ey6MHFxaVDD507OTkxefJkLl26xP79+5VajKdPn+bcuXMMHjyY3r17S3kUcRUJdkK0QdVDsd9++y27d+/m+PHjzJgxg9NkUZaXA0l5fxxcXAGPbIbkQsgtg9m9rr7g8QwenfEnvsaX0rxCkpKSSEhIYPDgwQCEhoY20zszcnBwwNPTk/T0dPLz88nMzLyprcCqg52VlZWUamomWq2W9PR0ZXg1Ly+v3mOra8r5+vri5eWFubl5M7a0bejcuTO+vr6cOHGCmJgYqqqqqKysZP/+/Zw+fZrhw4e3eHFx0bpIsBOiDbvrrrt499136d+/Px+vW0kvx+Wg0xor4m8+azzo13PQ1QlWz4L/7IOiyz0mNXtD+nuiWjeXSY4TWKQbiVqtJiAggCNHjnDrrbcSHR3NxIkTm/W9BQYGkp6eDhh77Roa7IqKipR9cGVeUtPKzc2tVVNOp9PVeZyFhQU+Pj5KmDPlfsDtmVqtpl+/fgQEBHDo0CFlcVF+fj6//PILXbp0ISwsTH55EYAEOyHavPvvv5+8vDwmzZyGVp8LlhrYUGPodJgvvPkbHEkHD1vo7Gh8vGcnmLUGngyDxbdimPkdb+jXss+yOxs3bOTZZ59l/vz5LFmypEV+YHTr1o19+/ah1Wo5d+4cYWFhDZowX3MY9mZ6+0T9ysvLa23Zda2acm5ubrVqysnQ4c2zsbFh9OjR9OrVi99//12ZQ3rx4kWSkpLo168fAwcOlJ7PDk52nhCinQjkQ+LJvf6B17GNexhP6yitsGvXLhISEgAYP348Xbt2veFzo6KiOHbsGAATJ06kS5cuTdLGjkCv15ORkaEEuZqh+Up2dna1Fj1YWlo2Y0s7DoPBQEJCAlFRUbWCtY2NDUOGDKFHjx4deo5ieyM7TwjRAaVhmk3ETXUdUwgMDFSC3ZkzZxoU7GThROMUFhYqQS4lJeWaNeW8vLyUUiRtvaZcW6FSqejRowf+/v4cOXKE48ePo9frKS0tJSIiglOnTjF8+HDpre6AJNgJ0U5UUve8poYqo+4f4C3Bx8cHW1tbSkpKSEpKoqysDGtr6+ueZzAYlCr+tra2HaZURmNU15SrDnOFhYX1Huvi4qIEOU9Pz3ZXU64tMTc3Z8iQIQQFBXHgwAESExMBY6mfjRs3EhgYyJAhQ+RroAORYCdEO2GPBTmX96tskPAVsHk+2BmHzJxoPfWxqnsljh49qgw99e3b97rnFRQUUFlZCUhvXX2qw291KZLMzEz0en2dx1pZWSnDq76+vhISWiEHBwcmTJhAcnIy+/fvV1Yjnz17lgsXLjBw4ED69u0rIbwDkGAnRDsxDF+2koCO606b/UMdP8i759mAswkb1kiBgYEcPXoUMP6QupFgJ8OwdSstLa1VU6561fCV1Go1Hh4eSq9cp06dZL5WG+Hr68usWbM4deoU0dHRVFZWUlVVxcGDB4mLiyMsLEzmm7ZzEuyEaAdeeOEFxtzen589cqDPx1DwHHx7AvLLYed5KKgALztYNQP2JcF/9oOZGqb+sZWYamsCdh8dI2qSK+ldutCnTx+6dOnS4j/QnZyccHd3JzMzk5ycHHJycujUqdM1z5FgZ6TT6UhLS1OGV3Nz619c4+joqPTIeXt7y8rKNkytVtOnTx8CAgKIjo7m9OnTGAwGCgsL+fXXX/H19WX48OEyH7KdkmAnRDswcuRIjv12DBePTHLD/eFQKvx2EXp0gik94C+h8H+R8N0JY7mTgnKIvN9Yy27VMfjpLIbNZ5n/l/sxTzEnNTWV1NRUHBwc6NOnDz179mzRH/SBgYFKaYezZ88SFhZ2zeM78lZieXl5Sq/c9WrKeXt7K6VIpKZc+2NlZcWIESMIDg5m3759pKWlAZCcnMy6devo3bs3gwcPxsLCooVbKkypzQW7oqIi5s+fT1FRERUVFbz00ktMnjy51jFbt26lrKyMGTNm1Ho8h1KWc4RfOUc2pahR4YEtdxBE36MGzCoNDBkyhPT0dJYtW8arr77Kr7/+yqJFi5gzZw4pKSn8+9//vqHJ20I0p+HDh7Ns2TL6epoT+dwI2HMRzuUZe+UeNu4eQag3/J5kDHYh3rULFC/aRa+dT/HX0vGcLj6pbF9UWFjIvn37iI6OpmfPnvTp06dFAkD37t3Zt28fer2e+Ph4hg4dWm89NL1eT05ODmCcd9Tey22Ul5eTmpqq7PRQUlJS77Hu7u5Kr5y7u7vUlOsgOnXqxNSpUzl//jwHDhyguLgYvV5PbGws8fHxDBkyhJ49e7Z477wwjTYX7FatWsWkSZN49NFHMRgMyg+gmiZNmlTr/jlyeY09fEssOgzoa8xBUgG/cg7zo7EMK3bn+yG98fT05NVXXwVg/fr1fPbZZwwcOLBJ35cQjeHo6EhRUREe1u78c8RdvPXKI+BpBwEucDAFBnsbe/F6uBhPUNf8Bq7CY+0CHBdsxXPtw/Sd05ukpCROnDhBcnIyYFwxGRsby4kTJ/D396dv3754eno22/uztLTE39+f8+fPU15eTlJSUr3zhHJzc5VeqvbYW6fX68nMzFSGV2v2Tl7J1tZW6ZHz9vaWjeM7uG7dutG5c2eOHTvG0aNH0el0lJeXs2fPHqU8SnN+XYum0eaCnbW1Nbt372b27Nl4eHjg5OTEihUr+PTTT7GysuJf//oXKSkpFBcX89hjj/Gvle/y1pcfGr/Rvz4GxnYzrgIc5AXRqRj6ecDS26hcdoA9uWV02bSTnz/7jo+ffoO//vWv/Pjjjxw+fJgXX3yRd999l82bN6PRaHjggQdITU3FzMyMnTt3tvTHIgR9+/bFzMyMf2vGs8HKg7MjO6G5uz+6u9cZh2A9bOGftxjn2AEaVOgwYIs5e3s+Q9mH2dx1112sW7eOzp0707lzZ3Jzczlx4gTx8fHodDoMBgMXLlzgwoULuLq60rdvX7p3794sPT+BgYGcP38eMA7H1hfs2uP8uqKiIqVHLjU1VVnxeyWNRlOrppyzcytaBSNaBTMzMwYPHkzPnj05cOCA8jWVnZ3Npk2b6N69O0OHDsXOzq6FWypuVpvbeaKqqoq33nqLdevWYW1tzX//+1/+/ve/ExkZiYWFBXq9nlWrVlFcXEy/u8Yx5u7pGLbcjaG0Em5bDRH3G4Pda2NglD+EfQFb74ENp6G4Es1jw3BOrGDI0yf4ed2PLFiwgKeffpo+ffoQHh7O5s2bWb58OVVVVTz11FPo9XoZzhCt0mmyWEY0yzlCCVWoDKAygP7yf9cRdOZxhnAHQVhw7RII5eXlnD59mpMnT161fZSNjQ29evWiV69eTdojpNfrWb16NWVlZeg1Gvrfcw8nLC2JAVKBcjAWaklLwyEhgS5ZWTwyfDid22APRFVVVa2acnWNTFRzcXFRhle9vLyknIVokLS0NPbt26dMXwBj+BswYAD9+vXDzKzN9f+0S+165wlzc3MWLVrEokWL2L59O88991ytyZ/VIUuPgbnnPkN/MgPGrDCenFXjB9JAL+PfPvbGlYOX6TCQRykHSa23DadPn+bBBx+s9XpCtDbBuPEBk3mTcWwhnu2x+8krKcS6Us0zI+fRV33jgcfKyoqBAwfSv39/zp8/z/Hjx5UCwKWlpURHR3PkyBF69OhBnz59cHFxMfn7UavV2PfuzbcqFXuCgym5PHfOHGqVVNZ4eKDz9ASVio8NBv4CPAL4m7xFpmMwGMjJyVEWPWRkZFyzppyPj4/SKyc15URjeHl5MXPmTOLi4jh06BDl5eVotVqio6OJi4tj2LBhdOvWraWbKRqgzQW7ixcv4uXlhYWFhTL59/Dhw1RVVWFubq58MzxJJundzKGfh7H4qkoFVTVWh9WcYmQwgLkGdMbOSx0GsinhBHXPXQkODmbPnj2EhIRIj51o9eyw4E56Y5t8keRk49dHzzAXuImFcGq1moCAAAICAkhPT+fEiRNcuHABg8GATqcjLi6OuLg4fHx86Nu3L35+fiaZkF0IPA18MXAgKoMBfY2vuSv3ydDVeC5fpeId4C1gAfAu4NTo1phGdU256j/XqylX3Svn6uoqk9yFSalUKoKDg+nWrRsxMTGcPHkSg8FAcXExO3bswNvbm+HDhzfJL2zC9NpcsIuNjWXu3LlYWVlhMBj46KOPOHjwILfccgu2tra88MILAERyEY1rALp5fWD0CtCooa87fDCl7guH+cJ9GyAqGd4chwoVyzhU56EPP/wwCxYsYPTo0TLHTrQZNYdUtFpto0sceHp64unpSVFRESdPniQuLk6Z+5WSkkJKSgqOjo706dOHwMDAmy6Xsh34E5AJGFQqDA0MNdW/zq0CfgFWAJPrP7zJ6HQ60tPTlV65a9WUc3BwqFVTTspRiOZgaWnJ8OHDCQ4OZv/+/criqdTUVH744QeCg4MJCQmRRTitXJubY3cjUinCh3cbfR1rzCjieTRIj5xo+3bv3k18fDwAc+fOxdHR0aTXr6qq4uzZs8TGxl61z6iFhQVBQUH06dOnQZOylwGPYuxgr3tgsmHUl6/zPvA3E1zvevLz82vVlNNqtXUeZ25ujo+PjxLm2sL3WdH+JSYmcuDAgVpfz5aWloSEhBAcHCyjVc2oXc+xuxHJ1L95dUOUoSWfcjohc1hE23dlj52pmZub07t3b3r16sWlS5eIjY0lNdU4V7WyspLjx48TGxtL165d6du3Lx4eHte83ifAXy/fbsAmaddUHQ6fuPy3qcNdRUUFKSkpyvBqcXFxvce6ubkppUikppxojfz9/fHz8yM2NpbDhw+j1WqpqKjg999/5/Tp0wwfPhxvb++Wbqa4QrsMdiXUXQrgZhRTKcFOtAs1h0Krqq6cmWY6KpWKLl260KVLF3Jzc4mNjSUhIUEpl3L+/HnOnz+Pm5sbffv2pVu3bleFmh38EeqayhNADxo3LKvX68nKylJ65bKysqhvEMTGxkYJcj4+PjKcJdoEjUbDgAEDCAwMJCoqSun1z83NZfPmzfj7+xMWFiY7l7Qi7XIo9jBpDOazhp20+DeY2we61q779Okaf7q6eOPh4YGHhweurq5oNBpWrlzJ/PnzsbCwYOXKlfTs2fO62xwJ0ZKio6M5fPgwAFOmTMHX17fZXrusrEwpl1JWVlbrORsbG3r37k1wcDBWVlYUAsFAOqYZfq2PGnAFztCwBRXFxcVKTbmUlJTr1pSrHl6VieeiPcjMzOT333+vVS9So9HQr18/Bg4cKOVRmkhDcli7DHYFlOPOEiqpe4/Eq+j1cOUwiAEcS9W8tdodVY0ltGq1Gjc3N1599VVWrVpFt27dpNyAaBOOHTtGVFQUAOPHj6dr167N3gadTse5c+eIjY2tVTcLjD8cAgMDWT5kCKssLZs01CmvCdyLcUFFfbRaba2acvn5+fUe6+zsrPTKeXp6yg850S4ZDAbi4+OJioqq9Yuara0tQ4cOJSAgoAVb1z61qTl2Bw4c4IknnsDGxobRo0ezefNmoqOjAQgJCSE6OppXXnmFhIQE5QfBtGnTWLNmDR4eHqxZs4aVK1eyadMmqqqqyM7OZuHChXRa9T3p+iIMv94DuWUwbx1o9cbq+2vuhKQC4ypYL3sY4AlnsuHp4RCVAl8fA6Bofwq6995n/fr1XLp0iaqqKu655x7i4+OJi4tjxowZDBgwAL1ez6BBg5g+fToff/wxx48fx8LCguXLl+Pv709wcDBDhgzh2LFjPPPMM9x9990t9nmLjqup59jdiOrwFhgYSFpaGrGxsSQmJgLG0Lfv0iW+GjHCZHPqrkcHfAW8BFTHXIPBQG5urtIrl56eXm9NOUtLS6VHztfXF1tb22ZquRAtR6VSERgYiL+/P0eOHCE2Nha9Xk9JSQm7du3i5MmT3HLLLbi6urZ0UzukFg92P//8My+//DJTpkxBr9ezefPmOo8LDg7mX//6F/Pnz6eyspKIiAhmzJihbIfSqVMnPv/8c1544QWOHDnCph1bCP3HLPjtIozoDNvvBTMNPLEFdl0w7pmZUgQ77gMLM1iwwfhCDw6CBweh/iSGJ0bNY+HChUybNo2ioiL27t3LV199xX333Yefnx+PPvooVlZW/PTTT6SlpfHNN99w6NAhFi5cSGZmJo8//jhLly4lPT2dDz/8EDD2lEiwEy2huebY3SgvLy+8vLwoLCxUyqX8FhRkrCvZjHXa1MBHVVU8kpio9MpdOVxcTaVS1aop5+bmJjXlRIdlYWHB0KFDCQoKYv/+/Vy6dAmAjIwM1q9fT1BQEKGhoVhbW7dwSzuWFg92jz76KK+//jqrV6++KvDUHCXu168fAN7e3sptHx8f8vLyrnre1taWELzp7tOFC3kV6HPKYOFmyCuH1CLjPrE9XKC/hzHUXUG18wJdI/P5zzf/RqVS8eWXX7Jjxw7A+MPxvvvuY/ny5fTr14+ioiJl4ndWVhb+/v5otVrs7e2Ji4vj119/xcHBgS1btuDh4UFJSQm5ubk4OzvLDwTRrFpDj11dHBwcCAsLo//gwTypVmNo5tWhOuBjvZ5ukZGY1dEzZ29vr+zyIDXlhLiao6MjkyZNIikpif379yvTFeLi4jh//jyDBg2iT58+svK7mbR4sHN0dGTp0qVUVlYyePBgbGxsKCoqAlB644BaIajm7erwV9fz99GfZYZ4Mr6JxXB7IDw0GB7/xdgjAKC+Olip43NxWHyIQz/uR6VSkZOTw/bt29m7dy8xMTE89dRTWFlZYW9vz8CBA3F0dCQ6OpqePXui0Wj45JNPsLOz48iRI7i7uyvXLSgooKCggKKiItatW4e5uTkeHh64u7vj6emJu7u7/MAQTaq19dhdKd7CgvwrH4yIgBdfNM6B9fKCZcugCTa2L7O0JLlTJ/yzsjA3N8fb21vplTN1vT8h2qvqFd8nTpzg8OHDVFZWUllZyYEDB4iLi8PX15dbbrmFqKgohgwZoky9euWVV5RrGDCwm0R+JYEcylCjwhUbphLIMHxrzXmvS8393TuqFg92n376KevXr0er1bJgwQLc3NwYOXIkQ4YMaXR9HBvM+T/G8p9xZ4i79zP46SxY1/2WVagwAN6Lj2GfBjOmTANg06ZNuLi4EB4ezrBhw5Tjp02bxpw5c5g1axYqlQoHBwduv/12Dhw4wMcff4xarebf//43FhYWmJubo1ara83TqaqqUoZ9qjk7Oyurbz08PHBycmrU+xeiptbaY1ct5soHcnPhb3+DnTvBzQ2+/RYeewxWr274xetaIFWDymBAP2AAU62s8PDwkJ4FIW6SWq2mX79+9OjRg0OHDhEXFwcYi3UnJCTQuXNn3njjDX788cda55VQyZcc4QOiOEce5qhrzbX9N3vpgzuPM4Q/0R9zvVq+TuvRLlfFXqkcLd8Qy/tEcZwMNKhQX079egzoMDCKLjxGKDMJbpKdJnQ6HdnZ2WRkZCh/SktLr3mOpaVlraDn5uZ209syCZGdnc369esB6NWrFyNGjGjhFtX2KPA5NfZ+/fprSEiAV1/946Du3WH4cPjnP6FPH3j6abj9dhg92hgCT5wAjQZWrgRfX+jVC4YOBUdHOHwYtm0DKyt44QUYMwbGjweMv+EuuPz6QgjTyc7OZt++faSnp5Odnc0PP/yAXq/n+eefx9zcnGPHjhEwrB+PvPEspboKeHwo3NXXOO/96eHQxwOe/hVuDzRe8D/7cTaz5dWpf6Y8p4iff/6ZwsJC3nrrLcaPH99ue+za1KrY5mCFGQ8wkPsZwEFS2MF5cmt08U6jJ8G4NWkbNBqNEtCqFRcXk56eTmZmJunp6eTk5NSaV1hRUcGlS5eUCakqlYpOnTrVGr5ti0FbtIzW3mOXRo1QB5CaClf22ru7Q436WYqffzYO0e7eDVFRsHgxLF0Kycnw++/G5959FzZtgjvvhMhIeP115XTt5dcXQpiWq6sr06ZNIyEhQVkcOX78eD788ENCQ0MpqCph8f99hXb3fcb6Q6NWwJze9V+woJyCyPl8rjKwvfQhnnnmGTIzM7nzzjsZf/kXtY6uQwS7aipUDMWXoTRfYdZrsbOzIyAgQKn5o9VqycrKqtWrV15erhxvMBjIzs4mOzubU6dOAWBtbX1Vr55Go2mR9yNat9Y2x85gMFBRUUFpaSmlpaXkOjlBzX1kvbzg3LnaJ2VnQ1BQzYsY/z51CjZsgD17jI/5+RkfDwj4Y07e3XfDwoXG64aFXTU0W44QoqkEBARw++2389NPP9GzZ082bdpEVlYWP6njqTibCRO+Mh6YXw5ZJbVXxtccVwzxRq+CU2Qx5et/Yrs6DrVaTVqa/GpWrUMFu9bOzMxMKQFRraCgoFbQy83NrXVOWVkZiYmJSi0wtVqNq6trrbAntbUENF+PnU6no7S0lLKyMiW01fxT/XhZWVmteacF48eDre0f39Bvuw3Cw43z6qrn2I0YYQxqycnGodjjx2HqVGPYmzPHuNACoDq41gxvHh7G0Pf++38cV4MUZBCiaZmZmeHs7MycOXNISUlh6ZefUPCnHhDkCtvuNVapqNKBuQacrSC50DgUezwDpl4eir286FGHgcMfbiTh2GnssrWtbmpJS5Jg18o5Ojri6OhIYKDxP3VlZSWZmZnK8G1mZmatLY30er3yfGxsLGDsGaw5fOvq6iqTTjugxvbY1exdu1Zwq2+LretxKi1Fo9ejq+5x7tTJGMJmzoSSErC3h82b4cIFuPde+PxzqN71ZepU2LXLOG9OpTL2zj344NUvMn8+vPYa9O9f62EzwPOmWi2EaCh7e3tefPFF/vPtZ8av10WjYPzXxtDmZgNr58CCAXDvBvj8MNjUPbdcNaILo0aMZM6widjV7O3v4DrE4on2zGAwkJ+fX6tX71pbHoFxvp+bm1utXj0pINkxfPHFF+j1elxdXZk5cyZ6vb7OkFZXaKtv94WGUqlUWFtbY21tjY2NjfJnq5cXL/n41F2cOC8PJk82hrm+fW/+xX/4wRgMn366dpuAj4G/3PyVhRANUEgFbrxz41t/1sMJK7J5pkkWPbYmsniiA1GpVDg7O+Ps7EzQ5blHFRUVtYJeZmZmraE3nU5Heno66enpymMODg61gp6Li0ujCignJiby9NNPs27dOuLj47nrrrtYv349nTt3vu65mZRwlhyKqMAWC7rgSJcGbdNutHTpUuzs7FiwYEHD30AbV1lZWWdQi4+Pp7S0FDMzM4qLi2vN4WwsMzOzWkHtyuBWfd/a2rrO/1sWGLf2qpOzMxw40LgGfvaZcaXtpk1XPWUABjfu6kKIBrhIfqNDHUA+5eRQhjsy5aiaBLt2yNLSks6dOyshSq/Xk5ubW2v4trCwsNY5hYWFFBYWEh8fDxiH7dzd3ZWg5+7ujqWlZYPbkpKSwvz58/nf//53zVBnwEAkF/mIg2wgDt0Vu4WG48/jDGEaPTGr5zczvV7froeY9Xo95eXl9c5Zq3m/vjl02dnZVFRUYGlpecOhzsrKqlZAqyu02djYNLoUT2/AFchu1FWu4c9/Nv6pgxPQv85nhBBNoYibm7JRlwLKJdjVIMGuA6heUOHq6kqvXr0A46KLmr16WVlZ6HR//PZUVVVFSkoKKSkpymNOTk5XFVC+Vq9ebm4us2bN4pNPPiEoKIg333yTX3/9FYPBwEcffYRWq2XZsmW88tl/mKpfzeFb3kDz1Ux0S/bCZ9Ng1HJ4aBDM7UPE9NeJ2HoPTu8epvP3KdhrrPjggw8YNGgQgwYNYuTIkWRnZ7N48WLmz5+PnZ0dlpaW3HHHHU32uZpKVVXVDS82aKzq4GswGLC3t68zoF3Zu9ZcYdkMWAi8CSb4Pf7GaYBHMPYYCiGahy1X/CK48TQM9wP3hs+Vs7viqzckJITo6OjGNK9Nk2DXQVlbW+Pv74+/vz9g7A26soBySUlJrXPy8/PJz8/nzJkzgHED6JpBz93dvVavzeHDhxk5ciSDBw/mxIkTnDlzhsjISFJTU1m4cCE//vgjx8+cJKRiGRn7TsPoLugCXeBsDlRowdkafk+Cbs4Q6g3pReRvPEbF7w+x+tI4/vnwP9m+fTt5eXk8/vjjBAQE8Nhjj/Hiiy8yYcIE5s2b12yf55UMBkOt3rX6QltpaalJV6haWlpedzi0qKgICwsL7rrrLpO9rqn8GXijmV9TjzHYCSGajy8OqFGhrx6d2RgHAS4NDnbWmOGKjXLfVHOB2zIJdgIw9uS4u7vj7u5O38uT04uLi8nMzFSCXnZ2dq0vmsrKSpKSkkhKSgKM8/1cXFzw8PCgqqqK0aNH06VLF1566SX69OnDvn37CA8PB4wLOIqo4Pw0d3J+PoL+lzPw98tbtrnZwuazMCkAdl2APRdhVBdIzIf+HlSq9Tzgvwe//BzAuBVbdS3AhIQEBg82zpYKDQ01+eek1WpvaLFBWVkZN7Au6Yao1eprzlmref96NQwdHR2VMiOtcejaF3gY4w4QzfHtWQPcB3RthtcSoiOKiIhg8eLFWFtbc/78eVavXk1ycjJvvPEGTroM8h/vj36YD2xNgJNZMMYfUorgnfFwOhv+/BOcewJejTD+HOjhAgs2QqUOVT9P7l/6EqtXfs3WrVspKSlh4cKFymt/9dVXREVF8dFHHzVqznhbI8FO1MvOzg47Ozu6desGGEPNlb16NYcHDQYDOTk55OTkkJ2dTXJyMjNmzODTTz+lvLyc0NBQVq1ahZmZGVVVVXxEDFl3d4eHf4LiSmO9IoARneHN3+CrO+BkJvx4Bv421HjM0XR0eh1Fl9LJcTL+6K8ZTgICAjhy5Ai33nor0dHRTJw48Ybe65Vz1+oLbjdbyqMuFhYWN7TYwNLS0mTflK4seXIz8yab2jvAZow7QTRluFNjnNP3bhO+hhDC+L1m69atbNmyhS+//JKDBw+ye/du9mguMX7UWJhzv/EX+eotxJYdgt8uweks6NkJUgohKhmevQWe2WY8blIPDA/+SOge44iHubk5P/30EwAvvfQSn3zyCXFxcR0u1IEEO9EAZmZmeHp64un5R8WvwsLCqwoo1+ypqqysZP78+bz33nsMGDCA3r17Y2FhwfDhw9myNBCVhz0GveGPfQABRnaG1yKhtzuM7AIHU8DO0vhnek8Y/iU6tYrsD28n/4r9Ap599lnmz5/PkiVLsLe3p7y8nMzMzOuGNlOX8rjeYgNra+taBYObS83XbK3Bzh74ChgPxoLCTfRNWQ+sgJtYby2EaIgBAwYA4OfnR35+PmfPnmXChAkAWOZXUZVVWvuXuJGdYVk05JbBg4Ng53nQ6sHaHBJyIdQHM9R0C+2LLj4bjUZTa4SmrKyM9957j0OHDnW4UAcS7EQjOTg44ODgQI8ePQBjWKjeFm3QoEFkZGQA8NxzzwEwadIkAE57V5BkfnkXDQsNzK9Rm2yQN+T803h7bh/jn2pP32L8A1QZYEnWDpYvX86BAweUoPbEE09QWlpKRUUFABs3bmz0+zQ3N693NWjNx62srFr1N5KaPXatcb/YauOAjw0GFjbhZ/khMLnJri6EqFbze6JOpyMoKIht27ZhYWFBXFUGw81Xkm+uwaC73CnQ2x2Ophvn3I3qApP/B7caR44IcEF9MBXPyYMYfMhAjz/14Pz587VGbqytrXn//feZO3cuP/zwAzY2NnQkEuyESZmbm+Pt7Y335c3bDQbDVdui5eXlEedTgVoP+lnfQXdn8LJv8GsZgJ9KTtD5QOpNt7dmULtWaGtsKY/Worm2FTOFkJgY7i4rY/WIEagMBgwmmA+oxthT9yHwWKOvJoRoKLVazaJFixg/fjxqtRo3Nzci137IqMmnKfj7Vgy3doN/jYJO1jDYyzjnuqTKGPAA9T9HYvGnn/B8MwHHPgMYNWoU58+fv+p1brnlFp5++mnmzZvH999/3ypHJ5qK7Dwhml1FRQUPVm1gjc1ZtOrGLTDommHOcz+61nqsulDu9RYbWFlZtbrFA00tKiqKY8eOATB16tRa+xK3JmfPniUiIgKA0z4+fDtxIllmZo2ac6cB3DAOv05qfBOFECaURhFv8ztfcIRiKmutmNWgQocBZ6x4hME8wy24dLDdnWXnCdGqWVpa4mTpgAoV0Lhg52znwLhx42oFNwsLqUhWnyvn2LVGaWlp7NmzR7n/YJcuvGZmxjPAZ4DaYEDXgCFaDcZeuj9hXCjhaNrmCiFMwAt73mMSrzOW7zjBVs6RQykqVLhhwzR6MotgLCW2XJd8QqJFuGGDoaGhbvFvxvl2XZ0BUKOim60H3bt3r/PwlStXMn/+fCwsLFi5ciU9e/YkLCyssU1v01r7HLvCwkK2bdumLGbp1asXffoY51h+AvwLeD0ri9UODpRYWYHBgLlKRc2Iag7KfWeMRY//DHRprjchhLhptljwIIN4kEEt3ZQ2S4KdaBF3EMQrRN74CXo9PDey9kMYmElQvaesXLmS2bNnY2Fh0SH3i61La55jV1FRwZYtW5RFL76+vgwfPrzWMX7AtEOHGJCaSqqLC26TJnHa1pZ0oBywAjww7vsaAvSBK+vbCyFEuybBTlzXgQMHeOKJJ7CxsWH06NFs3rxZ2a6leuuWV155hYSEBHJyjEWDp02bxpo1a/Dw8GDNmjWsXLmSTZs2UVVVRXZ2NgsXLsRh1RoK9eXw6z3GZe3z1hmXtHvYwpo7IakA7ttgXFgxwBPOZBvrF0WlwNfHMEPD/Qf+zW2ZmbzyyivExMRQVlbGZ599RllZGUePHmXy5MnMmDGDwsJCQkJCuP3223nqqaeIiorCwsKC5cuX4+/vT3BwMEOGDOHYsWM888wz3H333S35kTeZK+vYtRZ6vZ7t27dTUFAAGItO33rrrVfNgaysrCQtLQ2NwUCvykruspX9IYUQoqaONXNc3JSff/6Zl19+md27d/PSSy/Ve1xwcDBbtmzB2dmZyspKIiIiqKysVFYsderUiZ9++okxY8Zw5MgRlu1YA/094LeL4GwF2++F3x4AHwfjjhNgrED+9Qx4vkZv3YOD0EQ8wLh5U3n22WdxcHDg9ddfJzIykk8//ZR33nmHsLAwBgwYwJYtW3jyySeVU6Ojo0lJSWHv3r28+uqrvPbaawCkp6fz4YcfsmfPHj744AOTf4atRWudY/fbb7+Rmmpc3Wxtbc2kSZPqnCuZnJysDNN26SKDq0IIcSXpsRPX9eijj/L666+zevXqq3qyai6q7tevHwDe3t7KbR8fH/Ly8q563tbWljn05jWfrsTnVaDPKYOFmyGvHFKLYJCXceuY/h5gUfu/qRkqPHdmYReZwavfvAfAO++8w44dO4zPX6Pwb0JCglLIMjQ0lBdeeAGAbt26KSuNdLrm3IK+ebXGOXbHjh1T9h/WaDRMmDABe/u6y99cvHhRud25c+dmaZ8QQrQlEuzEdTk6OrJ06VIqKysZPHgwNjY2FBUVAdSqH1SzCGXN29Xh78rnzVBzL/34nyGJM9/EYrg9EB4aDI//YtxxAEBde/WjGhWe8ZX4Lz7Bqh9/RqVSkZOTw/bt29m7dy8xMTE89dRTgDHEXBnSAgIClILFhw4dUgort+aiwqbU2ubYXbhwgaioKOV+eHg4Hh4edR5rMBiUfYmr6yUKIYSoTYKduK5PP/2U9evXo9VqWbBgAW5ubowcOZIhQ4Y0+oerJWa8xCg2jAvi+3tfh5/OgvXV/y3VemPJilF0wXvxSY6lZTFlyhQANm3ahIuLC+Hh4QwbNkw5Z9q0acyZM4dZs2Ypj4WEhODl5cWIESMwMzNjxYoVjWp/W9Oa5thlZWWxe/du5X5ISEi9K5wBMjIyKC83biHn5+fX4WoQCiHEjZACxaLVyKKEFRzlIw5yiULlcZtyFSPjbHjKbjTjA0KvcQVxPQUFBaxZswYw9l6OHTu2RdpRXFzMxo0bKS0tBaBHjx6MGTPmmuccPHiQo0ePAsaevcDAwGseL4QQ7YUUKBZtkhu2PMstPMstVKClgApKM/P5deNmYzHjrvkQ0NKtbNtawxy7qqoqfv31VyXUeXp6MmrUqOueJ/PrhBDi+iTYiVbJEjPcMcPgZoOVpRUVFRWkpKSg1+tlCK4RWnqOncFgYOfOnUpZHAcHByZMmIBGo7nmeYWFhcoiHA8PD6ysrJq8rUII0RbJT0jRqqlUKnx8fABjDbOsrKwWblHb1tJz7A4cOMClS5cAsLCwYNKkSTcU0qrPASlzIoQQ1yLBTrR6fn5+yu3qVZHi5qhUKqV3rLmD3alTp4iNjQVArVYzYcIEnJycbuhcGYYVQogbI8FOtHq+vr7K7eTk5BZsSftQ3WvXnEOxycnJ/P7778r9ESNG3PCK6urdJgDs7e1xcXFpkjYKIUR7IMFOtHq2trY4OzsDxhIZ1XuJiptTPc+uuYJdbm4uO3bsUOoZ9u/fn6Cg+vf4vZLsNiGEEDdOgp1oE6p77QwGAykpKS3cmratOtg1x1BsWVkZW7dupbKyEgB/f3+GDBnSoGvUnF8nw7BCCHFtEuxEm1Bznp0MxzZO9VBsUwc7rVbLr7/+SnFxMQCurq6MHTu2Qbt8GAwGJdiZm5vj5eXVJG0VQoj2QoKdaBM8PT2VSf8S7BqnOWrZGQwGIiMjyczMBIzD6ZMmTbrmPr51qbnbhK+v73XLogghREcnwU60CWZmZkpvTXFxMfn5+S3boDasOWrZxcTEcO7cOeX1Jk2ahI2NTYOvI2VOhBCiYSTYiTZDVseaRlMHu/j4eA4fPqzcHzduHJ06dbqpa9Usc1JzOF4IIUTdJNiJNqNmsJN6djevKYsUp6enExkZqdwPCwu76Z62oqKiWrtNWFtbm6SNQgjRnkmwE22Gi4uLMpyXlpaGTqdr4Ra1TU0V7AoLC9m2bZtSmqRXr1707dv3pq9Xs7dOhmGFEOLGSLATbUp1r51WqyU9Pb2FW9M2NcVQbEVFBVu3bq210GH48OGNuqaUORFCiIaTYCfaFJln13imDnZ6vZ7t27crC1qcnZ259dZbUatv/ttLZWUlqampANjZ2cluE0IIcYMk2Ik2RYJd45l6KHbv3r1KCLOysmLSpElYWFg06pqy24QQQtwcCXaiTbGyssLV1RWAnJwcSktLW7hFbY8pg92xY8eIi4sDQKPRMHHiROzt7Rt1TZAyJ0IIcbMk2Ik2R3ahaBxTDcUmJiYSFRWl3B89ejQeHh6NahvIbhNCCNEYEuxEmyPDsY1jimCXnZ3Nrl27lPshISEEBAQ0um0AmZmZstuEEELcJAl2os3x8PBQhhOTk5MxGAwt3KK2pbFDsSUlJWzdulUJhT169GDQoEEma5+UORFCiJsnwU60OWq1Gm9vbwDKy8vJyclp4Ra1LY0JdlVVVWzdulWZ2+jp6cmoUaNM2r6a8+tktwkhhGgYCXaiTZLh2Jt3s0OxBoOBnTt3KkHawcGBCRMmmHSotKioiNzcXADc3d1ltwkhhGggCXaiTZIFFDfvZoPdgQMHlN40CwsLJk2ahJWVlUnbJqthhRCicSTYiTbJwcEBBwcHwLg/qan3PG3PbmYo9tSpU8TGxgLGofDx48fj5ORk8rbJ/DohhGgcCXaizaoejtXr9aSlpbVwa9qOhga75ORkfv/9d+X+iBEj8PHxMXm7qqqqZLcJIYRoJAl2os2qOc8uKSmpBVvSttScE3e9odi8vDx27NihrDzu168fQUFBTdIu2W1CCCEaT4KdaLO8vb1RqVSAzLNrCJVKpcyzu1awKysrY+vWrVRWVgLg7+/P0KFDm6xdNYdhO3fu3GSvI4QQ7ZkEO9FmWVhYKDsdFBQUUFRU1MItajuqg119Q7E6nY5t27Ypn6mrqytjx45VgrSp1dxtwszMTClnI4QQomEk2Ik2rSOVPUlMTMTNzY2xY8cyatQonnrqqZveK9fc3Bw9BiqrKut8PiIigoyMDABsbW2ZOHFirdW0dfnss89uqi0gu00IIYSpSLATbVpHCnZg3I91165dREZGYmNjw8svv3zD5xow8BsXmcc6HpydwF8fTuf+exNx4S0eZBOHMS5AiY6O5ty5c4Cx92zixInY2tpe9/qNCXZS5kQIIUzj2r+CC9HKubm5YWlpSUVFBSkpKej1etTq9v/7ikql4sUXX6Rv375MmTKF559/HoC//vWv3HfffSQkJPDII4+g0+kYPHgwk//zKFNDwimPfhAz1GjDlkH0I7BgA3mWZqw4m8Py7s64+3hh9t0penfpwezZsxk4cCAPPfQQhYWFeHl5sWrVKn777TcWL16MtbU158+fZ/Xq1cTHx3PmzBnCw8P585//zPz58xv0fmR+nRBCmEb7/wko2jWVSqX02lVWVpKVldXCLWo+FhYWVFZW8vzzz7N582Z+++03PvjgA8rKynj22Wd5++23iYiIoO879zCR/1GODgAt+toXGtUFw+4FcCqLzAEOZJ5awLHEOEJCQli9ejV/+9vf2LVrF/369WPDhg2AcW7ehg0bWLx4McuXL2fGjBn07NmTiIiIBoe64uJi2W1CCCFMRIKdaPM6atmTiooKLC0t0el0uLq6Ym5uTkBAAKmpqSQlJTF48GA2c5YH1JvQYwAMf5xc4yb9jAtQ8LaHAR5o1ZDVw5qsLuacOnWKl19+mfDwcNavX096ejoAAwYMAIw7gOTl5TXqfUhRYiGEMB0JdqLN62jz7Kr9+9//5o477kCtVpOdnU1VVRXx8fF4e3vj5+fHvsMHuZcNGC7XhqNcCzo9XMqHvLI/LlRzoavK+MeggkcMP9EzqCdvvvkmERERREVF8cgjjxgPq7E6trrG3c2umJVhWCGEMB2ZYyfaPFtbW5ydncnLyyMrK0vpyWqPIiMjGTNmDDqdjqFDh/Laa68xfvx4brvtNlQqFY899hjW1ta8/fbbTH34LvINWTDYG/4zEe7uB2FfwKgu4HS9PV4NXCSfkf+6h/cefkNZpPH222/Xe8aYMWOYPn06999/P3fccccNvZ8rd5vo1KnTDZ0nhBCibipD9a/b11BYWIijoyMFBQXK/pxCtCb79+9X9jK99dZb6datWwu3qOUN5jOOkn55GLbhzFBxG4FsZJ6JW/aHCxcusH37dgB69erFiBEjmuy1hBCirWpIDpOhWNEu+Pn5Kbc70nBsfS6Sz2HSbjrUAWgx8BNnKeP6+8neLClzIoQQpiXBTrQLnp6eSlFbCXaQQYlJrqPHQC5l1z/wJshuE0IIYXoS7ES7YGZmhpeXF2Asn5Gfn9+yDWphVZdLm5hCpQmvVVNWVhZlZcbQKLtNCCGEaUiwE+1GRyl7kpiYyOzZs695jDPWcDQNDjay9/KzaOO1gMWLF3PhwoXGXa8GKXMihBCmJ8FOtBsdtexJXQJwwfZoLhxMufpJvf7qx+qgAiw/O4YjxhXGzz33HF27djVZG2sGu5pzJIUQQtw8CXai3XBxccHGxgaAtLQ0dLqmGUJsbhkZGYwZM4aRI0cye/ZsdDodKSkpzJw5k0GDBrFr1y4A7r//fkaOHEl4eDjHDh3G4r1D8H4UTFgFiXkwajnM/R7e+h2+PgbhK2DQJ8bbAFklcPtqGL0C7v4Bw4bTcCaHMeFj+Oabb1iwYAEnTpwgIiKCSZMmMWPGDPr378+JEycA+OqrrwgJCeFPf/oTvXr1uuZ7unK3iep/NyGEEI0jdexEu+Lr68vZs2fRarWkp6fj4+PT0k1qNGdnZ7Zv346ZmRlPPPEEu3btIj09nYiICIqKipg6dSp79uzhzJkz/Pzzzxw6dIiYmBjGDRvJuj7Z8PhQY7BLKYId94GFGZRWwr39oawKbvnSePvfv8H9A2FWL9DrsVZbENQznoiICAC2bdumtKmqqoqtW7eyZcsWli9fzjvvvMN7771HVFQUJSUl1x1alaLEQgjRNCTYiXalOtiBcTi2PQS7nJwcFi5cSF5eHqmpqbi4uNCnTx8sLS2xtLREq9Wi1Wq59dZbmTx5Mra2tkyfPh3bCjXBWTbEGS7vINbfwxjqAH49B+8fMD6RYOw543Q2vDDSeFut5iVGs44Ndbbpyi3FsrKy8PPzU9rk7+9/zfckZU6EEKJpyFCsaFfa4wKKb775httvv53IyEgmTZpEly5dOHnyJJWVlWRmZlJRUcE333yDl5cXDzzwAPb29pw6dYrevXvzoMtwblP1MF5IXWPLr9f3wM93w5a7wcbc+FiwK+wx9qQ9qB/AP7ml3m3CrtxSzM3NjeTkZCorK8nLyyMxMbHe91NVVUVKinHun+w2IYQQpiU9dqJdsbKyws3NjaysLHJzcyktLW3z87fGjRvHvffey08//YS1tXGFqq+vL7fffjtnz55lxowZFBUV8fHHH6NWq7Gzs+ODDz5Aq9Vy33334XvQj7lvjmMN2zBDjRY9zAyGkcthkBc4G6+pfn4U+gUb6Px+HGW+Z1Gtnl5rm7Br0Wg0/P3vf2f48OEEBwdfc3g1JSUF/eUFHDIMK4QQpiVbiol259ChQxw5cgSA8PBwAgMDW7hFpnXp0iWioqLIy8tTHlOpVAQHBzN48GAl/F0plgyWEc1KjlKGttZzdjpz/qIJ4RFCCMDlptpVVVWFubk5ubm5TJo0iYMHD9Z5XGRkJGfOnAFg8uTJsiJWCCGuoyE5THrsRLvj6+urBLvk5OR2E+yysrKIiooiNTW11uP+/v4MGTIEJyena57fFw8+5jYWcyv7SSI+J5ljR45hV6FmpkcoI0OGNap9y5YtY/369RQVFfH666/XeYzsNiGEEE1Lgp1odzw8PDA3N6eqqork5GQMBkO9c8XagqKiIg4dOkRCQkKtx93d3Rk2bBienp4Nup4DlkwkgKEaVyzOGxeaVFmXNrqdf/vb3/jb3/52zWNktwkhhGhaEuxEu6NWq/H29ubixYuUl5eTk5ODq6trSzerwSoqKjhy5AgnTpxQ5qQBODg4MGTIELp169ao69vZ2Sm3i4qKGnWtGyVlToQQomlJsBPtkp+fnxIikpOT21Sw0+l0nDx5ksOHD1NZWak8bmVlxaBBg+jVqxdqdeMXtJuZmWFtbU1ZWVmzBbuaZU4k2AkhhOlJsBPt0pXbi1XXXWvNDAYD586d4+DBgxQXFyuPazQa+vbty4ABA7CwsDDpa9rb21NWVkZpaSk6na5Jh0aLi4vJyckBwM3Nrc2vVhZCiNZIgp1olxwcHHBwcKCwsJD09HRlxWZrlZqayoEDB8jOzq71eGBgICEhIbWGTU3J3t6ezMxMwBi8HB0dm+R1QIoSCyFEc5BgJ9otX19fTp06hV6vJy0trVUO/eXm5hIVFXVVMWVfX1+GDh3a5MV77e3tldtFRUVNGuxqzq+TYCeEEE1Dgp1ot6qDHRh3oWhNwa6kpITo6GjOnj1LzVKSnTp1YujQobWGkpvSlcGuqWi1WqVMi62trew2IYQQTUSCnWi3vL29UavV6PV6kpOTW7o5AFRWVnLs2DFiY2PRav8oEmxnZ0doaCgBAQHNWpqluYJdcnIyOp0OkN46IYRoShLsRLtlYWGBu7s76enpFBQUUFRUVCvINCe9Xs/p06eJiYmhvLy8VhsHDhxI7969MTNr/i/H5gp2shpWCCGahwQ70a75+vqSnp4OGHuNgoODm70NFy5c4ODBgxQUFCiPqdVqevfuzcCBA7Gysmr2NlVrjlp2BoNBmV8nu00IIUTTkmAn2jU/Pz+io6MB4zy75gx2GRkZHDhwgIyMjFqPd+/endDQ0Fax77JGo8HGxobS0tJaJVZMqeZuEz4+Pi3SMymEEB2FfIcV7ZqrqyuWlpZUVFSQmpqKXq83SXHfaykoKODgwYNcuHCh1uOenp4MGzYMd3f3Jn39hrK3t6e0tJTS0lK0Wq3Jg5eUORFCiOYjwU60ayqVCl9fX86dO0dlZSWZmZkN3lv1RpWVlXH48GFOnz5dawswJycnhg4d2mpDjb29vdKrWFxcjJOTk0mvL9uICSFE85FgJ9q96mAHxnl2pg52Wq2W2NhYjh49SlVVlfK4tbU1ISEh9OzZs8l7CRvjynl2pgx2stuEEEI0Lwl2ot27cnuxkJAQk1zXYDBw9uxZDh06RGlpqfK4mZkZ/fv3p1+/fq16t4tqNef6mXoBhQzDCiFE85JgJ9o9W1tbnJ2dycvLIysri4qKCiwtLRt1zaSkJKKiosjNzVUeU6lUBAUFMXjw4DbVM1Wzx87UCyikzIkQQjQvCXaiQ/Dz8yMvLw+dQc+JtPN08vfCDgucsULDjQ+TZmdnc+DAAWUXhWpdunRh6NChJp+f1hyaqpadVqslJSUFMIZrV1dXk11bCCFE3STYiQ7B0MWRDZaF7AkupdRqrfK4A5Y8xED+Qgg9qH+bq6KiIg4dOkRCQkKtx93d3Rk6dCheXl5N1vam1lS17GruNiG9dUII0Twk2Il2rYgKHmQT6zxPofIA/RWdc4VU8D5RvMsBbqcHXzEDF6yV5ysqKjhy5AgnTpyotdLVwcGBIUOG0K1bt+Z6K02mZi07UwY7mV8nhBDNT4KdaLeyKWUMX3GaLAwqMNSzBasOAwBbSGAInxPJAjx1tpw8eZIjR45QUVGhHGtpacngwYMJDg5Go9E0x9toFg4ODpSWllJWVmaSWnYGg0EJdrLbhBBCNB8JdqJdKkfL7XzDabKU4HY9OgxcNOQzpnI5z21yQ5tXojyn0Wjo27cvAwYMwMLCoqma3WKuXEDR2LmC2dnZykph2W1CCCGaj3y3Fe3SFxzmICk3GOn+oFUZSDAv4Ed/HbflGRcVBAYGEhISUiv8tDdXLqBobLCrWZRYhmGFEKL5tN6qqaLdKyoqYurUqYSHhxMWFsaWLVtMcl0DBj4gqmEn/X0LlBmLCxtUENmrFC8/H2bNmkV4ePhVoe6zzz5Tbi9evPiq7cPaGlOvjJUyJ0II0TIk2IkWs2rVKiZNmkRERAT79u0jLCzMJNeN5CLx5N54b51eD/+dDNaXiwmroMBWj35ydzp1qnulbM1g99xzz9G1a9fGNbqFmTLYlZSUkJ2dDRj36m1LNf2EEKKtk6FY0WKsra3ZvXs3s2fPxsPDAycnJ0JCQoiOjgZQbi9YsABLS0vOnj1L9+7d6dKlC7/88gu33HILS5Ys4ZVXXiEhIUHZuqpiWndY8zN42MKaOyE2Ax77BSp1MNgLlt4GERfgP/vBTA1TA2HVMdg8H96Pgu3nQA9zT79LeVYB8+fPJyUlBZ1OxzfffENMTAxnzpwhPDycP//5z2zbto2nn36a4OBg/vSnP5GUlISdnR3/+9//KCgo4O6778bX15dTp07x/vvvM3bs2Jb82OtkymAnw7BCCNFypMdOtJh7772Xnj17MnHiRMLCwjhz5ky9x44aNYrdu3dz6tQp+vXrx/79+4mMjFT2Zg0ODmbLli04OztTVFmGJuJ+Y5A7nwsBLhCxAPY/BEmFEG8MgBSUw/q58MCgP17oX6Mg4n4Y7kvQ4rkAfPHFF0RGRvLUU0/x6aefMmPGDHr27ElERATz589XTt2wYQO+vr5ERkYyb948PvzwQ8C4kGD16tWsXbuWpUuXmvQzNBVT1rKTMidCCNFypMdOtBhzc3MWLVrEokWL2L59Oy+//HKt5w2GPwZT+/XrB4C3t7dy28PDg8LCwquez+x3uffJxx7yyqFcC09tg9IqOJ8HqZeDS4g3qOqogbLqKFTp8XkwHJ1Ox7PPPsvx48cpKyujT58+9b6fhIQEQkNDAQgNDWXbtm0A9OnTBzMzM2X3i9ZIrVZja2tLSUlJo4Jdzd0mbGxsZLcJIYRoZtJjJ1rMxYsXqaysBIw7OBgMBsrLy9HpdFy6dKlWCFLVCGA1b1eHv5qP2assUaOqPgCWRcNTYRB5Pwz0ND4GoK4j1P1+CTbGoX5nAp2w5ujRo+Tn57Nnzx6ee+65Ol+vWkBAAAcPHgTg0KFD9OjRo972tkbVw7Hl5eVotdqbukb1kDVIb50QQrQE6bETLSY2Npa5c+diZWWFwWDgo48+4qeffiIsLIxRo0bddMmNULzZSI1VqlMD4YmtEOQK+usEq5d2Q0E5+rErOW7XmaA1W7h48SLjx48nKChIOWzMmDFMnz6d+++/X3nsjjvuYP369YwaNUqZY1fdo9gW2Nvbk56eDhiHY52dnRt8DZlfJ4QQLUtluIEuhMLCQhwdHSkoKMDBwaE52iXETdOhpzP/JZWbH1K0qVCz+8xtDO7dv13tMHEt0dHRHD58GIBJkyY1uEyJwWBg9erVlJaWotFo+NOf/iSFiYUQwgQaksNkKFa0OxrUPEboH8OxDaTWw8jT1hw9EM3atWs5f/68iVvYOtVcGVtcXNzg82W3CSGEaHkS7ES7tJBQuuKEWQPDncagwqXKgluP2wLGIckdO3awadMmsrKymqKprUbNYHczQ8gyDCuEEC1Pgp1ol5ywYjv34oYtZjf439wMNY4qKyIsH+T+2+bU2rg+PT2dDRs2EBERQUlJyTWu0nZduV9sQ8luE0II0fIk2Il2qyvORPNnBuAJUG/Aq368J52I5mF6406nTp24/fbbmThxIo6OjsqxZ8+eZc2aNcTExNz0ytHWys7OTlnB29CSJ1fuNmFra2vy9gkhhLg+mQQj2jVv7DnIQ/xOEh9xkHWcRoteeV6NiqkE8hhDGIM/qiuGbrt06YKfnx+nTp0iJiaGiooKtFotMTExxMXFERoaSo8ePeosf9LWVNeyKy4ubnCwk6LEQgjROkiwE+2eChUj6MwIOvMRZSSSTyEV2GNBZxxx49q9S2q1mj59+tCjRw9iYmI4deoUer2ekpISIiIiOHnyJGFhYXh6ejbTO2o6dnZ2FBcXU15eTlVVFebm5jd0nsyvE0KI1kGCnehQXLDGBeubOtfS0pLhw4fTq1cvoqKilDCTlZXFpk2b6NatG0OGDGnTJYEcHByUWnbFxcU3VMvuyt0mOnXq1KRtFEIIUT+ZYydEAzk5OTFx4kRuu+02XFxclMfPnz/P2rVriYqKUnbUaGtuZs/YmrtNdO7cuV0MSwshRFslwU6Im+Tj48OsWbMYNWoU1tbGXkC9Xs+xY8f47rvvlCHbtqRmyZMbDXYyDCuEEK2HBDshGkGlUhEUFMTcuXMZMGCAsktFeXk5e/fu5YcffiA5ObmFW3njbibYVS+c0Gg0+Pj4NEm7hBBC3BgJdkKYgIWFBUOGDGHOnDl0795deTwvL49ffvmFLVu2kJ+f33INvEENDXay24QQQrQuEuyEMCF7e3vGjRvH9OnTcXd3Vx5PSkri+++/5/fff6e8vLwFW3httra2DaplJ8OwQgjRukiwE6IJeHh4MH36dMaOHasU6zUYDJw8eZLvvvuO48ePt8r5d9W17ODGdp+oGexktwkhhGh5EuyEaCIqlYqAgADmzp1LSEiIMkxZWVnJgQMHWLt2LYmJiS3byDpUD8dW17KrT2lpqew2IYQQrYwEOyGamJmZGYMGDWLevHkEBgYqjxcWFrJt2zY2b96sBKTW4Ebn2UlvnRBCtD4S7IRoJjY2NoSHhzNz5ky8vLyUx1NTU1m/fj2RkZHKQoSWdDPBTubXCSFE6yDBTohm5urqytSpU5kwYUKtXSrOnDnDd999x+HDh9FqtS3WvhsJdlfuNuHq6tosbRNCCHFtUptAiBbi7++Pn58fJ0+e5PDhw1RWVqLVaomOjiYuLo4hQ4YQEBDQ7O2qGezqW0CRmpoqu00IIUQrJD12QrQgjUZDv379mDdvHr1791YCUnFxMbt27WLjxo1kZGQ0a5tqBrvCwsI6j5FhWCGEaJ0k2AnRClhZWXHLLbcwe/Zs/Pz8lMczMzP58ccf2blz5w2VHzEFGxubWgGzLtXBTnabEEKI1kWCnRCtiLOzM5MnT2bKlCk4Ozsrj587d441a9Zw8ODBa5YgMQW1Wo2dnR1Q9xw72W1CCCFaLwl2QrRCvr6+zJo1ixEjRmBlZQWATqfj6NGjfPfdd8TFxWEwGJrs9auHYysqKqisrKz1nJQ5EUKI1kuCnRCtlFqtplevXsybN4/+/fujVhu/XMvKytizZw8//PCDsjLV1K61gELm1wkhROslwU6IVs7CwoKhQ4cyZ84cunbtqjyem5vLzz//zK+//kpBQYFJX7O+kic1d5vo1KmT7DYhhBCtjEyOEaKNcHBwYPz48aSlpbF//34lYF28eJGkpCR69erF4MGDsbS0bPRrVc+xg9rB7tKlS8pt6a0TQojWR3rshGhjvLy8mDFjBuHh4djY2ACg1+s5ceIE3333HSdOnECv1zfqNerrsZNhWCGEaN0k2AnRBqlUKgIDA5k3bx6DBg1SVqZWVFSwb98+vv/++1ohrKHqCnay24QQQrR+EuyEaMPMzMwICQlh7ty59OjRQ3m8oKCAX3/9lZ9//pnc3NwGX9fW1lZZrFEd7FJTU5WtzmS3CSGEaJ0k2AnRDtja2jJmzBhmzJiBp6en8nhKSgo//PADe/bsoays7Iavp1KprqplJ2VOhBCi9ZNgJ0Q7kJiYyOzZs3Fzc2PatGnceuuttWrRPfzwwwwePJijR48qe7xeiwEDyb6wrV8xa/vl8JJ2JyssYym01qHRaPD19a11/MaNG8nMzARg69atbNiwwfRvUgghxHXJqlgh2qFu3brRpUsXTpw4wdq1a/H19WXu3LkcPHiQU6dOMXToULp3737VecX6Cr5Vn+ADDnJiRCYqPagNsF39O9pQA+oQGJHuQqBZCiP5Y/HExo0bCQgIwN3dnUmTJjXnWxVCCFGDBDsh2pHw8HAGDRpEdHQ0/fr1Y+nSpTz44INcunQJnU7HjBkz+OijjygrK8PDw4Nvv/2WhIQE/vOf/1BlZuDYVEfSl+6CMD/Yl4ThoUHoDiTD8Qx4cRT62b357X8/MeqX/+BWaMaqtz6iZ0AgW7du5eTJk4wZM4ZevXpRXFzMY489xrvvvsv333+PRqPhgw8+YNCgQQwaNIjhw4dz6NAhZs6cyT//+c+W/tiEEKLdkKFYIdqZO+64gz179hATE0NBQQFLlizhvvvuY/369Rw/fpw+ffrw9NNP4+Liwosvvsjhw4dJz83i6Ppwsh8IgvxyeG4E/HY/PLcD/jMBIhfA0oMAGB4LhYj7ydo6gwWvP4V/V38mTZrEihUrePvtt5V2pKens3HjRn7//Xf+97//KQEuPz+fZ555hn379vH111+3xEckhBDtlvTYCdHODBw4EAAfHx/y8/OVx11cXDA3N2fmzJmUlJTQpUsXzp07R3JqMqf7ayinFB0GcLYGP0fjSYGdwP1yseJy44pYvj4Oq4+DWkVGWhHvcaDOdiQmJipbofn7+yttcXZ2VmrgVe+DK4QQwjSkx06IdqZmGRKDwVDruYCAAC5dusTs2bMxGAz4+Phw3r2KEhsDOtXlY2tWMamrosmHUbB7Aay5EwzwJr+hMTe7alGGv78/R48eRa/Xk5iYiJOT01XtE0IIYVrSYydEB/Lwww9z991389133+Hh4cGXX37JkMhFkNGAi4zoDCOWwzBfsLMghzKcJvfh73//O7feeis+Pj4AeHp6Mn36dIYPH45arebDDz9smjclhBBCoTJc+St9HQoLC3F0dKSgoAAHB4fmaJcQohlcII9ufNCoa2hQEYYvv/GAiVolhBCipobkMBmKFaIDO9agrrq66TBwlHQTtEYIIURjSbATogMroNwk1ymmCgPX7fwXQgjRxCTYCdEB5efns3btWmwwv/mLbDwNmcUAmG89z8YNG03TOCGEEDdNgp0QHVB1sPPDsfYTev2NX2RjHGSWAOA7aRAzZswwYQuFEELcDAl2QrQzBoOBxx9/nDFjxnDrrbeyd+9epkyZgsFg4KWXXmLFihUsW7aMyMhIngu/B99TFTDoE3hiC9y7AWIzYPQKCPsCHvu5+qLw6M8wcjmMWQmHUmBrAtz/Izy7nUErM1i6dCkA7777LmFhYYwYMYLDhw8DMGjQIB577DGGDh3KW2+91UKfjBBCtH9S7kSIdubnn3/G2dmZ3bt3ExUVxddff83o0aN55JFHyM7O5rXXXiMxMZFz586xbt06/ssB/pG3DB4fAgGdoKwKIhaASgXTv4X4HDidBWoV/HZ55ateD5MC4OnhmPXxYuRKN0Bba7eJS5cu8fDDD7N9+3ZltwlfX1/69+8v24gJIUQTkWAnRDtz6tQpNmzYwJ49ezAYDPj5+fF///d/eHl5sWPHjquO/xP9edLZGgI6GZc/XMiDp7ZBaRWcz4PUIjidDaO7/HGS2tjZr0bFHHrhSBHFFMtuE0II0cJkKFaIdiYoKIg5c+YQERFBZGQkK1as4Nlnn+W9997jtddeQ6fTYW5uruwU4Yw13dUuwOWNJpZFw1NhEHk/DPQ0DsMGu8Kei3+8iF6PytwMH509HzJFeVh2mxBCiJYlwU6Idmbq1Knk5OQwZswYxo4dy2effYa5uTkLFy7kjjvu4J133sHLy4uysjJmz55NfHw8jljxLbPQGNSobguEJ7bCrDWgv1zCZGpP0OphxJcwZiXq7HK8Jg/A9++/s+yNd5XXrrnbxPz581m8eHELfQpCCNExyc4TQgjFt4l7+T+z3zjtW4laD/oav/qpDGAALLUq7irpyXtO03FChlWFEKKpNSSHyRw7IQRgXE2rOpDM3ws7kemgJXWaN4dsMsmlDAvM6FRpQbcDJYSes6Kbhx1Ot0moE0KI1kaCnRACgAsXLlBYWAjAQPsuLLK5rdbzBov/b+/eo6Oq772Pv/dMJvdAoAECJEASEoi5QaUUbZXAsYKlHKVVimV5HkutZ6nYPtU8y6JAH3RZrfbhtNY2iuXQRVuWeLTWNqwqVYip9Sw5XpJAgCSEcElCIBhCriRz2c8fI2NALokk2TM7n9daLmcye/b+zqyV8Fm/3/59fyZbj22l1dNKfX09bW1txMXFWVGqiIhchO6xExEASktLA49nzJjxmdcNw2DatGmB55WVlUNQlYiI9IeCnYhQV1fHyZMnAUhISGDixIkXPC4jIyOwwrWqqoo+3KIrIiJDSMFORC47WndWTEwMycnJALS3t1NXVzfIlYmISH8o2IkMcydOnKChoQGAkSNHkpKScsnjp0+fHnis6VgRkeCiYCcyzJWVlQUe5+XlXbaZ8KRJk4iKigLg0KFDnDlzZlDrExGRvlOwExnGWlpaqK2tBSA6Opr09PTLvsfhcJCRkQGAz+ejurp6UGsUEZG+U7ATGcZ6j9bl5ubidDr79L7eq2P3798/4HWJiMjno2AnMkx1dHQERtvCw8PPuXfucuLj40lMTATg1KlTnDhxYlBqFBGR/lGwExmmdu/ejc/nAyArK4vw8PB+vb93ENSonYhIcFCwExmGuru72bt3LwBOp5Ps7Ox+nyM1NRWXywVATU0Nbrd7QGsUEZH+U7ATGYYqKirweDyAf+Tt7CrX/ggLCyMtLQ0At9vNwYMHB7RGERHpPwU7kWHG4/GwZ88ewL9NWG5u7uc+l6ZjRUSCi4KdyDCzf//+QO+5tLQ04uLiPve5xo4dy+jRowE4fvw4LS0tA1GiiIh8Tgp2IsOIz+ejvLw88PxS24f1lVqfiIgEDwU7kWGkpqaG9vZ2wL+DxNnRtiuRnp6Ow+H/U1JdXR1YaSsiIkNPwU5kmDBNk9LS0sDzgRitA4iMjGTKlCkAdHV1cfjw4QE5r4iI9J+CncgwceTIEU6dOgVAYmJioMHwQOi9iKKysnLAzisiIv2jYCcyTAzGaN1ZEydOJDY2FoCjR4/S0dExoOcXEZG+UbATGQYaGxs5fvw4AKNHjyY5OXlAz28YRmARhWmaVFVVDej5RUSkbxTsRIaB3qN1eXl5GIYx4Nc4f3WsaZoDfg0REbk0BTsRm2tububIkSMAxMbGBnaLGGixsbEkJSUB0NbWxrFjxwblOiIicnEKdiI2d/5o3dnWJINBO1GIiFhLwU7Extra2qipqQH8bUl6T5cOhsmTJxMZGQlAbW0t3d3dg3o9ERE5l4KdiI2Vl5cH7nXLzs4mLCxsUK/ndDqZOnUqAF6vlwMHDgzq9URE5FwKdiI21dXVFZgOdblcZGVlDcl1NR0rImIdBTsRm9qzZw9erxeAzMxMIiIihuS6o0ePZuzYsQB8/PHHnDx5ckiuKyIiCnYittTT00NFRQUADoeDnJycIb3++a1PRERkaCjYidjQ/v376enpASAjI4OYmJghvX5aWlrgfr4DBw7g8XiG9PoiIsOVgp2IzXi9XsrLywPPc3Nzh7yG8PBwUlNTAf/oYW1t7ZDXICIyHCnYidhMdXU1nZ2dAKSkpBAfH29JHb0XUVRWVlpSg4jIcKNgJ2IjpmlSVlYWeJ6Xl2dZLYmJiYFQ2dDQQGtrq2W1iIgMFwp2IjZSW1vL6dOnAZgwYUJgdapVei+i0KidiMjgU7ATsZHe24fNmDHDsjrOSk9PxzAMwB/sfD6fxRWJiNibgp2ITdTX1wd6xiUkJJCUlGRxRRAdHc3kyZMB6OzspK6uzuKKRETsTcFOxCaCbbTuLO1EISIydBTsRGygqamJ+vp6AEaMGEFKSorFFX0qKSmJ6OhoAI4cORJYsSsiIgNPwU7EBs4frTt7X1swcDgcZGRkAODz+aiurra4IhER+1KwEwlxLS0tgQbA0dHRpKenW1zRZ2k6VkRkaCjYiYS43rtM5OTk4HQ6LazmwkaMGMGECRMAOH36NI2NjRZXJCJiTwp2IiGso6ODqqoqwL+NV2ZmpsUVXVzvnnYatRMRGRwKdiIhbPfu3YHecFlZWYSHh1tc0cWlpKQE6jt48CA9PT0WVyQiYj8KdiIhqru7m3379gHgdDrJzs62uKJLCwsLY+rUqQB4PB5qamosrkhExH4U7ERCVEVFBW63G/BPc0ZFRVlc0eX1XkShLcZERAaegp1ICPJ4POzZswcAwzDIy8uzuKK+SUhI4Atf+AIAJ06coLm52eKKRETsRcFOJARVVlZy5swZANLS0oiLi7O4or5T6xMRkcGjYCcSYnw+H2VlZYHnwbR9WF9MnTo10JKluroar9drcUUiIvahYCcSYmpqamhvbwdg0qRJjB492uKK+iciIiKw5Vl3dzeHDx+2uCIREftQsBMJIaZpfmb7sFCk6VgRkcGhYCcSQo4ePcqpU6cAGDduHImJiRZX9PmMHz8+cF9gXV1dYARSRESujIKdSAixw2gd+Ffy9t6JQq1PREQGhoKdSIhobGwM7LE6atQoJk2aZHFFV2batGkYhgH4g51pmhZXJCIS+hTsRELE+aN1Z0NRqIqJiSE5ORmA9vZ26uvrLa5IRCT0KdiJhIDm5maOHDkCQGxsLGlpaRZXNDB6T8dqEYWIyJVTsBMJAb1H63Jzc3E47PGrO3nyZCIjIwE4dOhQoOmyiIh8Pvb410HExtra2qipqQEgMjLynFYhoc7hcJCRkQH4Gy9XV1dbXJGISGhTsBMJcuXl5YGFBdnZ2YSFhVlc0cDqHVS1OlZE5Moo2IkEsa6ursC9Z2FhYWRlZVlc0cCLj49n3LhxgP9ewhMnTlhckYhI6FKwEwlie/bsCeyletVVVxEREWFxRYNDO1GIiAwMBTuRINXT00NFRQXgvxctJyfH4ooGT2pqKi6XC/DvhevxeCyuSEQkNCnYiQSp/fv309PTA0B6ejoxMTEWVzR4XC5XoIWL2+3m4MGDFlckIhKaFOxEgpDX66W8vDzwPC8vz8JqhoamY0VErpyCnUgQqq6uprOzE4CUlBTi4+OtLWgIjB07llGjRgH+7dNaWlqsLUhEJAQp2IkEGdM0KSsrCzwfDqN1Z/XeiUKtT0RE+k/BTiTI1NbWcvr0aQAmTJjA2LFjLa5o6GRkZAR21aiqqsLn81lckYhIaFGwEwkyvbcPmzFjhmV1WCEyMpIpU6YA/h5+Z/fHFRGRvlGwEwki9fX1nDx5EoCEhASSkpIsrmjo9Z6O1SIKEZH+UbATCSLDebTurKSkJGJjYwE4evQoHR0dFlckIhI6FOxEgkRTUxP19fUAjBgxgpSUFIsrsoZhGGRkZAD+hSRVVVUWVyQiEjoU7ESCxPmjdYZhWFeMxc5fHWuapoXViIiEDgU7kSDQ0tJCbW0tANHR0aSnp1tckbXi4uKYOHEiAK2trRw7dsziikREQoOCnUgQ6L3LRE5ODk6n08JqgoN2ohAR6T8FOxGLdXR0BO4jCw8PJzMz0+KKgsOUKVOIiIgA/L39zu6bKyIiF6dgJ2Kx3bt3BxrxZmVlER4ebnFFwcHpdAampL1eLwcOHLC4IhGR4KdgJ2Kh7u5u9u3bB/iDTHZ2tsUVBRdNx4qI9I+CnYiFKioqcLvdgH8laFRUlMUVBZfRo0czZswYAE6ePBlo3iwiIhemYCdiEY/Hw549ewB/77a8vDyLKwpO57c+ERGRi1OwE7FIZWUlZ86cASAtLY24uDiLKwpOU6dOJSwsDIDq6mo8Ho/FFYmIBC8FOxEL+Hw+ysrKAs+H6/ZhfREeHk5qaioAPT09HDp0yNqCRESCmIKdyCUcOnSIMWPGkJ+fT35+PqtWrbrgcRs2bLjgz914eZm93M1f+RYvcRv/xT0UsfFYCa0dbQBMmjSJ8vLyQMuT0tJSCgsLB+cDhaje07FaRCEicnFhVhcgEuzmzp3Lyy+/fMljNmzYwN133x143kwXv/T9N4WOD2iikzAcePG3NHGaDjwTfYy63cG8ihiempLF7ws3MmvWLDIyMpgxY4btR/Da2tr4zne+Q1tbG93d3axdu5abbrrpnGNef/11urq6WLJkCePHj2fkyJGcPn2ahoYGKtsaaI+DLjyMJII0RhONi9LSUnp6epg9ezaNjY0UFhaybt063njjDVavXs3SpUupr6/niSee0EIVEbElBTuRfmhsbOS2227j73//O1u2bOHw4cMkJiZSWVlJfn4+a9euZdWja9k/O4LWjw7BH74Jy17G4/HBuBjYehseJ/B4CaeKqvhThJPdvzpF1+8288orr/DSSy+xYsUKioqKWLZsGRs3bqSwsBDTNLnmmmt499132b59O48//jher5f777+f22+/3eqvpd82b97MwoULue+++zBNk9OnT3/mmIULF57zPG1aOr898Q92ZnXy73EvnPNaDC6+x0wSSw8Q124we/ZsEhMTWbduHQB/+tOf2LBhAzNnzhy8DyUiEgQU7EQu4+233yY/Px+AJUuWsHLlSu666y7q6+vZvn07LpeLjRs3UlxcTB2tfPToMbwLroOnroceD/z9Dghzwg//BjtqYWwM7KqHd78HhsFBH4y48yqennUXy77xLYqLiwGYNWsWP/jBD/B4POzatYs5c+ZgGAaPPfYYO3fuxOl0cv3117N06dKQ24IsKiqKnTt3cuuttzJu3Dji4+PZtGkTzz//PJGRkTzyyCPU19fT3t7OypUrWfO79fxs47O4vW6MR+fDxFTI3wRfHA/vN9CRO47fPOvFU/g8sc1eXv3La2zc8AIFBQXce++9vPbaa3z44YesWbOG9evXU1RUhNPpZMWKFTQ0NBAWFsZbb71l9dciInLFFOxELuP8qViPx8MDDzzAz372M1wuV+DnJia38CJufPCl8f4fftwF9xTBqTPQ0OYPIs1dcN0kMAwAvA5o4Qz/j/9mGd8659rz589nx44dbNu2jdtvv52mpiaqqqq48cYbAWhpaaGpqYnExMRB/hYG1h133EFDQwMLFiwgKiqKX/ziF2zYsIGSkhLCw8Px+Xxs3rwZgFc+fp/HXyzEKPlf0NmDueiPcIN/MQW3TIf1C+Ga3+I53Qn3zKKj3U3ryptpP9QN+L/DhQsXUlBQQHZ2NuvXrwfghRdeYNasWTz44IOBnT9EREKdFk+I9NOTTz7JD3/4Q55//nna29sBfx+6dznKBxwDTHD4QxtbdsM3MuDt78LCqWCakJkA7xzxPwbw+TBdDt731lPNx+dca9myZWzZsoUPPviAOXPmkJCQwPTp09m+fTvFxcWUlpaGXKgDcLlcrF69mtLSUh599FF+/OMfc/XVVwe2U3M4/H+aGmhlec1GzIoT+OZtgkV/hKbOT08085MAPTEOWvytY0xMPqKRe9mGiXnRGvbt28fcuXPPuZ6ISKjTiJ3IZfSeijUMg5EjR/LnP/+ZrKwsCgoKeO6555g2bRrLvrUU5wPZeHu/+V9S4I5X4a9VEPXJr1tuIsyaANf8FqJc8MxNMD8FHnqTpTu+x38s+d+Bt2dnZ1NaWhq438zhcLB69Wq+9rWv4XA4GDNmDC+99NKQfA8D6fDhw4wfP57w8HDGjh2Lw+Hgww8/xO1243K5AiNor1GJOzURcsdB0Xf8o5zuXt+w0eukpgkuJ3hNvJj8gyNcS8dFa8jMzKSkpIRZs2bh8/kU7kTEFhTsRC5hypQpNDU1XfC1RYsWsWjRIgCe/cNvGcPT/pWvxd/99KAZ42H3vZ998+q5/v96K/kuNYTzVa4PBEnwtz/pbcGCBSxYsODzfJygsXv3br797W8TGRmJaZr8+te/ZteuXXzlK18hJiaGhx9+mJN0spcmSEiFZdkwdxM4HZAzFp75+oVPfE0S/Nur8F4djp/eQA3NF63h+9//PnfeeSdz587VPXYiYhuGaZoXn6v4RGtra6DVwIgRI4aiLpGQUs5x8nhuQM7VyIOMI3ZAzhXKVvEmT/Mu3ktMp16OAVRzP2mMHrjCRESGWH9ymOYeRAZAG90DeK6eATtXKNtG9RWFOgATeJODA1OQiEgIULATOc+hQ4fYvn17v47/v7deYLr1Ql6vhlf3XfKQOML7fG07+5iuKz5HGA6aB+A8IiKhQsFO5Dz9DXYA0bgI68uv08J0WJJ50ZfjCOcLRPfr2nY1UH+cHOessBARsTcFO5HzFBYWsnXrVvLz81m/fj3XXXcd1157LTt27ABg165dfPWrXyU/P5+nn34agJPHTjDh269Dzm9gxydTf/mb4IHX4fr/hJXb/D/73Ufw7Hv+x0/+w78y9u6/wBefw4lB8p072L9nLwAFBQUUFxdjmib3338/8+bN44YbbqCuro7m5mby8/OZN28eN99885B+P0NlDDFXfA4PPgVlERlWtCpW5Dz33HMPycnJrFq1iuXLl1NSUkJnZyeLFi1i/vz5/OhHP+LFF18kOTkZn8/HkSNHOHnyJJvf/hv51evhkbdg/mcb6HL6zKcXOd4Ofzvg331i/0n4+h/xYjKNhM/Us23bNkaNGsXOnTt57733ePLJJ1myZAmzZ8/mqaeesm1z3W+SSRnH8V3BfXYODL5OutqZiMiwoWAnchE1NTVUVFQwb948gEDbk56eHpKTk4FPG9tmZ2dzfVgKM5IzKDu17dMocoEGugDUnvL3ZjMMyBwDseF8g3RGGocCh5xdsL53715effVVSkpKME2T5ORk5s6dyzvvvMPy5cuZOXMmBQUFg/Y9DJXi4mJ++tOfEhERQWNjI0/957OYm16HDxqgyw0bFvvbx+RvgpxxUNbo/35/eROcccNdf/Hv7hEbDn/4Js7mbuL/7W/8aHwFM2bMoLOzk7feeouIiAieeOIJ5syZY/VHFhEZcAp2IudxuVx4vV5SU1PJzc2lqKgIwzBwu90AREREUF9fz8SJEwOjZYZhYGDwIreSY/4SEwMPfLaB7llT4mH3cTBNnFWnMNo9bGYJj416n7q6OrKzsykvL2fx4sVMnz6dpUuXsmbNGgDcbjdut5uf/OQnANx4440sXbqUSZMmDf6XM8g6Ozt544032L9/Pw899BC3vHgvf42uxfNRPTz9Lvzxky3XFmfAr74Oy/4LPmyAd4/6mzyv+CJs3QMbPsB761WE13fy+zd/T3h4OF/+8pf55z//SVhYmG1HOUVEFOxEzpOTk8OqVau45557WLZsGXPnzsXpdJKTk8MzzzzD+vXrWbp0KS6Xi0WLFnHbbbcF3juREcxkPE2MpPZSN+0nxsGNaXDNRuKvTmX8qGRGEcWdd97JHXfcwQsvvEB0tP/esMWLF7Njxw7mzZuHYRgsX76c9PR0HnnkERwOB0lJSSQlJQ321zIkZs6ciWEYZGZmcuzYMb7y9B54cyvgg7BeU6lXT/D//0sToboZ9jbB/zTA5jJw++C6yfwr03DmfbpN2bp161ixYgVRUVGsW7cuJLdiExG5HDUoFhkEzXTxK97jN7zPCToIw4EXHwYGDgw8+EhmBCuZzX18ibmzruX999+3umxLFRcXs2bNGkpKSqiqqqKgoIBTp07xH+9sZf4HT9L+YBEU3+mfil19PdyQBre/DAXXwj+PwKgouCMPA/iaezK/qr+Ohwse4uWXXwagq6uLqKgotmzZwoEDB1i7dq2ln1dEpK/6k8M0YicyCEYTxU/I52Gu4y9U8gY1NNOFgUECUfwr01jAVLXiOM/IkSNZvHgxx48fZ+PGjaxevZr/k7+c2+fksgXXJzu/Gv6FJ4++DXmJ/tG7rDFwdxHGplImMoL7HnyM8CznOee+5ZZb6O7uxuPxUFhYaMXHExEZdBqxE5GgUFxcTFFRET//+c8v+LqJyS7quTl/IR8X3YIn1hV4LYkRrORLrGDmgLRJEREJJhqxExHbMTD4MklMJ4FXKKAHJ114iCeSUURiaPRTREQjdiIiIiLBrD85TB07RURERGxCwU5ERETEJhTsRERERGxCwU5ERETEJhTsRERERGxCwU5ERETEJhTsRERERGxCwU5ERETEJhTsRERERGxCwU5ERETEJhTsRERERGxCwU5ERETEJhTsRERERGxCwU5ERETEJhTsRERERGxCwU5ERETEJhTsRERERGxCwU5ERETEJhTsRERERGxCwU5ERETEJhTsRERERGxCwU5ERETEJhTsRERERGxCwU5ERETEJhTsRERERGxCwU5ERETEJhTsRERERGwirC8HmaYJQGtr66AWIyIiIiLnOpu/zuaxS+lTsGtrawMgOTn5CsoSERERkc+rra2NkSNHXvIYw+xD/PP5fDQ0NBAXF4dhGANWoIiIiIhcmmmatLW1MWHCBByOS99F16dgJyIiIiLBT4snRERERGxCwU5ERETEJhTsRERERGxCwU5ERETEJhTsRERERGxCwU5ERETEJhTsRERERGzi/wMELo35ufPVUQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Chat_KG_class.draw_graph_from_record(record,\n",
    "                                     node_colors=([0, 1, 1], [0, 1, 0.5], [1, 0.7, 0.75]),\n",
    "                                     node_shape='o',\n",
    "                                     edge_color='black',\n",
    "                                     edge_widths=(2, 0.5),\n",
    "                                     node_sizes=(500, 150, 50),\n",
    "                                     font_color='black',\n",
    "                                     font_size=6,\n",
    "                                     show_text=False,\n",
    "                                     save_fig=True,\n",
    "                                     save_path='KG_outputs/what_is_autorela.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c4846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-glm",
   "language": "python",
   "name": "conda-glm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
